{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.getLogger('jieba').setLevel(logging.WARN)\n",
    "logging.getLogger('fgclassifier').setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-19 14:35:03,853 [INFO] Reading data/english.csv..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    Hey, the lollipop of the dead man, the overlor...\n",
       "1    The third time to participate in the public co...\n",
       "Name: content, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-19 14:35:04,263 [INFO] Fit & Transform TF-IDF...\n",
      "2018-11-19 14:35:24,675 [INFO] Fit & Transform TruncatedSVD...\n",
      "2018-11-19 14:35:42,922 [INFO] Transforming TF-IDF...\n",
      "2018-11-19 14:35:45,461 [INFO] Transforming TruncatedSVD...\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from fgclassifier.baseline import BaselineFeature, Tfidf, SVD\n",
    "from fgclassifier.utils import read_data\n",
    "\n",
    "X, y = read_data('data/english.csv', seg_words=False, sample_n=None)\n",
    "display(X.head(2))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Builder TF-IDF features with reduced dimension\n",
    "feature = BaselineFeature([\n",
    "    ('tfidf', Tfidf(analyzer='word', ngram_range=(1, 4),\n",
    "                    min_df=0.01, max_df=1.0, norm='l2')),\n",
    "    ('svd', SVD(n_components=1000))\n",
    "])\n",
    "X_train = feature.fit_transform(X_train)\n",
    "X_test = feature.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-19 14:41:40,774 [INFO] [Validate]: F1 Scores\n",
      "2018-11-19 14:41:40,776 [INFO]   location_traffic_convenience            \t0.4385\n",
      "2018-11-19 14:41:40,778 [INFO]   location_distance_from_business_district\t0.3371\n",
      "2018-11-19 14:41:40,781 [INFO]   location_easy_to_find                   \t0.4637\n",
      "2018-11-19 14:41:40,783 [INFO]   service_wait_time                       \t0.4034\n",
      "2018-11-19 14:41:40,786 [INFO]   service_waiters_attitude                \t0.5584\n",
      "2018-11-19 14:41:40,789 [INFO]   service_parking_convenience             \t0.4865\n",
      "2018-11-19 14:41:40,793 [INFO]   service_serving_speed                   \t0.5119\n",
      "2018-11-19 14:41:40,796 [INFO]   price_level                             \t0.5383\n",
      "2018-11-19 14:41:40,801 [INFO]   price_cost_effective                    \t0.4258\n",
      "2018-11-19 14:41:40,806 [INFO]   price_discount                          \t0.4814\n",
      "2018-11-19 14:41:40,809 [INFO]   environment_decoration                  \t0.4415\n",
      "2018-11-19 14:41:40,820 [INFO]   environment_noise                       \t0.4812\n",
      "2018-11-19 14:41:40,831 [INFO]   environment_space                       \t0.4833\n",
      "2018-11-19 14:41:40,838 [INFO]   environment_cleaness                    \t0.4628\n",
      "2018-11-19 14:41:40,847 [INFO]   dish_portion                            \t0.4435\n",
      "2018-11-19 14:41:40,853 [INFO]   dish_taste                              \t0.5123\n",
      "2018-11-19 14:41:40,857 [INFO]   dish_look                               \t0.3482\n",
      "2018-11-19 14:41:40,861 [INFO]   dish_recommendation                     \t0.4603\n",
      "2018-11-19 14:41:40,870 [INFO]   others_overall_experience               \t0.4787\n",
      "2018-11-19 14:41:40,873 [INFO]   others_willing_to_consume_again         \t0.4960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4626354712591074"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fgclassifier.baseline import Baseline\n",
    "from fgclassifier.classifiers import LinearDiscriminantAnalysis\n",
    "\n",
    "model = Baseline(classifier=LinearDiscriminantAnalysis())\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exam the quality of the top terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yuan to \t 5256\n",
      "yuan the \t 5255\n",
      "yuan it \t 5254\n",
      "yuan is \t 5253\n",
      "yuan for \t 5252\n",
      "yuan and \t 5251\n",
      "yuan \t 5250\n",
      "yourself \t 5249\n",
      "your \t 5248\n",
      "young \t 5247\n",
      "you will \t 5246\n",
      "you want to eat \t 5245\n",
      "you want to \t 5244\n",
      "you want \t 5243\n",
      "you to \t 5242\n",
      "you should \t 5241\n",
      "you need to \t 5240\n",
      "you need \t 5239\n",
      "you must \t 5238\n",
      "you like \t 5237\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print('\\n'.join(['%s \\t %s' % (k, v) for k, v in\n",
    "                 Counter(feature.named_steps.tfidf.vocabulary_).most_common()[:20]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-aff520c8fee3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mClassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mall_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mall_avg_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from fgclassifier import classifiers\n",
    "\n",
    "# Run for all classifiers\n",
    "# can add another layer of for loops to \n",
    "# change vectorizer/reducer, or use sklearn's\n",
    "# GridSearchCV\n",
    "all_avg_scores, all_scores = {}, {}\n",
    "for cls in ['LinearDiscriminantAnalysis',\n",
    "            'LogisticRegression',\n",
    "            'RidgeClassifierCV']:\n",
    "    Classifier = getattr(classifiers, cls)\n",
    "    model = Baseline(classifier=Classifier)\n",
    "    model.fit(X_train, y_train)\n",
    "    all_scores[cls] = model.scores(X_test, y_test)\n",
    "    all_avg_scores[cls] = np.mean(all_scores[cls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
