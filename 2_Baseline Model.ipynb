{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.getLogger('jieba').setLevel(logging.WARN)\n",
    "logging.getLogger('fgclassifier').setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-16 02:00:08,983 [INFO] Reading data/english.csv..\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "\n",
    "from fgclassifier.baseline import Baseline, Tfidf, SVD\n",
    "from fgclassifier.utils import read_data, read_csv\n",
    "from fgclassifier import classifiers\n",
    "\n",
    "\n",
    "vectorizer = Tfidf(analyzer='word', ngram_range=(1, 4), min_df=0.005, max_df=0.8, norm='l2')\n",
    "reducer = SVD(n_components=100)\n",
    "\n",
    "model = Baseline(steps=[\n",
    "    ('tfidf', vectorizer),\n",
    "    ('reduce_dim', reducer)\n",
    "])\n",
    "df = read_csv('data/english.csv', seg_words=False, sample_n=None)\n",
    "X_train, Y_train = read_data(df[:8000])\n",
    "X_validate, Y_validate = read_data(df[8000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-16 02:04:12,923 [INFO] Fit & Transform TF-IDF...\n"
     ]
    }
   ],
   "source": [
    "ff = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exam the quality of the top terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zhongshan \t 10962\n",
      "zhejiang \t 10961\n",
      "zhang \t 10960\n",
      "yunnan \t 10959\n",
      "yum kung soup \t 10958\n",
      "yum kung \t 10957\n",
      "yum \t 10956\n",
      "yuba \t 10955\n",
      "yuan vouchers \t 10954\n",
      "yuan to \t 10953\n",
      "yuan this \t 10952\n",
      "yuan there \t 10951\n",
      "yuan the price is \t 10950\n",
      "yuan the price \t 10949\n",
      "yuan the \t 10948\n",
      "yuan per person \t 10947\n",
      "yuan per \t 10946\n",
      "yuan it is \t 10945\n",
      "yuan it \t 10944\n",
      "yuan is \t 10943\n",
      "yuan in \t 10942\n",
      "yuan for \t 10941\n",
      "yuan and the \t 10940\n",
      "yuan and \t 10939\n",
      "yuan \t 10938\n",
      "yourself \t 10937\n",
      "your own \t 10936\n",
      "your home \t 10935\n",
      "your \t 10934\n",
      "younger \t 10933\n",
      "young people \t 10932\n",
      "young \t 10931\n",
      "you will be \t 10930\n",
      "you will \t 10929\n",
      "you want to eat \t 10928\n",
      "you want to \t 10927\n",
      "you want \t 10926\n",
      "you to \t 10925\n",
      "you think \t 10924\n",
      "you the \t 10923\n",
      "you that \t 10922\n",
      "you should \t 10921\n",
      "you say \t 10920\n",
      "you order \t 10919\n",
      "you need to \t 10918\n",
      "you need \t 10917\n",
      "you must \t 10916\n",
      "you look at \t 10915\n",
      "you look \t 10914\n",
      "you like \t 10913\n",
      "you know \t 10912\n",
      "you have to \t 10911\n",
      "you have \t 10910\n",
      "you go to \t 10909\n",
      "you go \t 10908\n",
      "you for your \t 10907\n",
      "you for the \t 10906\n",
      "you for \t 10905\n",
      "you feel \t 10904\n",
      "you enter the door \t 10903\n",
      "you enter the \t 10902\n",
      "you enter \t 10901\n",
      "you eat the \t 10900\n",
      "you eat it \t 10899\n",
      "you eat \t 10898\n",
      "you don want \t 10897\n",
      "you don have to \t 10896\n",
      "you don have \t 10895\n",
      "you don \t 10894\n",
      "you do \t 10893\n",
      "you come \t 10892\n",
      "you can use \t 10891\n",
      "you can try it \t 10890\n",
      "you can try \t 10889\n",
      "you can take \t 10888\n",
      "you can see the \t 10887\n",
      "you can see it \t 10886\n",
      "you can see \t 10885\n",
      "you can order \t 10884\n",
      "you can have \t 10883\n",
      "you can go \t 10882\n",
      "you can get \t 10881\n",
      "you can find \t 10880\n",
      "you can eat it \t 10879\n",
      "you can eat \t 10878\n",
      "you can come \t 10877\n",
      "you can choose \t 10876\n",
      "you can also \t 10875\n",
      "you can add \t 10874\n",
      "you can \t 10873\n",
      "you are not \t 10872\n",
      "you are \t 10871\n",
      "you \t 10870\n",
      "yolk \t 10869\n",
      "yogurt \t 10868\n",
      "yoghurt \t 10867\n",
      "yet \t 10866\n",
      "yesterday \t 10865\n",
      "yes \t 10864\n",
      "yellow throat \t 10863\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print('\\n'.join(['%s \\t %s' % (k, v) for k, v in\n",
    "                 Counter(model.vectorizer.vocabulary_).most_common()[:100]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-11 22:21:20,258 [INFO] [train] location_traffic_convenience \n",
      "2018-11-11 22:21:22,628 [INFO] [train] location_distance_from_business_district \n",
      "2018-11-11 22:21:24,881 [INFO] [train] location_easy_to_find \n",
      "2018-11-11 22:21:27,474 [INFO] [train] service_wait_time \n",
      "2018-11-11 22:21:29,750 [INFO] [train] service_waiters_attitude \n",
      "2018-11-11 22:21:31,833 [INFO] [train] service_parking_convenience \n",
      "2018-11-11 22:21:33,869 [INFO] [train] service_serving_speed \n",
      "2018-11-11 22:21:35,799 [INFO] [train] price_level \n",
      "2018-11-11 22:21:37,756 [INFO] [train] price_cost_effective \n",
      "2018-11-11 22:21:39,686 [INFO] [train] price_discount \n",
      "2018-11-11 22:21:41,682 [INFO] [train] environment_decoration \n",
      "2018-11-11 22:21:43,801 [INFO] [train] environment_noise \n",
      "2018-11-11 22:21:45,922 [INFO] [train] environment_space \n",
      "2018-11-11 22:21:47,951 [INFO] [train] environment_cleaness \n",
      "2018-11-11 22:21:49,997 [INFO] [train] dish_portion \n",
      "2018-11-11 22:21:52,461 [INFO] [train] dish_taste \n",
      "2018-11-11 22:21:54,538 [INFO] [train] dish_look \n",
      "2018-11-11 22:21:56,502 [INFO] [train] dish_recommendation \n",
      "2018-11-11 22:21:58,484 [INFO] [train] others_overall_experience \n",
      "2018-11-11 22:22:00,468 [INFO] [train] others_willing_to_consume_again \n",
      "2018-11-11 22:22:02,710 [INFO] [validate] location_traffic_convenience \n",
      "2018-11-11 22:22:02,717 [INFO] [validate] location_distance_from_business_district \n",
      "/Users/jesse/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "2018-11-11 22:22:02,724 [INFO] [validate] location_easy_to_find \n",
      "2018-11-11 22:22:02,740 [INFO] [validate] service_wait_time \n",
      "2018-11-11 22:22:02,763 [INFO] [validate] service_waiters_attitude \n",
      "2018-11-11 22:22:02,794 [INFO] [validate] service_parking_convenience \n",
      "2018-11-11 22:22:02,822 [INFO] [validate] service_serving_speed \n",
      "2018-11-11 22:22:02,835 [INFO] [validate] price_level \n",
      "2018-11-11 22:22:02,846 [INFO] [validate] price_cost_effective \n",
      "2018-11-11 22:22:02,859 [INFO] [validate] price_discount \n",
      "2018-11-11 22:22:02,874 [INFO] [validate] environment_decoration \n",
      "2018-11-11 22:22:02,884 [INFO] [validate] environment_noise \n",
      "2018-11-11 22:22:02,894 [INFO] [validate] environment_space \n",
      "2018-11-11 22:22:02,899 [INFO] [validate] environment_cleaness \n",
      "2018-11-11 22:22:02,907 [INFO] [validate] dish_portion \n",
      "2018-11-11 22:22:02,912 [INFO] [validate] dish_taste \n",
      "2018-11-11 22:22:02,917 [INFO] [validate] dish_look \n",
      "2018-11-11 22:22:02,924 [INFO] [validate] dish_recommendation \n",
      "2018-11-11 22:22:02,931 [INFO] [validate] others_overall_experience \n",
      "2018-11-11 22:22:02,938 [INFO] [validate] others_willing_to_consume_again \n",
      "2018-11-11 22:22:02,944 [INFO] [validate] \n",
      "  location_traffic_convenience            \t0.4649\n",
      "  location_distance_from_business_district\t0.3406\n",
      "  location_easy_to_find                   \t0.5136\n",
      "  service_wait_time                       \t0.4131\n",
      "  service_waiters_attitude                \t0.5956\n",
      "  service_parking_convenience             \t0.4781\n",
      "  service_serving_speed                   \t0.4981\n",
      "  price_level                             \t0.5513\n",
      "  price_cost_effective                    \t0.4374\n",
      "  price_discount                          \t0.4988\n",
      "  environment_decoration                  \t0.4515\n",
      "  environment_noise                       \t0.4820\n",
      "  environment_space                       \t0.5008\n",
      "  environment_cleaness                    \t0.4846\n",
      "  dish_portion                            \t0.4437\n",
      "  dish_taste                              \t0.5390\n",
      "  dish_look                               \t0.3600\n",
      "  dish_recommendation                     \t0.4299\n",
      "  others_overall_experience               \t0.4780\n",
      "  others_willing_to_consume_again         \t0.4619\n",
      "2018-11-11 22:22:02,944 [INFO] [validate] Final F1 Score: 0.47114084378701343\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_avg_scores, all_scores = {}, {}\n",
    "for cls in ['LinearDiscriminantAnalysis']:\n",
    "    if cls.startswith('_'):\n",
    "        continue\n",
    "    Classifier = getattr(classifiers, cls) \n",
    "    model = Indie(classifier=Classifier,\n",
    "                  vectorizer=model.vectorizer,\n",
    "                  reducer=model.reducer)\n",
    "    model.train(X_train, Y_train)\n",
    "    avg_score, scores = model.validate(X_validate, Y_validate)\n",
    "    all_avg_scores[cls] = avg_score\n",
    "    all_scores[cls] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
