{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.getLogger('jieba').setLevel(logging.WARN)\n",
    "logging.getLogger('fgclassifier').setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-19 23:15:38,945 [INFO] Reading data/english.csv..\n",
      "2018-11-19 23:15:39,167 [INFO] Building features for count...\n",
      "2018-11-19 23:16:06,107 [INFO] Building features for tfidf...\n",
      "2018-11-19 23:16:06,108 [INFO]   count: fit_transform use cache.\n",
      "2018-11-19 23:16:06,239 [INFO]   count: transform use cache.\n",
      "2018-11-19 23:16:06,262 [INFO] Building features for lsa_100...\n",
      "2018-11-19 23:16:06,263 [INFO]   tfidf: fit_transform use cache.\n",
      "2018-11-19 23:16:08,077 [INFO]   tfidf: transform use cache.\n",
      "2018-11-19 23:16:08,130 [INFO] Building features for lsa_1k...\n",
      "2018-11-19 23:16:08,131 [INFO]   tfidf: fit_transform use cache.\n",
      "2018-11-19 23:16:28,601 [INFO]   tfidf: transform use cache.\n",
      "2018-11-19 23:16:28,964 [INFO] Building features for lda_count_100...\n",
      "2018-11-19 23:16:28,965 [INFO]   count: fit_transform use cache.\n",
      "2018-11-19 23:21:06,303 [INFO]   count: transform use cache.\n",
      "2018-11-19 23:21:11,277 [INFO] Building features for lda_count_200...\n",
      "2018-11-19 23:21:11,279 [INFO]   count: fit_transform use cache.\n",
      "2018-11-19 23:26:29,980 [INFO]   count: transform use cache.\n",
      "2018-11-19 23:26:35,953 [INFO] Building features for lda_tfidf_100...\n",
      "2018-11-19 23:26:35,954 [INFO]   tfidf: fit_transform use cache.\n",
      "2018-11-19 23:28:00,234 [INFO]   tfidf: transform use cache.\n",
      "2018-11-19 23:28:01,194 [INFO] Building features for lda_tfidf_200...\n",
      "2018-11-19 23:28:01,196 [INFO]   tfidf: fit_transform use cache.\n",
      "2018-11-19 23:29:58,101 [INFO]   tfidf: transform use cache.\n",
      "2018-11-19 23:29:59,194 [INFO] Building features for count_sv...\n",
      "2018-11-19 23:30:22,441 [INFO] Building features for tfidf_sv...\n",
      "2018-11-19 23:30:22,442 [INFO]   count_sv: fit_transform use cache.\n",
      "2018-11-19 23:30:22,572 [INFO]   count_sv: transform use cache.\n",
      "2018-11-19 23:30:22,592 [INFO] Building features for lsa_100_sv...\n",
      "2018-11-19 23:30:22,594 [INFO]   tfidf_sv: fit_transform use cache.\n",
      "2018-11-19 23:30:24,188 [INFO]   tfidf_sv: transform use cache.\n",
      "2018-11-19 23:30:24,236 [INFO] Building features for lsa_1k_sv...\n",
      "2018-11-19 23:30:24,237 [INFO]   tfidf_sv: fit_transform use cache.\n",
      "2018-11-19 23:30:42,890 [INFO]   tfidf_sv: transform use cache.\n",
      "2018-11-19 23:30:43,240 [INFO] Building features for lda_count_100_sv...\n",
      "2018-11-19 23:30:43,242 [INFO]   count_sv: fit_transform use cache.\n",
      "2018-11-19 23:34:12,177 [INFO]   count_sv: transform use cache.\n",
      "2018-11-19 23:34:17,084 [INFO] Building features for lda_count_200_sv...\n",
      "2018-11-19 23:34:17,085 [INFO]   count_sv: fit_transform use cache.\n",
      "2018-11-19 23:38:53,610 [INFO]   count_sv: transform use cache.\n",
      "2018-11-19 23:38:59,105 [INFO] Building features for lda_tfidf_100_sv...\n",
      "2018-11-19 23:38:59,106 [INFO]   tfidf_sv: fit_transform use cache.\n",
      "2018-11-19 23:40:12,635 [INFO]   tfidf_sv: transform use cache.\n",
      "2018-11-19 23:40:13,430 [INFO] Building features for lda_tfidf_200_sv...\n",
      "2018-11-19 23:40:13,432 [INFO]   tfidf_sv: fit_transform use cache.\n",
      "2018-11-19 23:42:15,745 [INFO]   tfidf_sv: transform use cache.\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "from fgclassifier.features import FeaturePipeline, logger\n",
    "from fgclassifier.utils import read_data\n",
    "\n",
    "X, y = read_data('data/english.csv', seg_words=False, sample_n=None)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# feature models with dependency specs\n",
    "fm_spec = {\n",
    "   'count': CountVectorizer(ngram_range=(1, 4), min_df=0.01, max_df=0.99),\n",
    "   'tfidf': ['count', TfidfTransformer],\n",
    "   'lsa_100': ['tfidf', TruncatedSVD(n_components=100)],\n",
    "   'lsa_1k': ['tfidf', TruncatedSVD(n_components=1000)],\n",
    "   'lda_count_100': ['count', LatentDirichletAllocation(n_components=100)],\n",
    "   'lda_count_200': ['count', LatentDirichletAllocation(n_components=200)],\n",
    "   'lda_tfidf_100': ['tfidf', LatentDirichletAllocation(n_components=100)],\n",
    "   'lda_tfidf_200': ['tfidf', LatentDirichletAllocation(n_components=200)],\n",
    "    \n",
    "    # small vocabulary (removed more stop words)\n",
    "   'count_sv': [CountVectorizer(ngram_range=(1, 4), min_df=0.01, max_df=0.85)],\n",
    "   'tfidf_sv': ['count_sv', TfidfTransformer],\n",
    "   'lsa_100_sv': ['tfidf_sv', TruncatedSVD(n_components=100)],\n",
    "   'lsa_1k_sv': ['tfidf_sv', TruncatedSVD(n_components=1000)],\n",
    "   'lda_count_100_sv': ['count_sv', LatentDirichletAllocation(n_components=100)],\n",
    "   'lda_count_200_sv': ['count_sv', LatentDirichletAllocation(n_components=200)],\n",
    "   'lda_tfidf_100_sv': ['tfidf_sv', LatentDirichletAllocation(n_components=100)],\n",
    "   'lda_tfidf_200_sv': ['tfidf_sv', LatentDirichletAllocation(n_components=200)],\n",
    "}\n",
    "\n",
    "# Cache trained fetures, we make this cache object\n",
    "# so different steps can reuse previously trained features\n",
    "fm = defaultdict(dict)\n",
    "\n",
    "for name in fm_spec.keys():\n",
    "    logger.info(f'Building features for {name}...')\n",
    "    model = FeaturePipeline(name, spec=fm_spec, cache=fm)\n",
    "    model.fit_transform(X_train)\n",
    "    model.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exam the quality of the top terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500,) (2500,)\n",
      "\n",
      "min_df: 0.01, max_df: 0.99, ngram_range: (1, 4)\n",
      "vocab size: 5306\n",
      "yuan to \t 5305\n",
      "yuan the \t 5304\n",
      "yuan it \t 5303\n",
      "yuan is \t 5302\n",
      "yuan for \t 5301\n",
      "yuan and \t 5300\n",
      "yuan \t 5299\n",
      "yourself \t 5298\n",
      "your own \t 5297\n",
      "your \t 5296\n",
      "\n",
      "min_df: 0.01, max_df: 0.85, ngram_range: (1, 4)\n",
      "vocab size: 5297\n",
      "yuan to \t 5296\n",
      "yuan the \t 5295\n",
      "yuan it \t 5294\n",
      "yuan is \t 5293\n",
      "yuan for \t 5292\n",
      "yuan and \t 5291\n",
      "yuan \t 5290\n",
      "yourself \t 5289\n",
      "your own \t 5288\n",
      "your \t 5287\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "counter = fm['count']['model'].named_steps.count\n",
    "counter_sv = fm['count_sv']['model'].named_steps.count_sv\n",
    "for model in [counter, counter_sv]:\n",
    "    print('\\nmin_df: %.2f, max_df: %.2f, ngram_range: %s' % (\n",
    "        model.min_df, model.max_df, model.ngram_range\n",
    "    ))\n",
    "    print('vocab size: %s' % len(model.vocabulary_))\n",
    "    print('\\n'.join(['%s \\t %s' % (k, v) for k, v in\n",
    "                     Counter(model.vocabulary_).most_common()[:10]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Very Basic TF-IDF + LDA classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-19 23:51:59,870 [INFO] [Validate]: F1 Scores\n",
      "2018-11-19 23:51:59,874 [INFO]   location_traffic_convenience            \t0.4409\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "2018-11-19 23:51:59,880 [INFO]   location_distance_from_business_district\t0.3275\n",
      "2018-11-19 23:51:59,883 [INFO]   location_easy_to_find                   \t0.4765\n",
      "2018-11-19 23:51:59,886 [INFO]   service_wait_time                       \t0.4311\n",
      "2018-11-19 23:51:59,889 [INFO]   service_waiters_attitude                \t0.5667\n",
      "2018-11-19 23:51:59,897 [INFO]   service_parking_convenience             \t0.4789\n",
      "2018-11-19 23:51:59,901 [INFO]   service_serving_speed                   \t0.5168\n",
      "2018-11-19 23:51:59,908 [INFO]   price_level                             \t0.5529\n",
      "2018-11-19 23:51:59,912 [INFO]   price_cost_effective                    \t0.4438\n",
      "2018-11-19 23:51:59,924 [INFO]   price_discount                          \t0.4932\n",
      "2018-11-19 23:51:59,928 [INFO]   environment_decoration                  \t0.4533\n",
      "2018-11-19 23:51:59,942 [INFO]   environment_noise                       \t0.4904\n",
      "2018-11-19 23:51:59,957 [INFO]   environment_space                       \t0.4933\n",
      "2018-11-19 23:51:59,968 [INFO]   environment_cleaness                    \t0.4784\n",
      "2018-11-19 23:51:59,987 [INFO]   dish_portion                            \t0.4394\n",
      "2018-11-19 23:52:00,011 [INFO]   dish_taste                              \t0.5105\n",
      "2018-11-19 23:52:00,024 [INFO]   dish_look                               \t0.3545\n",
      "2018-11-19 23:52:00,050 [INFO]   dish_recommendation                     \t0.4409\n",
      "2018-11-19 23:52:00,083 [INFO]   others_overall_experience               \t0.4797\n",
      "2018-11-19 23:52:00,093 [INFO]   others_willing_to_consume_again         \t0.4764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4672456343211369"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fgclassifier.baseline import Baseline\n",
    "from fgclassifier.classifiers import LDA\n",
    "\n",
    "# Linear Discriminant Analysis\n",
    "model = Baseline(classifier=LDA)\n",
    "model.fit(fm['lsa_1k']['train'], y_train)\n",
    "model.score(fm['lsa_1k']['test'], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for the Best Feature + Classifier Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for all classifiers and feature builders\n",
    "all_avg_scores, all_scores = defaultdict(dict), defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-20 00:28:32,133 [INFO] ======== Feature Model: tfidf =========\n",
      "2018-11-20 00:28:32,134 [INFO] Train for tfidf -> DummyStratified...\n",
      "2018-11-20 00:28:32,163 [INFO] [Validate]: F1 Scores\n",
      "2018-11-20 00:28:32,166 [INFO]   location_traffic_convenience            \t0.2476\n",
      "2018-11-20 00:28:32,168 [INFO]   location_distance_from_business_district\t0.2610\n",
      "2018-11-20 00:28:32,172 [INFO]   location_easy_to_find                   \t0.2475\n",
      "2018-11-20 00:28:32,176 [INFO]   service_wait_time                       \t0.2546\n",
      "2018-11-20 00:28:32,179 [INFO]   service_waiters_attitude                \t0.2424\n",
      "2018-11-20 00:28:32,182 [INFO]   service_parking_convenience             \t0.2668\n",
      "2018-11-20 00:28:32,185 [INFO]   service_serving_speed                   \t0.2485\n",
      "2018-11-20 00:28:32,189 [INFO]   price_level                             \t0.2424\n",
      "2018-11-20 00:28:32,191 [INFO]   price_cost_effective                    \t0.2600\n",
      "2018-11-20 00:28:32,195 [INFO]   price_discount                          \t0.2300\n",
      "2018-11-20 00:28:32,198 [INFO]   environment_decoration                  \t0.2446\n",
      "2018-11-20 00:28:32,202 [INFO]   environment_noise                       \t0.2491\n",
      "2018-11-20 00:28:32,206 [INFO]   environment_space                       \t0.2530\n",
      "2018-11-20 00:28:32,210 [INFO]   environment_cleaness                    \t0.2388\n",
      "2018-11-20 00:28:32,216 [INFO]   dish_portion                            \t0.2500\n",
      "2018-11-20 00:28:32,222 [INFO]   dish_taste                              \t0.2468\n",
      "2018-11-20 00:28:32,227 [INFO]   dish_look                               \t0.2552\n",
      "2018-11-20 00:28:32,230 [INFO]   dish_recommendation                     \t0.2472\n",
      "2018-11-20 00:28:32,234 [INFO]   others_overall_experience               \t0.2540\n",
      "2018-11-20 00:28:32,238 [INFO]   others_willing_to_consume_again         \t0.2303\n",
      "2018-11-20 00:28:32,239 [INFO] ---------------------------------------------------\n",
      "2018-11-20 00:28:32,241 [INFO] 【tfidf -> DummyStratified】: 0.2485\n",
      "2018-11-20 00:28:32,242 [INFO] ---------------------------------------------------\n",
      "2018-11-20 00:28:32,243 [INFO] Train for tfidf -> DummyMostFrequent...\n",
      "2018-11-20 00:28:32,280 [INFO] [Validate]: F1 Scores\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "2018-11-20 00:28:32,283 [INFO]   location_traffic_convenience            \t0.2192\n",
      "2018-11-20 00:28:32,287 [INFO]   location_distance_from_business_district\t0.2218\n",
      "2018-11-20 00:28:32,291 [INFO]   location_easy_to_find                   \t0.2160\n",
      "2018-11-20 00:28:32,297 [INFO]   service_wait_time                       \t0.2353\n",
      "2018-11-20 00:28:32,301 [INFO]   service_waiters_attitude                \t0.1448\n",
      "2018-11-20 00:28:32,303 [INFO]   service_parking_convenience             \t0.2421\n",
      "2018-11-20 00:28:32,306 [INFO]   service_serving_speed                   \t0.2285\n",
      "2018-11-20 00:28:32,309 [INFO]   price_level                             \t0.1652\n",
      "2018-11-20 00:28:32,315 [INFO]   price_cost_effective                    \t0.2158\n",
      "2018-11-20 00:28:32,320 [INFO]   price_discount                          \t0.1894\n",
      "2018-11-20 00:28:32,324 [INFO]   environment_decoration                  \t0.1675\n",
      "2018-11-20 00:28:32,328 [INFO]   environment_noise                       \t0.2034\n",
      "2018-11-20 00:28:32,333 [INFO]   environment_space                       \t0.1905\n",
      "2018-11-20 00:28:32,337 [INFO]   environment_cleaness                    \t0.1912\n",
      "2018-11-20 00:28:32,342 [INFO]   dish_portion                            \t0.1744\n",
      "2018-11-20 00:28:32,345 [INFO]   dish_taste                              \t0.1723\n",
      "2018-11-20 00:28:32,347 [INFO]   dish_look                               \t0.2099\n",
      "2018-11-20 00:28:32,349 [INFO]   dish_recommendation                     \t0.2233\n",
      "2018-11-20 00:28:32,352 [INFO]   others_overall_experience               \t0.1994\n",
      "2018-11-20 00:28:32,355 [INFO]   others_willing_to_consume_again         \t0.1907\n",
      "2018-11-20 00:28:32,357 [INFO] ---------------------------------------------------\n",
      "2018-11-20 00:28:32,358 [INFO] 【tfidf -> DummyMostFrequent】: 0.2000\n",
      "2018-11-20 00:28:32,360 [INFO] ---------------------------------------------------\n",
      "2018-11-20 00:28:32,364 [INFO] ======== Feature Model: tfidf =========\n",
      "2018-11-20 00:28:32,365 [INFO] Train for tfidf -> MultinomialNB...\n",
      "2018-11-20 00:28:32,679 [INFO] [Validate]: F1 Scores\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "2018-11-20 00:28:32,681 [INFO]   location_traffic_convenience            \t0.3284\n",
      "2018-11-20 00:28:32,683 [INFO]   location_distance_from_business_district\t0.2394\n",
      "2018-11-20 00:28:32,685 [INFO]   location_easy_to_find                   \t0.3079\n",
      "2018-11-20 00:28:32,687 [INFO]   service_wait_time                       \t0.2353\n",
      "2018-11-20 00:28:32,689 [INFO]   service_waiters_attitude                \t0.4577\n",
      "2018-11-20 00:28:32,691 [INFO]   service_parking_convenience             \t0.2421\n",
      "2018-11-20 00:28:32,693 [INFO]   service_serving_speed                   \t0.2673\n",
      "2018-11-20 00:28:32,696 [INFO]   price_level                             \t0.2697\n",
      "2018-11-20 00:28:32,698 [INFO]   price_cost_effective                    \t0.2280\n",
      "2018-11-20 00:28:32,700 [INFO]   price_discount                          \t0.3241\n",
      "2018-11-20 00:28:32,702 [INFO]   environment_decoration                  \t0.3505\n",
      "2018-11-20 00:28:32,704 [INFO]   environment_noise                       \t0.2464\n",
      "2018-11-20 00:28:32,706 [INFO]   environment_space                       \t0.2459\n",
      "2018-11-20 00:28:32,708 [INFO]   environment_cleaness                    \t0.2795\n",
      "2018-11-20 00:28:32,711 [INFO]   dish_portion                            \t0.2778\n",
      "2018-11-20 00:28:32,713 [INFO]   dish_taste                              \t0.3549\n",
      "2018-11-20 00:28:32,716 [INFO]   dish_look                               \t0.2326\n",
      "2018-11-20 00:28:32,723 [INFO]   dish_recommendation                     \t0.2233\n",
      "2018-11-20 00:28:32,728 [INFO]   others_overall_experience               \t0.3193\n",
      "2018-11-20 00:28:32,731 [INFO]   others_willing_to_consume_again         \t0.2724\n",
      "2018-11-20 00:28:32,733 [INFO] ---------------------------------------------------\n",
      "2018-11-20 00:28:32,735 [INFO] 【tfidf -> MultinomialNB】: 0.2851\n",
      "2018-11-20 00:28:32,737 [INFO] ---------------------------------------------------\n",
      "2018-11-20 00:28:32,738 [INFO] Train for tfidf -> ComplementNB...\n",
      "2018-11-20 00:28:33,098 [INFO] [Validate]: F1 Scores\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "2018-11-20 00:28:33,100 [INFO]   location_traffic_convenience            \t0.3758\n",
      "2018-11-20 00:28:33,103 [INFO]   location_distance_from_business_district\t0.3168\n",
      "2018-11-20 00:28:33,105 [INFO]   location_easy_to_find                   \t0.3662\n",
      "2018-11-20 00:28:33,107 [INFO]   service_wait_time                       \t0.3977\n",
      "2018-11-20 00:28:33,109 [INFO]   service_waiters_attitude                \t0.4717\n",
      "2018-11-20 00:28:33,111 [INFO]   service_parking_convenience             \t0.3088\n",
      "2018-11-20 00:28:33,113 [INFO]   service_serving_speed                   \t0.4444\n",
      "2018-11-20 00:28:33,116 [INFO]   price_level                             \t0.5098\n",
      "2018-11-20 00:28:33,118 [INFO]   price_cost_effective                    \t0.4290\n",
      "2018-11-20 00:28:33,120 [INFO]   price_discount                          \t0.4444\n",
      "2018-11-20 00:28:33,122 [INFO]   environment_decoration                  \t0.3823\n",
      "2018-11-20 00:28:33,124 [INFO]   environment_noise                       \t0.4175\n",
      "2018-11-20 00:28:33,127 [INFO]   environment_space                       \t0.4502\n",
      "2018-11-20 00:28:33,129 [INFO]   environment_cleaness                    \t0.3995\n",
      "2018-11-20 00:28:33,131 [INFO]   dish_portion                            \t0.3850\n",
      "2018-11-20 00:28:33,133 [INFO]   dish_taste                              \t0.4954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-20 00:28:33,135 [INFO]   dish_look                               \t0.3417\n",
      "2018-11-20 00:28:33,138 [INFO]   dish_recommendation                     \t0.3483\n",
      "2018-11-20 00:28:33,140 [INFO]   others_overall_experience               \t0.4336\n",
      "2018-11-20 00:28:33,143 [INFO]   others_willing_to_consume_again         \t0.4220\n",
      "2018-11-20 00:28:33,144 [INFO] ---------------------------------------------------\n",
      "2018-11-20 00:28:33,148 [INFO] 【tfidf -> ComplementNB】: 0.4070\n",
      "2018-11-20 00:28:33,150 [INFO] ---------------------------------------------------\n",
      "2018-11-20 00:28:33,152 [INFO] ======== Feature Model: tfidf_sv =========\n",
      "2018-11-20 00:28:33,155 [INFO] Train for tfidf_sv -> MultinomialNB...\n",
      "2018-11-20 00:28:33,536 [INFO] [Validate]: F1 Scores\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "2018-11-20 00:28:33,539 [INFO]   location_traffic_convenience            \t0.3315\n",
      "2018-11-20 00:28:33,541 [INFO]   location_distance_from_business_district\t0.2434\n",
      "2018-11-20 00:28:33,544 [INFO]   location_easy_to_find                   \t0.3108\n",
      "2018-11-20 00:28:33,546 [INFO]   service_wait_time                       \t0.2353\n",
      "2018-11-20 00:28:33,549 [INFO]   service_waiters_attitude                \t0.4591\n",
      "2018-11-20 00:28:33,551 [INFO]   service_parking_convenience             \t0.2421\n",
      "2018-11-20 00:28:33,554 [INFO]   service_serving_speed                   \t0.2712\n",
      "2018-11-20 00:28:33,557 [INFO]   price_level                             \t0.2777\n",
      "2018-11-20 00:28:33,563 [INFO]   price_cost_effective                    \t0.2301\n",
      "2018-11-20 00:28:33,567 [INFO]   price_discount                          \t0.3325\n",
      "2018-11-20 00:28:33,570 [INFO]   environment_decoration                  \t0.3520\n",
      "2018-11-20 00:28:33,578 [INFO]   environment_noise                       \t0.2463\n",
      "2018-11-20 00:28:33,580 [INFO]   environment_space                       \t0.2502\n",
      "2018-11-20 00:28:33,583 [INFO]   environment_cleaness                    \t0.2822\n",
      "2018-11-20 00:28:33,586 [INFO]   dish_portion                            \t0.2805\n",
      "2018-11-20 00:28:33,590 [INFO]   dish_taste                              \t0.3551\n",
      "2018-11-20 00:28:33,597 [INFO]   dish_look                               \t0.2321\n",
      "2018-11-20 00:28:33,603 [INFO]   dish_recommendation                     \t0.2233\n",
      "2018-11-20 00:28:33,606 [INFO]   others_overall_experience               \t0.3321\n",
      "2018-11-20 00:28:33,612 [INFO]   others_willing_to_consume_again         \t0.2758\n",
      "2018-11-20 00:28:33,613 [INFO] ---------------------------------------------------\n",
      "2018-11-20 00:28:33,614 [INFO] 【tfidf_sv -> MultinomialNB】: 0.2882\n",
      "2018-11-20 00:28:33,616 [INFO] ---------------------------------------------------\n",
      "2018-11-20 00:28:33,617 [INFO] Train for tfidf_sv -> ComplementNB...\n",
      "2018-11-20 00:28:33,940 [INFO] [Validate]: F1 Scores\n",
      "2018-11-20 00:28:33,942 [INFO]   location_traffic_convenience            \t0.3757\n",
      "2018-11-20 00:28:33,945 [INFO]   location_distance_from_business_district\t0.3180\n",
      "2018-11-20 00:28:33,947 [INFO]   location_easy_to_find                   \t0.3610\n",
      "2018-11-20 00:28:33,950 [INFO]   service_wait_time                       \t0.3970\n",
      "2018-11-20 00:28:33,952 [INFO]   service_waiters_attitude                \t0.4713\n",
      "2018-11-20 00:28:33,955 [INFO]   service_parking_convenience             \t0.3044\n",
      "2018-11-20 00:28:33,957 [INFO]   service_serving_speed                   \t0.4393\n",
      "2018-11-20 00:28:33,960 [INFO]   price_level                             \t0.5081\n",
      "2018-11-20 00:28:33,963 [INFO]   price_cost_effective                    \t0.4290\n",
      "2018-11-20 00:28:33,965 [INFO]   price_discount                          \t0.4444\n",
      "2018-11-20 00:28:33,971 [INFO]   environment_decoration                  \t0.3799\n",
      "2018-11-20 00:28:33,975 [INFO]   environment_noise                       \t0.4177\n",
      "2018-11-20 00:28:33,979 [INFO]   environment_space                       \t0.4495\n",
      "2018-11-20 00:28:33,983 [INFO]   environment_cleaness                    \t0.4003\n",
      "2018-11-20 00:28:33,986 [INFO]   dish_portion                            \t0.3848\n",
      "2018-11-20 00:28:33,989 [INFO]   dish_taste                              \t0.4945\n",
      "2018-11-20 00:28:33,992 [INFO]   dish_look                               \t0.3406\n",
      "2018-11-20 00:28:33,995 [INFO]   dish_recommendation                     \t0.3497\n",
      "2018-11-20 00:28:33,998 [INFO]   others_overall_experience               \t0.4329\n",
      "2018-11-20 00:28:34,001 [INFO]   others_willing_to_consume_again         \t0.4206\n",
      "2018-11-20 00:28:34,002 [INFO] ---------------------------------------------------\n",
      "2018-11-20 00:28:34,004 [INFO] 【tfidf_sv -> ComplementNB】: 0.4059\n",
      "2018-11-20 00:28:34,005 [INFO] ---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from collections import defaultdict\n",
    "from fgclassifier.baseline import logger\n",
    "from fgclassifier.features import FeaturePipeline, SparseToSense\n",
    "from fgclassifier.features import LatentDirichletAllocation, SVD\n",
    "from fgclassifier import classifiers\n",
    "\n",
    "def fm_cross_check(fmns, clss):\n",
    "    \"\"\"Feature Model Cross Check\"\"\"\n",
    "    # Test for all Feature models\n",
    "    for fmn in fmns:\n",
    "        logger.info(f'======== Feature Model: {fmn} =========')\n",
    "        cache = fm[fmn]\n",
    "        Xtrain, Xtest = cache['train'], cache['test']\n",
    "        # Test on all major classifiers\n",
    "        for cls in clss:\n",
    "            logger.info(f'Train for {fmn} -> {cls}...')\n",
    "            Classifier = getattr(classifiers, cls)\n",
    "            model = Baseline(name=cls, classifier=Classifier)\n",
    "            model.fit(Xtrain, y_train)\n",
    "            all_scores[fmn][cls] = model.scores(Xtest, y_test)\n",
    "            f1 = all_avg_scores[fmn][cls] = np.mean(all_scores[fmn][cls])\n",
    "            logger.info('---------------------------------------------------')\n",
    "            logger.info(f'【{fmn} -> {cls}】: {f1:.4f}')\n",
    "            logger.info('---------------------------------------------------')\n",
    "            \n",
    "\n",
    "# We'd only need to run the dummy models on one feature model,\n",
    "# as they do not care about the features\n",
    "fm_cross_check(\n",
    "    ['tfidf'],\n",
    "    ['DummyStratified', 'DummyMostFrequent']\n",
    ")\n",
    "\n",
    "# Naive Bayes models cannot handle negative values, so we pass\n",
    "# in only tfidf features\n",
    "fm_cross_check(\n",
    "    ['tfidf', 'tfidf_sv'],\n",
    "    ['MultinomialNB', 'ComplementNB']\n",
    ")\n",
    "\n",
    "# All other models can run on many classifiers\n",
    "fm_cross_check(\n",
    "    ['lsa_100', 'lsa_1k',\n",
    "     'lda_count_100', 'lda_count_200',\n",
    "     'lda_tfidf_100', 'lda_tfidf_200',\n",
    "     'lsa_100_sv', 'lsa_1k_sv',\n",
    "     'lda_count_100_sv', 'lda_count_200_sv',\n",
    "     'lda_tfidf_100_sv', 'lda_tfidf_200_sv',\n",
    "    ],\n",
    "    \n",
    "    ['LDA', 'LinearSVC', 'Logistic', 'Ridge', 'ExtraTree']\n",
    ")\n",
    "\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'tfidf': {'DummyStratified': 0.24850453508887155,\n",
       "              'DummyMostFrequent': 0.20004133859221804,\n",
       "              'MultinomialNB': 0.2851317119840156,\n",
       "              'ComplementNB': 0.4070130652449275},\n",
       "             'tfidf_sv': {'MultinomialNB': 0.2881810332309514,\n",
       "              'ComplementNB': 0.40593509859996635},\n",
       "             'lsa_100': {'LDA': 0.37994477253680514,\n",
       "              'LinearSVC': 0.3380442087162074,\n",
       "              'Logistic': 0.33412824892379456,\n",
       "              'Ridge': 0.323475620903369,\n",
       "              'ExtraTree': 0.2193105117571359},\n",
       "             'lsa_1k': {'LDA': 0.4672456343211369,\n",
       "              'LinearSVC': 0.4170892428737959,\n",
       "              'Logistic': 0.37443974704251676,\n",
       "              'Ridge': 0.363214429438162,\n",
       "              'ExtraTree': 0.20935807927874767},\n",
       "             'lda_count_100': {'LDA': 0.3205497662606225,\n",
       "              'LinearSVC': 0.2849517453749279,\n",
       "              'Logistic': 0.27708563669736763,\n",
       "              'Ridge': 0.275476372671412,\n",
       "              'ExtraTree': 0.2187186587826781},\n",
       "             'lda_count_200': {'LDA': 0.3291370384392787,\n",
       "              'LinearSVC': 0.2905665575452426,\n",
       "              'Logistic': 0.2710691119786636,\n",
       "              'Ridge': 0.2791576694279281,\n",
       "              'ExtraTree': 0.21649036192831828},\n",
       "             'lda_tfidf_100': {'LDA': 0.24308912265450858,\n",
       "              'LinearSVC': 0.22034137100883905,\n",
       "              'Logistic': 0.22096340954110216,\n",
       "              'Ridge': 0.22817693051727214,\n",
       "              'ExtraTree': 0.22455623393137558},\n",
       "             'lda_tfidf_200': {'LDA': 0.2365137242458435,\n",
       "              'LinearSVC': 0.21363196983630348,\n",
       "              'Logistic': 0.2107186643046442,\n",
       "              'Ridge': 0.22274987901724605,\n",
       "              'ExtraTree': 0.22326892294935607},\n",
       "             'lsa_100_sv': {'LDA': 0.38088340956988975,\n",
       "              'LinearSVC': 0.33773708959883353,\n",
       "              'Logistic': 0.3328999945068516,\n",
       "              'Ridge': 0.32228474915187705,\n",
       "              'ExtraTree': 0.2189411225161419},\n",
       "             'lsa_1k_sv': {'LDA': 0.4663261716929785,\n",
       "              'LinearSVC': 0.4168929190846569,\n",
       "              'Logistic': 0.376873490453722,\n",
       "              'Ridge': 0.3618032074436066,\n",
       "              'ExtraTree': 0.2096531701942284},\n",
       "             'lda_count_100_sv': {'LDA': 0.3090442836397822,\n",
       "              'LinearSVC': 0.28064642773076415,\n",
       "              'Logistic': 0.27314967022318587,\n",
       "              'Ridge': 0.27353101610908076,\n",
       "              'ExtraTree': 0.21813145813586768},\n",
       "             'lda_count_200_sv': {'LDA': 0.3239420193228036,\n",
       "              'LinearSVC': 0.2964080586907992,\n",
       "              'Logistic': 0.2751261914039494,\n",
       "              'Ridge': 0.28309477868355604,\n",
       "              'ExtraTree': 0.2149564509175829},\n",
       "             'lda_tfidf_100_sv': {'LDA': 0.22773732148887738,\n",
       "              'LinearSVC': 0.21334016925133464,\n",
       "              'Logistic': 0.21311557181784413,\n",
       "              'Ridge': 0.2203943362598879,\n",
       "              'ExtraTree': 0.22283549051091756},\n",
       "             'lda_tfidf_200_sv': {'LDA': 0.24564374794589255,\n",
       "              'LinearSVC': 0.21209037057297558,\n",
       "              'Logistic': 0.20611585466570342,\n",
       "              'Ridge': 0.22822614762252913,\n",
       "              'ExtraTree': 0.2220698453436364}})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_avg_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- `ComplementNB` performs much better than a simple MultinomialNB, because our class labels are mostly unbalanced.\n",
    "- `LatentDirichletAllocation` topics as features are not suitable for our classification problem, as features are often collinear. They often fare no better than the dummy classifier where we simply return the most frequent labels.\n",
    "- LSA (Latent Semantic Analysis) shows a much more promising outcome, especially when combined with Linear Discriminant Analysis or SVC.\n",
    "- A smaller vocabulary had marginal impact on the performance, what matters more is the number of SVD components in LSA. The higher the better, as more compoents will capture more information. LDA and SVC both perform well in high dimensional space.\n",
    "- Basically SVD makes each feature (component) more indendent with each other, making LDA and SVC easier to come up with good fittings.\n",
    "- Tree based models are not particularly useful. But the results may be different had we tuned the tree structure more.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Tune hyperparamters for `ComplementNB`, `TruncatedSVD`, `LinearDiscriminantAnalysis` and `SVC`/`LinearSVC`. Try different kernel functions.\n",
    "- Test some boosting methods, especially [xgboost](https://xgboost.readthedocs.io/en/latest/).\n",
    "- Possibly use different classifier for different labels.\n",
    "- Test two step predictions: first run binary prediction for \"mentioned\" vs \"not mentioned\", i.e., -2 vs (-1, 0, 1), then predict (-1, 0, 1).\n",
    "    - This could happen as either [ClassifierChain](https://scikit-learn.org/stable/modules/multiclass.html#classifierchain) or separate steps.\n",
    "- Test word embedding as features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
