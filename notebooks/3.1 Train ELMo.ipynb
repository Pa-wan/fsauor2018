{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use [ELMo](https://allennlp.org/elmo), we can either use the [pre-trained models](https://github.com/HIT-SCIR/ELMoForManyLangs), or train a set of word representations of our own.\n",
    "\n",
    "This notebook shows how to do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "2018-11-15 19:54:52,426 DEBUG: Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/6r/772b4sy16rg94jhq1fskv9fc0000gn/T/jieba.cache\n",
      "2018-11-15 19:54:53,624 DEBUG: Dumping model to file cache /var/folders/6r/772b4sy16rg94jhq1fskv9fc0000gn/T/jieba.cache\n",
      "Loading model cost 1.294 seconds.\n",
      "2018-11-15 19:54:53,723 DEBUG: Loading model cost 1.294 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "2018-11-15 19:54:53,725 DEBUG: Prefix dict has been built succesfully.\n",
      "2018-11-15 19:54:53,728 INFO: Read cache data/train/sentiment_analysis_trainingset.csv.segged_sample_None.tsv..\n",
      "2018-11-15 19:54:56,978 INFO: Read cache data/validate/sentiment_analysis_validationset.csv.segged_sample_None.tsv..\n",
      "2018-11-15 19:54:57,496 INFO: Read cache data/test-a/sentiment_analysis_testa.csv.segged_sample_None.tsv..\n",
      "2018-11-15 19:54:57,874 INFO: Read cache data/test-b/sentiment_analysis_testb.csv.segged_sample_None.tsv..\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from config import validate_data_path, train_data_path, testa_data_path, testb_data_path\n",
    "from fgclassifier.utils import read_csv\n",
    "from fgclassifier.embedding import count_to_corpus\n",
    "\n",
    "# read_csv reads by default the tokenized text\n",
    "df_train = read_csv(train_data_path)\n",
    "df_valid = read_csv(validate_data_path)\n",
    "df_testa = read_csv(testa_data_path)\n",
    "df_testb = read_csv(testb_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "吼吼 吼 ， 萌死 人 的 棒棒糖 ， 中 了 大众 点评 的 霸王餐 ， 太 可爱 了\n",
      "一直 就 好奇 这个 棒棒糖 是 怎么 个 东西 ， 大众 点评 给 了 我 这个 土老冒 一个 见识 的 机会\n",
      "看 介绍 棒棒糖 是 用 德国 糖 做 的 ， 不会 很甜 ， 中间 的 照片 是 糯米 的 ， 能 食用 ， 真是太 高端 大气 上档次 了 ， 还 可以 买 蝴蝶结 扎口 ， 送人 可以 买 礼盒\n",
      "我 是 先 打 的 卖家 电话 ， 加 了 微信 ， 给 卖家 传 的 照片\n",
      "等 了 几天 ， 卖家 就 告诉 我 可以 取货 了 ， 去 大官 屯 那取 的\n",
      "虽然 连 卖家 的 面 都 没 见到 ， 但是 还是 谢谢 卖家 送 我 这么 可爱 的 东西 ， 太 喜欢 了 ， 这 哪 舍得吃 啊\n",
      "第三次 参加 大众 点评 网 霸王餐 的 活动\n",
      "这家 店 给 人 整体 感觉 一般\n",
      "首先 环境 只能 算 中等 ， 其次 霸王餐 提供 的 菜品 也 不是 很多 ， 当然 商家 为了 避免 参加 霸王餐 吃不饱 的 现象 ， 给 每桌 都 提供 了 至少 六份 主食 ， 我们 那桌 都 提供 了 两份 年糕 ， 第一次 吃火锅 会 在 桌上 有 这么 多 的 主食 了\n",
      "整体 来说 这家 火锅店 没有 什么 特别 有 特色 的 ， 不过 每份 菜品 分量 还是 比较 足 的 ， 这点 要 肯定 ！ 至于 价格 ， 因为 没有 看 菜单 不 了解 ， 不过 我 看 大众 有 这家 店 的 团购 代金券 ， 相当于 7 折 ， 应该 价位 不会 很 高 的 ！ 最后 还是 要 感谢 商家 提供 霸王餐 ， 祝 生意兴隆 ， 财源 广进\n"
     ]
    }
   ],
   "source": [
    "content_to_corpus(df_train, 'data/text_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_to_corpus(df_train.sample(1000, random_state=1),\n",
    "                  'data/text_train_10k.txt', print_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "哎 ， 想当年 来 佘山 的 时候 ， 啥 都 没有 ， 三品 香算 镇上 最大 看起来 最 像样 的 饭店 了\n",
      "菜品 多 ， 有点 太 多 ， 感觉 啥 都 有 ， 杂都 不足以 形容\n",
      "随便 点些 ， 居然 口味 什么 的 都 好 还 可以 ， 价钱 自然 是 便宜 当 震惊\n",
      "元宝 虾 和 椒盐 九肚鱼 都 不错 吃\n",
      "不过 近来 几次 么 ， 味道 明显 没 以前 好 了\n",
      "冷餐 里面 一个 凉拌 海带丝 还 可以 ， 酸酸甜甜 的\n",
      "镇上 也 有 了 些 别的 大点 的 饭店 ， 所以 不是 每次 必来 了\n",
      "对 了 ， 这家 的 生意 一如既往 的 超级 好 ， 不 定位 基本 吃 不到\n",
      "不过 佘山 这边 的 人 吃晚饭 很早 的 ， 所以 稍微 晚点 去 就 很 空 了\n",
      "趁着 国庆节 ， 一家人 在 白天 在 山里 玩耍 之后 ， 晚上 决定 吃 李记 搅团\n"
     ]
    }
   ],
   "source": [
    "content_to_corpus(df_valid, 'data/text_valid.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 想 说 他们 家 的 优惠活动 好 持久 啊 ， 我 预售 的 时候 买 的 券 ， 前两天 心血来潮 去 吃 的 活动 还 在 继续\n",
      "首先 说 下 服务 ， 因为 和 男票 开车 去 的 ， 有点 不 认路 ， 老板 很 耐心 的 在 电话 里 帮 我们 指路 ， 到 了 门店 之后 也 帮 我们 推荐 了 他们 家 做 的 比较 地道 的 伤心 凉粉 ， 说 是 厨师 是 四川 那边 来 的\n",
      "环境 呢 比较简单 干净 ， 去 的 时候 下午 一点多 了 ， 还有 四五桌 人 在 用餐\n",
      "口味 对于 我 而言 点 了 麻辣 的 口感 正 正好 ， 男票 比较 能 吃 辣 ， 相对而言 觉得 他们 家 的 麻辣 口感 麻有 了 ， 辣 还 欠缺 一点 ， 老板娘 说 考虑 到 客人 口味 不同 所以 没敢 放太多 辣椒 ， 能 吃 辣 的 朋友 可以 考虑 下单 之前 和 老板 先 说好\n",
      "鱼 呢 我们 选 的 是 黑鱼 ， 2.9 斤 的 鱼 加上 一盆 我 以为 没有 什么 东西 实际上 东西 很多 的 锅底 ， 我们 吃 的 饱饱 的 ， 最后 以为 吃 的 差不多 了 ， 打包 一看 简直 像 没动 过 一样 ， 分量 还是 满足 的 ， 鱼 比较 新鲜\n",
      "伤心 凉粉 很辣 ， 不过 口味 也 蛮 好吃 的\n",
      "总的来说 ， 性价比 还是 可以 的 ， 两个 人 吃 了 大概 160 左右 ， 用 了 团购 券 的话 一百块 不到 ， 会 考虑 下次 再 来\n",
      "终于 开 到 心心念念 的 LAB BBLANKK loft\n",
      "第一次 来 就 随便 点 也 一些 ～ 【 香辣虾 意 面 】 蛮辣 的 ， 但 其实 一般般\n",
      "【 玛格丽特 】 进口 的 感觉 蛮 好 的 就是 喝完 后 就 点 呛 ～ 但是 朋友 不是 很 喜欢 【 一柱擎天 】 看 点评 很多 人 说 喜欢 就 点 了 ， 水蜜桃 味 ， 还 不错 挺 好喝 的 ～ 赞 【 海鲜 饭 】 想 吃饭 但 这店 的 饭类 只有 两种 ， 就 点 了 这个\n"
     ]
    }
   ],
   "source": [
    "content_to_corpus(df_testa, 'data/text_testa.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "可以 说 工作日 中午 的 这个 套餐 着实 是 特别 的 实惠 啊 ， 店家 给 的 量 也 是 大大的 足 ！ 首先 如图 ， 每个 菜品 摆盘 都 很 精美 ， 让 人 一 看 就 充满 食欲\n",
      "土豆泥 口味 很棒 ， 甜 酱油 、 鱼籽 和 沙拉酱 的 搭配 非常 完美\n",
      "三文鱼 很 新鲜 ， 切得 得 好 厚 啊 ， 吃 起来 非常 满足 ！ 猪排 饭上 的 实在 有点 慢 了 ， 至少 等 了 20 分钟 ， 但量 超级 大 ， 上面 是 又 大 又 厚 的 炸 猪排 ， 不 知道 是不是 做好 了 没有 及时 给 上 ， 猪排 已经 被 酱汁 泡得变 湿软 了 ， 没有 了 酥脆 感\n",
      "这个 套餐 店家 真的 是 满满的 诚意 啊 ， 估计 一般 人 真的 吃不完\n",
      "位置 很 不错 ， 老板 眼光 很 好 👍\n",
      "位于 地铁站 附近 ， 周围 有 办公楼 、 商圈 、 住宅 、 别墅 虽然 现在 还 有些 荒凉 ， 但 我 想 很快 会 发展 起来 的 💪\n",
      "餐厅 内部 的 环境 还 算 干净 温馨\n",
      "服务员 也 很 热情 亲切\n",
      "姜油大 芥菜 ： 首先 看到 觉得 略微 粗旷 了 些 ， 但 吃 起来 味道 不错 ， 姜丝 没有 很 浓重 的 味道\n",
      "香煎海 鲈鱼 ： 特别 酥脆 鲜香 好吃 😋\n"
     ]
    }
   ],
   "source": [
    "content_to_corpus(df_testb, 'data/text_testb.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2896571 76231079 412681013 data/text_all.txt\r\n"
     ]
    }
   ],
   "source": [
    "!cat data/text_train.txt data/text_valid.txt data/text_testa.txt data/text_testb.txt > data/text_all.txt\n",
    "!wc data/text_all.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All dataset combined has 76 million words, which is too many. According to [ELMoForManyLangs](https://github.com/HIT-SCIR/ELMoForManyLangs), it would take 3 days to train 20m words on an NVIDIA P100 GPU.\n",
    "\n",
    "We must sample the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   82727 2255688 12200210 data/text_train_10k.txt\r\n"
     ]
    }
   ],
   "source": [
    "!wc data/text_train_10k.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random sample of 10,000 reviews gives about 83k sentences, and 2.2m words.\n",
    "It should take probably 8 hours to train the embedings from the 10,000 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "店里 冰淇淋 有 12 个 口味 的 ~\r\n",
      "除了 冰淇淋 ~ 甜品 饮料 也 有 ~ 看 电影 前 可以 来 这里 等 ~ 也 可以 买 进去 吃 哈 ~\r\n",
      "# 枫树 胡桃 # BBLANKK\r\n",
      "店员 妹子 挖 完 冰淇淋 还 帮 我 称 了 一下 ~ 说 他们 家 的 单球 是 60g ~\r\n",
      "味道 很 好 啊 ~ 奶味算重 的 了 ~ 也 不会 很甜 ~ 里面 有 核桃仁 ~ 核桃仁 也 好吃 ~\r\n",
      "一个 球挺 多 的 ~ 吃 着 绝对 够 了 ~\r\n",
      "不过 原价 有点 小贵 ~ M 团有 团购 能 便宜 一点 ~\r\n",
      "总体 很 满意 的 ~ 以后 想 吃 冰淇淋 可以 来 这家 ~ 再 吃 吃 别的 味 ~\r\n",
      "极食 urban BBLANKK harvest 是 一个 走 自然 环保 高端 线路 的 餐厅 ， 位于 杭州 大厦 D座 5 楼 ～ 光看 地标 也 是 够 逼格 了 一进 门口 装饰 有 微型 田园 BBLANKK 看上去 食材 都 新鲜 的 不要 不要 的 ～ 给 创意 一个 赞 BBLANKK 只要 菜单 上 有 “ 即 摘 ” 字眼 的 ， 都 由 服务员 现场 采摘 取用 ， 菜色 摆盘 精致 而且 色彩 丰富 ， 让 人 食欲 大开 ， 口味 都 还 不错 ～ 不过 本人 本 就 不是 一个 太 挑食 的 人 啦 饭后 上 了 甜品 ， 好吃 到 飞 起来 ， 吃 得 愉快 心情 就 好好 ， 尤其 是 这样 一个 周末\r\n",
      "因为 价格 偏贵 的 缘故 ， 如此 黄金地段 、 高峰 时间 用餐 人 倒 不 多 ， 这 也 保证 了 用餐 环境 的 舒适度 ， 还有 一个 好消息 就是 ： 开业 初期 有 七折 优惠 哦 ！ 大家 赶紧 去 拔草 吧\r\n"
     ]
    }
   ],
   "source": [
    "!tail data/text_train_10k.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Let's try a very small subset just to make sure the software works.\n",
    "\n",
    "Use 1000 sentences as training and 100 sentences as validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1000   27705  150876 data/text_train_1ks.txt\n",
      "     100    2729   14924 data/text_train_100s.txt\n"
     ]
    }
   ],
   "source": [
    "# !shuf -n 10000 data/all_text.txt > data/little_text.txt\n",
    "# Use `gshuf` on Mac\n",
    "!gshuf -n 1000 data/text_train.txt > data/text_train_1ks.txt\n",
    "!gshuf -n 100 data/text_train.txt > data/text_train_100s.txt\n",
    "!wc data/text_train_1ks.txt\n",
    "!wc data/text_train_100s.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, clip_grad=5.0, config_path='/Users/jesse/workspace/ML/fine-grain-sentiment-analysis/misc/elmo/cnn_50_100_512_4096_sample.json', eval_steps=10000, gpu=0, lr=0.001, lr_decay=0.8, max_epoch=10, max_sent_len=20, max_vocab_size=150000, min_count=5, model='data/elmo-zhs-1k', optimizer='adam', save_classify_layer=False, seed=1, test_path=None, train_path='data/text_train_100s.txt', valid_path=None, valid_size=10, word_embedding=None)\n",
      "{'encoder': {'name': 'elmo', 'projection_dim': 512, 'cell_clip': 3, 'proj_clip': 3, 'dim': 4096, 'n_layers': 2}, 'token_embedder': {'name': 'cnn', 'activation': 'relu', 'filters': [[1, 32], [2, 32], [3, 64], [4, 128], [5, 256], [6, 512], [7, 1024]], 'n_highway': 2, 'word_dim': 100, 'char_dim': 50, 'max_characters_per_token': 50}, 'classifier': {'name': 'sampled_softmax', 'n_samples': 8192}, 'dropout': 0.1}\n",
      "2018-11-15 03:06:43,847 INFO: training instance: 149, training tokens: 2836.\n",
      "2018-11-15 03:06:43,847 INFO: training instance: 139, training tokens after division: 2646.\n",
      "2018-11-15 03:06:43,847 INFO: valid instance: 10, valid tokens: 190.\n",
      "2018-11-15 03:06:43,850 INFO: Truncated word count: 1359.\n",
      "2018-11-15 03:06:43,850 INFO: Original vocabulary size: 1090.\n",
      "2018-11-15 03:06:43,851 INFO: Word embedding size: 78\n",
      "2018-11-15 03:06:43,853 INFO: Char embedding size: 902\n",
      "2018-11-15 03:06:44,055 INFO: 5 batches, avg len: 20.0\n",
      "2018-11-15 03:06:44,056 INFO: Evaluate every 10000 batches.\n",
      "2018-11-15 03:06:44,067 INFO: 1 batches, avg len: 20.0\n",
      "2018-11-15 03:06:44,067 INFO: vocab size: 78\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "2018-11-15 03:06:49,848 INFO: Model(\n",
      "  (token_embedder): ConvTokenEmbedder(\n",
      "    (word_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(78, 100, padding_idx=3)\n",
      "    )\n",
      "    (char_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(902, 50, padding_idx=899)\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
      "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
      "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
      "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
      "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
      "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
      "    )\n",
      "    (highways): Highway(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
      "  )\n",
      "  (encoder): ElmobiLm(\n",
      "    (forward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (forward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      "  (classify_layer): SampledSoftmaxLayer(\n",
      "    (criterion): CrossEntropyLoss()\n",
      "    (column_emb): Embedding(78, 512)\n",
      "    (column_bias): Embedding(78, 1)\n",
      "  )\n",
      ")\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/elmoformanylangs-0.0.2-py3.6.egg/elmoformanylangs/biLM.py:343: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/elmoformanylangs-0.0.2-py3.6.egg/elmoformanylangs/biLM.py:348: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/elmoformanylangs-0.0.2-py3.6.egg/elmoformanylangs/biLM.py:297: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2018-11-15 03:06:55,393 INFO: Epoch=0 iter=5 lr=0.001000 valid_ppl=72.815895\n",
      "2018-11-15 03:06:55,994 INFO: New record achieved!\n",
      "2018-11-15 03:06:58,477 INFO: Epoch=1 iter=5 lr=0.000800 valid_ppl=38.599525\n",
      "2018-11-15 03:06:59,102 INFO: New record achieved!\n",
      "2018-11-15 03:07:01,467 INFO: Epoch=2 iter=5 lr=0.000640 valid_ppl=14.500859\n",
      "2018-11-15 03:07:02,077 INFO: New record achieved!\n",
      "2018-11-15 03:07:05,598 INFO: Epoch=3 iter=5 lr=0.000512 valid_ppl=11.034621\n",
      "2018-11-15 03:07:06,522 INFO: New record achieved!\n",
      "2018-11-15 03:07:08,950 INFO: Epoch=4 iter=5 lr=0.000410 valid_ppl=11.360459\n",
      "2018-11-15 03:07:11,265 INFO: Epoch=5 iter=5 lr=0.000328 valid_ppl=8.874183\n",
      "2018-11-15 03:07:11,868 INFO: New record achieved!\n",
      "2018-11-15 03:07:14,915 INFO: Epoch=6 iter=5 lr=0.000262 valid_ppl=8.629713\n",
      "2018-11-15 03:07:15,532 INFO: New record achieved!\n",
      "2018-11-15 03:07:17,992 INFO: Epoch=7 iter=5 lr=0.000210 valid_ppl=8.306626\n",
      "2018-11-15 03:07:18,607 INFO: New record achieved!\n",
      "2018-11-15 03:07:20,959 INFO: Epoch=8 iter=5 lr=0.000168 valid_ppl=8.456163\n",
      "2018-11-15 03:07:23,581 INFO: Epoch=9 iter=5 lr=0.000134 valid_ppl=8.405726\n",
      "2018-11-15 03:07:23,584 INFO: best train ppl: 100000000.000000, best valid ppl: 8.306626.\n"
     ]
    }
   ],
   "source": [
    "!python -m elmoformanylangs.biLM train \\\n",
    "    --train_path data/text_train_100s.txt \\\n",
    "    --model data/elmo-zhs-1k \\\n",
    "    --valid_size 10 \\\n",
    "    --config_path `pwd`/misc/elmo/cnn_50_100_512_4096_sample.json \\\n",
    "    --seed 1 \\\n",
    "    --gpu 0 \\\n",
    "    --optimizer adam \\\n",
    "    --lr 0.001 \\\n",
    "    --lr_decay 0.8 \\\n",
    "    --batch_size 32 \\\n",
    "    --clip_grad 5 \\\n",
    "    --max_epoch 10 \\\n",
    "    --max_sent_len 20 \\\n",
    "    --max_vocab_size 150000 \\\n",
    "    --eval_steps 10000 \\\n",
    "    --min_count 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, clip_grad=5.0, config_path='/Users/jesse/workspace/ML/fine-grain-sentiment-analysis/misc/elmo/cnn_50_100_512_4096_sample.json', eval_steps=10000, gpu=0, lr=0.001, lr_decay=0.8, max_epoch=10, max_sent_len=20, max_vocab_size=150000, min_count=5, model='data/elmo-zhs-1k', optimizer='adam', save_classify_layer=False, seed=1, test_path=None, train_path='data/text_train_1k.txt', valid_path='data/text_train_100.txt', valid_size=0, word_embedding=None)\n",
      "{'encoder': {'name': 'elmo', 'projection_dim': 512, 'cell_clip': 3, 'proj_clip': 3, 'dim': 4096, 'n_layers': 2}, 'token_embedder': {'name': 'cnn', 'activation': 'relu', 'filters': [[1, 32], [2, 32], [3, 64], [4, 128], [5, 256], [6, 512], [7, 1024]], 'n_highway': 2, 'word_dim': 100, 'char_dim': 50, 'max_characters_per_token': 50}, 'classifier': {'name': 'sampled_softmax', 'n_samples': 8192}, 'dropout': 0.1}\n",
      "2018-11-14 22:36:57,640 INFO: training instance: 1505, training tokens: 28596.\n",
      "2018-11-14 22:36:57,645 INFO: valid instance: 143, valid tokens: 2705.\n",
      "2018-11-14 22:36:57,675 INFO: Truncated word count: 7085.\n",
      "2018-11-14 22:36:57,676 INFO: Original vocabulary size: 5629.\n",
      "2018-11-14 22:36:57,683 INFO: Word embedding size: 786\n",
      "2018-11-14 22:36:57,704 INFO: Char embedding size: 2140\n",
      "2018-11-14 22:36:59,727 INFO: 48 batches, avg len: 20.0\n",
      "2018-11-14 22:36:59,728 INFO: Evaluate every 10000 batches.\n",
      "2018-11-14 22:37:00,040 INFO: 5 batches, avg len: 19.9\n",
      "2018-11-14 22:37:00,040 INFO: vocab size: 786\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "2018-11-14 22:37:08,984 INFO: Model(\n",
      "  (token_embedder): ConvTokenEmbedder(\n",
      "    (word_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(786, 100, padding_idx=3)\n",
      "    )\n",
      "    (char_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(2140, 50, padding_idx=2137)\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
      "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
      "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
      "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
      "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
      "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
      "    )\n",
      "    (highways): Highway(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
      "  )\n",
      "  (encoder): ElmobiLm(\n",
      "    (forward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (forward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      "  (classify_layer): SampledSoftmaxLayer(\n",
      "    (criterion): CrossEntropyLoss()\n",
      "    (column_emb): Embedding(786, 512)\n",
      "    (column_bias): Embedding(786, 1)\n",
      "  )\n",
      ")\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/elmoformanylangs-0.0.2-py3.6.egg/elmoformanylangs/biLM.py:343: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/elmoformanylangs-0.0.2-py3.6.egg/elmoformanylangs/biLM.py:348: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "2018-11-14 22:37:40,645 INFO: Epoch=0 iter=32 lr=0.001000 train_ppl=72388.250000 time=28.90s\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/elmoformanylangs-0.0.2-py3.6.egg/elmoformanylangs/biLM.py:297: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2018-11-14 22:37:56,929 INFO: Epoch=0 iter=48 lr=0.001000 valid_ppl=58.615864\n",
      "2018-11-14 22:37:57,981 INFO: New record achieved!\n",
      "2018-11-14 22:38:24,576 INFO: Epoch=1 iter=32 lr=0.000800 train_ppl=63.343208 time=26.59s\n",
      "2018-11-14 22:38:42,185 INFO: Epoch=1 iter=48 lr=0.000800 valid_ppl=44.460205\n",
      "2018-11-14 22:38:42,798 INFO: New record achieved!\n",
      "2018-11-14 22:39:09,410 INFO: Epoch=2 iter=32 lr=0.000640 train_ppl=52.716682 time=26.61s\n",
      "2018-11-14 22:39:24,734 INFO: Epoch=2 iter=48 lr=0.000640 valid_ppl=41.916843\n",
      "2018-11-14 22:39:25,305 INFO: New record achieved!\n",
      "2018-11-14 22:39:55,008 INFO: Epoch=3 iter=32 lr=0.000512 train_ppl=47.527332 time=29.70s\n",
      "2018-11-14 22:40:11,341 INFO: Epoch=3 iter=48 lr=0.000512 valid_ppl=39.813450\n",
      "2018-11-14 22:40:12,012 INFO: New record achieved!\n",
      "2018-11-14 22:40:38,603 INFO: Epoch=4 iter=32 lr=0.000410 train_ppl=43.219276 time=26.58s\n",
      "2018-11-14 22:40:54,555 INFO: Epoch=4 iter=48 lr=0.000410 valid_ppl=38.112942\n",
      "2018-11-14 22:40:55,184 INFO: New record achieved!\n",
      "2018-11-14 22:41:27,812 INFO: Epoch=5 iter=32 lr=0.000328 train_ppl=40.482231 time=32.62s\n",
      "2018-11-14 22:41:44,222 INFO: Epoch=5 iter=48 lr=0.000328 valid_ppl=37.239307\n",
      "2018-11-14 22:41:44,942 INFO: New record achieved!\n",
      "2018-11-14 22:42:12,696 INFO: Epoch=6 iter=32 lr=0.000262 train_ppl=36.799458 time=27.75s\n",
      "2018-11-14 22:42:29,051 INFO: Epoch=6 iter=48 lr=0.000262 valid_ppl=36.741238\n",
      "2018-11-14 22:42:29,662 INFO: New record achieved!\n",
      "2018-11-14 22:42:58,419 INFO: Epoch=7 iter=32 lr=0.000210 train_ppl=35.172501 time=28.75s\n",
      "2018-11-14 22:43:17,635 INFO: Epoch=7 iter=48 lr=0.000210 valid_ppl=36.912933\n",
      "2018-11-14 22:43:48,403 INFO: Epoch=8 iter=32 lr=0.000168 train_ppl=32.478752 time=30.75s\n",
      "2018-11-14 22:44:03,723 INFO: Epoch=8 iter=48 lr=0.000168 valid_ppl=36.847874\n",
      "2018-11-14 22:44:29,567 INFO: Epoch=9 iter=32 lr=0.000134 train_ppl=31.984341 time=25.84s\n",
      "2018-11-14 22:44:51,497 INFO: Epoch=9 iter=48 lr=0.000134 valid_ppl=37.348961\n",
      "2018-11-14 22:44:51,503 INFO: best train ppl: 100000000.000000, best valid ppl: 36.741238.\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "# add `pwd` to `config_path` because trained model depends on that file\n",
    "# absolute path makes it easier to find\n",
    "!python -m elmoformanylangs.biLM train \\\n",
    "    --train_path data/text_train_1ks.txt \\\n",
    "    --valid_path data/text_train_100s.txt \\\n",
    "    --model data/elmo-zhs-1k \\\n",
    "    --config_path `pwd`/misc/elmo/cnn_50_100_512_4096_sample.json \\\n",
    "    --seed 1 \\\n",
    "    --gpu 0 \\\n",
    "    --optimizer adam \\\n",
    "    --lr 0.001 \\\n",
    "    --lr_decay 0.8 \\\n",
    "    --batch_size 32 \\\n",
    "    --clip_grad 5 \\\n",
    "    --max_epoch 10 \\\n",
    "    --max_sent_len 20 \\\n",
    "    --max_vocab_size 150000 \\\n",
    "    --eval_steps 10000 \\\n",
    "    --min_count 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-14 23:19:31,908 [INFO] Read cache data/train/sentiment_analysis_trainingset.csv.segged_sample_None.tsv..\n"
     ]
    }
   ],
   "source": [
    "df_train = read_csv(train_data_path, seg_words=True, sample_n=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-14 23:21:26,090 [INFO] char embedding size: 8582\n",
      "2018-11-14 23:21:26,861 [INFO] word embedding size: 69827\n",
      "2018-11-14 23:21:34,862 [INFO] Model(\n",
      "  (token_embedder): ConvTokenEmbedder(\n",
      "    (word_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(69827, 100, padding_idx=3)\n",
      "    )\n",
      "    (char_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(8582, 50, padding_idx=8579)\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
      "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
      "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
      "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
      "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
      "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
      "    )\n",
      "    (highways): Highway(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
      "  )\n",
      "  (encoder): ElmobiLm(\n",
      "    (forward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (forward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "2018-11-14 23:21:35,856 [INFO] 1 batches, avg len: 371.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.16197295,  0.05117923, -0.13360588, ...,  0.24924016,\n",
       "         -0.27383432, -0.05000202],\n",
       "        [ 0.06199374,  0.07696173, -0.23577517, ...,  0.26290917,\n",
       "         -0.27809614, -0.06464732],\n",
       "        [ 0.0008731 , -0.04712557, -0.08987609, ..., -0.00968068,\n",
       "         -0.13784361, -0.03070146],\n",
       "        ...,\n",
       "        [-0.27461815,  0.03719755, -0.13428287, ..., -0.06027537,\n",
       "         -0.07961495, -0.14139868],\n",
       "        [-0.06108154,  0.13908525, -0.2571093 , ...,  0.01645198,\n",
       "         -0.02265188, -0.02150639],\n",
       "        [-0.19907278,  0.02419554, -0.19596738, ...,  0.07171986,\n",
       "         -0.01507132,  0.02613006]], dtype=float32),\n",
       " array([[-0.17354196, -0.36698878, -0.04885902, ..., -0.02680009,\n",
       "          0.13608061,  0.12091058],\n",
       "        [-0.29550084, -0.12204532, -0.28084293, ..., -0.29321548,\n",
       "          0.13516046, -0.11846065],\n",
       "        [-0.05146622, -0.19961458,  0.01509347, ...,  0.05483557,\n",
       "         -0.06374971, -0.0203303 ],\n",
       "        ...,\n",
       "        [-0.1181826 ,  0.02767085, -0.35975978, ..., -0.01324531,\n",
       "          0.00909343, -0.03078758],\n",
       "        [-0.0251124 ,  0.20625134, -0.2706751 , ...,  0.09297368,\n",
       "          0.14488776, -0.00088627],\n",
       "        [-0.04889162, -0.19273376, -0.3477179 , ...,  0.0895622 ,\n",
       "          0.04090813,  0.11943939]], dtype=float32)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elmoformanylangs import Embedder\n",
    "\n",
    "elmoemb = Embedder('data/elmo-zhs-fsauor')\n",
    "# e = Embedder('data/elmo-zhs-1k')\n",
    "\n",
    "sents = df_train['content'][0:2]\n",
    "elmoemb.sents2elmo(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now let's train a bigger model.\n",
    "\n",
    "I'm running this on my 16G Macbook.\n",
    "10k reviews (82727 lines) takes about 3G memory.\n",
    "40k reviews (344k lines) take about 6.4G memory.\n",
    "\n",
    "My usable memory is about 10G, which should be able to\n",
    "handle 100K reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这家 店 还 没有 开业 的 时候 就 提前 在 网上 有 售卖 ， 当时 抱 着 不管 吃 不吃 ， 先 抢 两份 的 心态 就 下单 买 了 两份\n",
      "# 开店 到 现在 都 快 大半年 了 ， 一直 都 没有 去 使用 ， 搞 得 都 快 过期 了 ， 今天 家里 又 停水 了 就 想着 过来 把 这个 用 了 吧\n",
      "O ( ∩ _ ∩ ) O 哈哈 ~\n",
      "# 位置 也 还是 蛮 好找 的 就 在 u 频道 的 星光 天地 ， 里面 也 比较 大 比较 安静 ， 哈哈 ， 我们 今天 来 的 似乎 有点 早 ， 店 里面 就 我们 一桌 ！\n",
      "# 把 团购 验证 后 牛排 很快 就 快 就 上来 了 ， 在 老板 的 建议 下要 了 七分 熟 ， 牛排 很嫩 ， 比较 好切 ！\n",
      "# 女儿 不会 切 牛排 老板 还 亲自 上阵 帮 女儿 切 牛排 ， 还 送 了 一个 水杯 给 女儿 ， 真心 为 这个 细心 的 老板 点个 赞\n",
      "… … 吃 完 牛排 旁边 还有 一些 点心 和 水果 、 和 小吃 、 还有 一些 水果 沙拉 ， 自选 的 种类 不是 很多\n",
      "， 但 对 这个 价位 来说 已经 够 了\n",
      "# 推荐 一下 那个 “ 玉米浓汤 ” 很 开胃 的 ， 还有 我 超级 爱 的 “ 红烧 猪蹄 ” 吃 了 好多 呀 ！ 到 最后 真的 是 扶 墙 而 出 O ( ∩ _ ∩ ) O 哈哈 ~\n",
      "# 最后 总的来说 比较 经济 实惠 ， 不错 ！ 而且 服务态度 真心 不错 ！ ！ 下次 有 机会 还会 再 去 的 ， 也 会 推荐 给 朋友 们 … …\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.concat([df_train, df_valid, df_testa, df_testb], axis=0)\n",
    "df_100k = df_all.sample(100000, random_state=1024)\n",
    "content_to_corpus(df_100k, 'data/text_100k.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  864508 22698437 122895547 data/text_100k.txt\r\n"
     ]
    }
   ],
   "source": [
    "!wc data/text_100k.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train the full model\n",
    "!time python -m elmoformanylangs.biLM train \\\n",
    "    --train_path data/text_100k.txt \\\n",
    "    --valid_size 50000 \\\n",
    "    --model data/elmo-zhs-100k \\\n",
    "    --config_path `pwd`/misc/elmo/cnn_50_100_512_4096_sample.json \\\n",
    "    --seed 1 \\\n",
    "    --gpu 0 \\\n",
    "    --optimizer adam \\\n",
    "    --lr 0.001 \\\n",
    "    --lr_decay 0.8 \\\n",
    "    --batch_size 32 \\\n",
    "    --clip_grad 5 \\\n",
    "    --max_epoch 10 \\\n",
    "    --max_sent_len 20 \\\n",
    "    --max_vocab_size 150000 \\\n",
    "    --eval_steps 5000 \\\n",
    "    --min_count 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: /Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/elmoformanylangs-0.0.2-py3.6.egg/elmoformanylangs/biLM.py\r\n",
      "       [-h] [--seed SEED] [--gpu GPU] --train_path TRAIN_PATH\r\n",
      "       [--valid_path VALID_PATH] [--test_path TEST_PATH] --config_path\r\n",
      "       CONFIG_PATH [--word_embedding WORD_EMBEDDING]\r\n",
      "       [--optimizer {sgd,adam,adagrad}] [--lr LR] [--lr_decay LR_DECAY]\r\n",
      "       --model MODEL [--batch_size BATCH_SIZE] [--max_epoch MAX_EPOCH]\r\n",
      "       [--clip_grad CLIP_GRAD] [--max_sent_len MAX_SENT_LEN]\r\n",
      "       [--min_count MIN_COUNT] [--max_vocab_size MAX_VOCAB_SIZE]\r\n",
      "       [--save_classify_layer] [--valid_size VALID_SIZE]\r\n",
      "       [--eval_steps EVAL_STEPS]\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --seed SEED           The random seed.\r\n",
      "  --gpu GPU             Use id of gpu, -1 if cpu.\r\n",
      "  --train_path TRAIN_PATH\r\n",
      "                        The path to the training file.\r\n",
      "  --valid_path VALID_PATH\r\n",
      "                        The path to the development file.\r\n",
      "  --test_path TEST_PATH\r\n",
      "                        The path to the testing file.\r\n",
      "  --config_path CONFIG_PATH\r\n",
      "                        the path to the config file.\r\n",
      "  --word_embedding WORD_EMBEDDING\r\n",
      "                        The path to word vectors.\r\n",
      "  --optimizer {sgd,adam,adagrad}\r\n",
      "                        the type of optimizer: valid options=[sgd, adam,\r\n",
      "                        adagrad]\r\n",
      "  --lr LR               the learning rate.\r\n",
      "  --lr_decay LR_DECAY   the learning rate decay.\r\n",
      "  --model MODEL         path to save model\r\n",
      "  --batch_size BATCH_SIZE, --batch BATCH_SIZE\r\n",
      "                        the batch size.\r\n",
      "  --max_epoch MAX_EPOCH\r\n",
      "                        the maximum number of iteration.\r\n",
      "  --clip_grad CLIP_GRAD\r\n",
      "                        the tense of clipped grad.\r\n",
      "  --max_sent_len MAX_SENT_LEN\r\n",
      "                        maximum sentence length.\r\n",
      "  --min_count MIN_COUNT\r\n",
      "                        minimum word count.\r\n",
      "  --max_vocab_size MAX_VOCAB_SIZE\r\n",
      "                        maximum vocabulary size.\r\n",
      "  --save_classify_layer\r\n",
      "                        whether to save the classify layer\r\n",
      "  --valid_size VALID_SIZE\r\n",
      "                        size of validation dataset when there's no valid.\r\n",
      "  --eval_steps EVAL_STEPS\r\n",
      "                        report every xx batches.\r\n"
     ]
    }
   ],
   "source": [
    "!python -m elmoformanylangs.biLM train -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elmoformanylangs import biLM\n",
    "\n",
    "corpus = biLM.read_corpus('data/text_100k.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_count = Counter()\n",
    "for sentence in corpus:\n",
    "    word_count.update(sentence)\n",
    "\n",
    "word_count = word_count.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check which `min_count` is a reasonable number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166345\n",
      "[('杂鲜', 4), ('刀刀', 4), ('606', 4), ('453', 4), ('Wine', 4), ('水电', 4), ('斯是', 4), ('海洋公园', 4), ('做外', 4), ('这顿餐', 4), ('小堡', 4), ('偶在', 4), ('肝腰', 4), ('嫣色', 4), ('服务项目', 4), ('感足', 4), ('首映', 4), ('蕉芝', 4), ('空到', 4), ('给些', 4), ('大爱椒', 4), ('吴财记', 4), ('陆居路', 4), ('南姜', 4), ('有食', 4), ('試吃', 4), ('鴨掌', 4), ('相間', 4), ('两角', 4), ('红签', 4), ('客隆', 4), ('砍掉', 4), ('会烧', 4), ('用上', 4), ('装碟', 4), ('笔筒', 4), ('元真', 4), ('速八', 4), ('数十', 4), ('两大个', 4), ('七次', 4), ('比百丽店', 4), ('没评', 4), ('凤二店', 4), ('游子', 4), ('现打现', 4), ('较酸', 4), ('酒食', 4), ('宝丽金', 4), ('药筒', 4), ('毛家湾', 4), ('黄梅', 4), ('双椒石', 4), ('找個', 4), ('當晚', 4), ('Christmas', 4), ('勾出', 4), ('葱条', 4), ('腰果仁', 4), ('我变', 4), ('床垫', 4), ('献出', 4), ('全宴', 4), ('各界', 4), ('长不大', 4), ('倩影', 4), ('喜蛋', 4), ('很适', 4), ('缺心眼', 4), ('配上去', 4), ('百桌', 4), ('👶', 4), ('座区', 4), ('维尼熊', 4), ('优乐', 4), ('調配', 4), ('空关', 4), ('银花', 4), ('🎋', 4), ('慢性子', 4), ('塔底', 4), ('一个班', 4), ('晚自习', 4), ('开铺', 4), ('多万', 4), ('洗衣', 4), ('1981', 4), ('圆方', 4), ('九龙湾', 4), ('百福', 4), ('叫作', 4), ('略涩', 4), ('价贵量', 4), ('金坛', 4), ('得脆', 4), ('鐵站', 4), ('數量', 4), ('地少', 4), ('兩樣', 4), ('錯過', 4), ('多线', 4), ('及餐', 4), ('洗脸', 4), ('我到', 4), ('开是', 4), ('加菌', 4), ('新造', 4), ('同學們', 4), ('笋叶', 4), ('金兰', 4), ('灌进', 4), ('甜醋', 4), ('藏不住', 4), ('观澜', 4), ('小兰', 4), ('后盖', 4), ('冷鹅肝', 4), ('小麻巷', 4), ('可玩', 4), ('跟进去', 4), ('会订', 4), ('不订', 4), ('枫镇', 4), ('蓬勃', 4), ('饺是', 4), ('欠考虑', 4), ('没窗', 4), ('接住', 4), ('困了', 4), ('没嚼头', 4), ('粒饭', 4), ('太骚', 4), ('别碰', 4), ('不味', 4), ('姜水', 4), ('五黑', 4), ('花蛤倒', 4), ('怀生记', 4), ('20150904', 4), ('为佳', 4), ('赶潮流', 4), ('木兰', 4), ('入川', 4), ('赫赫', 4), ('神功', 4), ('周总理', 4), ('同煮', 4), ('像鹅肝', 4), ('碧波', 4), ('阳家', 4), ('8.6', 4), ('劲够', 4), ('泪点', 4), ('只多不少', 4), ('猖狂', 4), ('傻呵呵', 4), ('所好', 4), ('加咯', 4), ('方物', 4), ('指到', 4), ('食材外', 4), ('蛮大颗', 4), ('79.9', 4), ('脂肪肝', 4), ('不大上', 4), ('巨油', 4), ('有用吗', 4), ('警示牌', 4), ('半满', 4), ('张包', 4), ('管吃', 4), ('再卷', 4), ('甚于', 4), ('阴郁', 4), ('养得', 4), ('奶会', 4), ('首肯', 4), ('网红风', 4), ('慕斯体', 4), ('小妮子', 4), ('一个亿', 4), ('天气预报', 4), ('要半糖', 4), ('卖不掉', 4), ('聊天记录', 4), ('毫无顾忌', 4), ('May', 4), ('难见', 4), ('会食', 4), ('务实', 4), ('950', 4), ('熟到', 4), ('赏味期', 4), ('完带', 4), ('往过', 4), ('梯队', 4), ('开街', 4), ('鱼凉', 4), ('女娃儿', 4), ('橡筋', 4)]\n"
     ]
    }
   ],
   "source": [
    "max_to_keep = 4\n",
    "\n",
    "for i, x in enumerate(word_count):\n",
    "    if x[1] <= max_to_keep:\n",
    "        break\n",
    "print(len(word_count[i:]))\n",
    "print(word_count[i:i+200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically we emperically check whether the words make sense or relevant to sentiment analysis.\n",
    "If for a cutoff, most words are actual words, then we'll keep it.\n",
    "\n",
    "## Check Word Embedding Performance\n",
    "\n",
    "See `4_Word Embeddings.ipyn`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
