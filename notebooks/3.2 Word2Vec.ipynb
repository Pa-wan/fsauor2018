{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-03 21:02:07,120 [INFO] Reading data/english_train.csv..\n",
      "2018-12-03 21:02:07,384 [INFO] Reading data/english_valid.csv..\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from fgclassifier.utils import read_data, get_dataset\n",
    "\n",
    "X_train, y_train = read_data(get_dataset('train_en'), flavor=None)\n",
    "X_test, y_test = read_data(get_dataset('valid_en'), flavor=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jyyjc\\Anaconda3\\envs\\idp\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "2018-12-03 21:02:13,350 [INFO] 'pattern' package not found; tag filters are not available for English\n",
      "2018-12-03 21:02:13,383 [INFO] Building features for word2vec_en...\n",
      "2018-12-03 21:02:37,467 [INFO] collecting all words and their counts\n",
      "2018-12-03 21:02:37,469 [INFO] PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-12-03 21:02:38,081 [INFO] collected 23515 word types from a corpus of 1877982 raw words and 8000 sentences\n",
      "2018-12-03 21:02:38,083 [INFO] Loading a fresh vocabulary\n",
      "2018-12-03 21:02:38,192 [INFO] effective_min_count=3 retains 10128 unique words (43% of original 23515, drops 13387)\n",
      "2018-12-03 21:02:38,193 [INFO] effective_min_count=3 leaves 1861693 word corpus (99% of original 1877982, drops 16289)\n",
      "2018-12-03 21:02:38,257 [INFO] deleting the raw counts dictionary of 23515 items\n",
      "2018-12-03 21:02:38,261 [INFO] sample=0.001 downsamples 45 most-common words\n",
      "2018-12-03 21:02:38,263 [INFO] downsampling leaves estimated 1291285 word corpus (69.4% of prior 1861693)\n",
      "2018-12-03 21:02:38,343 [INFO] estimated required memory for 10128 words and 400 dimensions: 37473600 bytes\n",
      "2018-12-03 21:02:38,345 [INFO] resetting layer weights\n",
      "2018-12-03 21:02:38,769 [INFO] training model with 3 workers on 10128 vocabulary and 400 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-12-03 21:02:39,784 [INFO] EPOCH 1 - PROGRESS: at 28.32% examples, 360688 words/s, in_qsize 6, out_qsize 0\n",
      "2018-12-03 21:02:40,788 [INFO] EPOCH 1 - PROGRESS: at 54.76% examples, 349061 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-03 21:02:41,790 [INFO] EPOCH 1 - PROGRESS: at 82.15% examples, 349852 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-03 21:02:42,436 [INFO] worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-03 21:02:42,448 [INFO] worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-03 21:02:42,470 [INFO] worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-03 21:02:42,472 [INFO] EPOCH - 1 : training on 1877982 raw words (1291690 effective words) took 3.7s, 349345 effective words/s\n",
      "2018-12-03 21:02:43,511 [INFO] EPOCH 2 - PROGRESS: at 22.38% examples, 281961 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-03 21:02:44,530 [INFO] EPOCH 2 - PROGRESS: at 51.00% examples, 319856 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-03 21:02:45,556 [INFO] EPOCH 2 - PROGRESS: at 75.06% examples, 312491 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-03 21:02:46,369 [INFO] worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-03 21:02:46,388 [INFO] worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-03 21:02:46,390 [INFO] worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-03 21:02:46,392 [INFO] EPOCH - 2 : training on 1877982 raw words (1291355 effective words) took 3.9s, 330240 effective words/s\n",
      "2018-12-03 21:02:47,416 [INFO] EPOCH 3 - PROGRESS: at 20.80% examples, 265230 words/s, in_qsize 6, out_qsize 0\n",
      "2018-12-03 21:02:48,428 [INFO] EPOCH 3 - PROGRESS: at 52.59% examples, 332649 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-03 21:02:49,434 [INFO] EPOCH 3 - PROGRESS: at 83.21% examples, 351903 words/s, in_qsize 6, out_qsize 0\n",
      "2018-12-03 21:02:50,002 [INFO] worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-03 21:02:50,030 [INFO] worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-03 21:02:50,032 [INFO] worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-03 21:02:50,034 [INFO] EPOCH - 3 : training on 1877982 raw words (1290810 effective words) took 3.6s, 355042 effective words/s\n",
      "2018-12-03 21:02:51,092 [INFO] EPOCH 4 - PROGRESS: at 30.52% examples, 373046 words/s, in_qsize 6, out_qsize 0\n",
      "2018-12-03 21:02:52,100 [INFO] EPOCH 4 - PROGRESS: at 58.92% examples, 367760 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-03 21:02:53,166 [INFO] EPOCH 4 - PROGRESS: at 86.80% examples, 357281 words/s, in_qsize 6, out_qsize 0\n",
      "2018-12-03 21:02:53,600 [INFO] worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-03 21:02:53,628 [INFO] worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-03 21:02:53,632 [INFO] worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-03 21:02:53,635 [INFO] EPOCH - 4 : training on 1877982 raw words (1291209 effective words) took 3.6s, 359476 effective words/s\n",
      "2018-12-03 21:02:54,651 [INFO] EPOCH 5 - PROGRESS: at 29.41% examples, 373956 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-03 21:02:55,679 [INFO] EPOCH 5 - PROGRESS: at 56.80% examples, 357902 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-03 21:02:56,703 [INFO] EPOCH 5 - PROGRESS: at 87.80% examples, 368743 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-03 21:02:57,102 [INFO] worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-03 21:02:57,120 [INFO] worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-03 21:02:57,122 [INFO] worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-03 21:02:57,125 [INFO] EPOCH - 5 : training on 1877982 raw words (1290901 effective words) took 3.5s, 370606 effective words/s\n",
      "2018-12-03 21:02:58,146 [INFO] EPOCH 6 - PROGRESS: at 16.20% examples, 206214 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-03 21:02:59,172 [INFO] EPOCH 6 - PROGRESS: at 42.61% examples, 267986 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-03 21:03:00,214 [INFO] EPOCH 6 - PROGRESS: at 66.74% examples, 278544 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-03 21:03:01,255 [INFO] EPOCH 6 - PROGRESS: at 94.17% examples, 293694 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-03 21:03:01,445 [INFO] worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-03 21:03:01,447 [INFO] worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-03 21:03:01,474 [INFO] worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-03 21:03:01,475 [INFO] EPOCH - 6 : training on 1877982 raw words (1291801 effective words) took 4.3s, 297335 effective words/s\n",
      "2018-12-03 21:03:02,500 [INFO] EPOCH 7 - PROGRESS: at 19.18% examples, 245344 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-03 21:03:03,511 [INFO] EPOCH 7 - PROGRESS: at 37.96% examples, 239736 words/s, in_qsize 6, out_qsize 0\n",
      "2018-12-03 21:03:04,527 [INFO] EPOCH 7 - PROGRESS: at 57.75% examples, 244070 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-03 21:03:05,532 [INFO] EPOCH 7 - PROGRESS: at 78.09% examples, 247119 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-03 21:03:06,462 [INFO] worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-03 21:03:06,489 [INFO] worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-03 21:03:06,503 [INFO] worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-03 21:03:06,507 [INFO] EPOCH - 7 : training on 1877982 raw words (1290912 effective words) took 5.0s, 256915 effective words/s\n",
      "2018-12-03 21:03:07,639 [INFO] EPOCH 8 - PROGRESS: at 26.74% examples, 338631 words/s, in_qsize 6, out_qsize 0\n",
      "2018-12-03 21:03:08,647 [INFO] EPOCH 8 - PROGRESS: at 54.20% examples, 343418 words/s, in_qsize 6, out_qsize 0\n",
      "2018-12-03 21:03:09,664 [INFO] EPOCH 8 - PROGRESS: at 70.53% examples, 297717 words/s, in_qsize 6, out_qsize 0\n",
      "2018-12-03 21:03:10,687 [INFO] EPOCH 8 - PROGRESS: at 96.71% examples, 305983 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-03 21:03:10,800 [INFO] worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-03 21:03:10,843 [INFO] worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-03 21:03:10,846 [INFO] worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-03 21:03:10,848 [INFO] EPOCH - 8 : training on 1877982 raw words (1291115 effective words) took 4.2s, 305454 effective words/s\n",
      "2018-12-03 21:03:11,878 [INFO] EPOCH 9 - PROGRESS: at 23.48% examples, 297717 words/s, in_qsize 4, out_qsize 1\n",
      "2018-12-03 21:03:12,906 [INFO] EPOCH 9 - PROGRESS: at 52.59% examples, 329572 words/s, in_qsize 6, out_qsize 1\n",
      "2018-12-03 21:03:13,907 [INFO] EPOCH 9 - PROGRESS: at 80.64% examples, 339460 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-03 21:03:14,499 [INFO] worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-03 21:03:14,530 [INFO] worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-03 21:03:14,532 [INFO] worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-03 21:03:14,534 [INFO] EPOCH - 9 : training on 1877982 raw words (1291246 effective words) took 3.7s, 351252 effective words/s\n",
      "2018-12-03 21:03:15,568 [INFO] EPOCH 10 - PROGRESS: at 27.23% examples, 342173 words/s, in_qsize 6, out_qsize 1\n",
      "2018-12-03 21:03:16,570 [INFO] EPOCH 10 - PROGRESS: at 57.75% examples, 366636 words/s, in_qsize 6, out_qsize 0\n",
      "2018-12-03 21:03:17,570 [INFO] EPOCH 10 - PROGRESS: at 84.83% examples, 359629 words/s, in_qsize 6, out_qsize 0\n"
     ]
    }
   ],
   "source": [
    "from fgclassifier.features import FeaturePipeline, logger\n",
    "\n",
    "for name in ['word2vec_en']:\n",
    "    logger.info(f'Building features for {name}...')\n",
    "    model = FeaturePipeline.from_spec(name, cache=fm)\n",
    "    model.fit_transform(X_train)\n",
    "    model.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scores_train, avg_score_train = defaultdict(dict), defaultdict(dict)\n",
    "scores_test, avg_score_test = defaultdict(dict), defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fgclassifier.train import fm_cross_check\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-03 21:01:49,839 [INFO] \n",
      "2018-12-03 21:01:49,841 [INFO] ============ Feature Model: word2vec ============\n",
      "2018-12-03 21:01:49,843 [INFO] \n",
      "2018-12-03 21:01:49,845 [INFO] Train for word2vec -> RBF...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-07949f9dc85f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m results = fm_cross_check(\n\u001b[0;32m     18\u001b[0m     \u001b[1;33m[\u001b[0m\u001b[1;34m'word2vec'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     ['RBF', 'LDA', 'QDA', 'LinearSVC', 'Ridge', 'Logistic'], **conf)\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mclear_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\workspace\\fine-grained-sentiment-analysis\\fgclassifier\\train.py\u001b[0m in \u001b[0;36mfm_cross_check\u001b[1;34m(fmns, clss, fm_cache, X_train, X_test, y_train, y_test, model_cls, results)\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Train for {fmn} -> {cls}...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mClassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_cls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'model'"
     ]
    }
   ],
   "source": [
    "conf = {\n",
    "    'fm_cache': fm,\n",
    "    'X_train': X_train,\n",
    "    'X_test': X_test,\n",
    "    'y_train': y_train,\n",
    "    'y_test': y_test,\n",
    "    'results': {\n",
    "        'models': {},\n",
    "        'avg': avg_score_test,\n",
    "        'all': scores_test,\n",
    "        'avg_train': avg_score_train,\n",
    "        'all_train': scores_train,\n",
    "    }\n",
    "}\n",
    "\n",
    "# All other models can run on many classifiers\n",
    "results = fm_cross_check(\n",
    "    ['word2vec'],\n",
    "    ['RBF', 'LDA', 'QDA', 'LinearSVC', 'Ridge', 'Logistic'], **conf)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = {}\n",
    "for fm_name in all_scores:\n",
    "    for clf_name in all_scores[fm_name]:\n",
    "        key = f'{fm_name}.{clf_name}'\n",
    "        rows[key] = [all_avg_scores[fm_name][clf_name],\n",
    "                     *all_scores[fm_name][clf_name]]\n",
    "df = pd.DataFrame(rows)\n",
    "df.index = ['average', *y_train.columns]\n",
    "df = df.T.sort_values('average', ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40654159090857\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
