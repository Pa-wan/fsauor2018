{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our dataset is in Chinese, to facilitate communication with team members and instructors, we are creating a subset of English translations using Google Translate API.\n",
    "\n",
    "If you want to run the following code yourself, follow the instructions [here](https://cloud.google.com/translate/docs/quickstart-client-libraries#client-libraries-install-python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-05 02:01:38,903 [INFO] Reading /opt/storage/train/sentiment_analysis_trainingset.csv..\n"
     ]
    }
   ],
   "source": [
    "from config import valid_data_path, train_data_path, testa_data_path\n",
    "from fgclassifier import read_csv\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "df_train_raw = read_csv(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10015\n"
     ]
    }
   ],
   "source": [
    "from config import data_root \n",
    "\n",
    "cache_path = f'{data_root}/train/en.pkl'\n",
    "try:\n",
    "    translations = joblib.load(cache_path)\n",
    "    print(len(translations))\n",
    "except:\n",
    "    translations = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12000/12000 [39:01<00:00,  1.03s/it]   "
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from tqdm import tqdm\n",
    "from google.cloud import translate\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "\n",
    "# All available credentials\n",
    "credentials = glob.glob('../data/google-cloud/*.json')\n",
    "\n",
    "# Use multiple credentials to bypass rate limit\n",
    "clients = []\n",
    "for credential in credentials:\n",
    "    print(credential)\n",
    "    clients.append(translate.Client.from_service_account_json(credential))\n",
    "\n",
    "df = df_train_raw.copy().iloc[0:12000,:]\n",
    "contents = [x.strip('\"') for x in df['content']]\n",
    "n_client = len(clients)\n",
    "n_records = df.shape[0]\n",
    "\n",
    "client_ok = [True for _ in clients]\n",
    "\n",
    "\n",
    "def get_client(i):\n",
    "    c = 0\n",
    "    while not client_ok[i % n_client] and c < n_client:\n",
    "        c += 1\n",
    "        i += 1\n",
    "    i = i % n_client\n",
    "    client = clients[i] if c < n_client else None\n",
    "    return i, client\n",
    "\n",
    "failed = []\n",
    "\n",
    "clear_output()\n",
    "pbar = tqdm(total=n_records)\n",
    "queue = list(range(n_records))\n",
    "n_failed = 0\n",
    "\n",
    "while len(queue) and n_failed < n_client:\n",
    "    i = queue.pop(0)\n",
    "    if i not in translations:\n",
    "        start_time = time.time()\n",
    "        client_idx, client = get_client(i)\n",
    "        if not client:\n",
    "            raise RuntimeError('No Available Client.')\n",
    "        try:\n",
    "            translation = client.translate(contents[i],\n",
    "                target_language='en', source_language='zh')\n",
    "            translations[i] = translation['translatedText']\n",
    "        except Exception as e:\n",
    "            # print(client_idx + 1, e)\n",
    "            client_ok[client_idx] = False\n",
    "            queue.append(i)\n",
    "            n_failed += 1\n",
    "            continue\n",
    "        end_time = time.time()\n",
    "        # If finished within 1 second, wait...\n",
    "        if end_time < start_time + 0.5:\n",
    "            time.sleep(start_time + 0.5 - end_time)\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/opt/storage/train/en.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(translations, cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace content with translation, and replace apostrophe \n",
    "df['content'] = [x.replace('&#39;', \"'\") for x in pd.Series(translations).sort_index()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"夏天散步时曾经路过，看到里面很是热闹，进去吃过一次，感觉还不错。今天再散步到此，排队、拿托盘、慢走点菜，菜式非常丰富，好几种鱼、鸡肉、红烧肉、小排骨、炒猪肝、各种蔬菜、羹、汤、、、盛米饭的碗不大，说可以添，问老板为何碗小饭少，曰浪费粮食是可耻的，让食客自己添加不要浪费☺一楼坐不下的客人，可以去二楼，上面面积也挺大的。观察一会，估计旁边居民为多，大概都是一家三口为省事，几人团聚免烧菜的格调各种菜肴价格不贵，味道也不错，就是有人抽烟无人管（虽然到处写着不许抽烟）\"\n",
      "I used to pass by during the summer walk. I saw that it was very lively. I went in and ate once and it felt pretty good. Today, I will take a walk here, line up, take the tray, and slowly go to order. The dishes are very rich. There are several kinds of fish, chicken, braised pork, small ribs, fried pork liver, various vegetables, clams, soup, and bowls of rice. Not big, said that you can add, ask the boss why the bowl is small, it is shameful to waste food, let the diners add themselves and don't waste the guests who can't sit on the first floor, you can go to the second floor, the area is quite big. After observing for a while, it is estimated that there are many residents nearby. It is probably a family of three to save trouble. The style of several people reunion and cooking is not expensive. The taste is not bad. Some people smoke unattended (although there is no smoking everywhere) )\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "idx = np.random.randint(0, 10000)\n",
    "print(df_train_raw['content'][idx])\n",
    "print(df['content'][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Sample data obtained by Google Translating to English\n",
    "df.to_csv('data/english.csv', index=False, quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split to a training set and a hold-out validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-05 02:43:03,992 [INFO] Reading data/english.csv..\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from fgclassifier.utils import read_csv\n",
    "\n",
    "df = read_csv('data/english.csv')\n",
    "df_train = df[:10000].sample(frac=0.8, random_state=42)\n",
    "df_valid = df[:10000].drop(df_train.index)\n",
    "\n",
    "df_train.to_csv('data/english_train.csv', index=False, quoting=csv.QUOTE_NONNUMERIC)\n",
    "df_valid.to_csv('data/english_valid.csv', index=False, quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[10000:].to_csv('data/english_test.csv', index=False, quoting=csv.QUOTE_NONNUMERIC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
