{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.getLogger('jieba').setLevel(logging.WARN)\n",
    "logging.getLogger('fgclassifier').setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "## Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to use our baseline model.\n",
    "It also demonstrates how to test different feature models (i.e.,\n",
    "different ways of building the features) at the same time.\n",
    "\n",
    "We will use mostly the Google Translated English dataset for this\n",
    "demonstration purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-04 13:04:02,226 [INFO] Reading /opt/storage/train/sentiment_analysis_trainingset.csv.tokenized.csv..\n",
      "2018-12-04 13:04:04,626 [INFO] Reading /opt/storage/train/sentiment_analysis_trainingset.csv..\n",
      "2018-12-04 13:04:07,298 [INFO] Take 8000 samples with random state 1\n",
      "2018-12-04 13:04:07,333 [INFO] Reading /opt/storage/valid/sentiment_analysis_validationset.csv.tokenized.csv..\n",
      "2018-12-04 13:04:07,662 [INFO] Reading /opt/storage/valid/sentiment_analysis_validationset.csv..\n",
      "2018-12-04 13:04:07,934 [INFO] Take 2000 samples with random state 1\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from fgclassifier.utils import read_data, get_dataset\n",
    "\n",
    "X_train, y_train = read_data(get_dataset('train'), sample_n=8000)\n",
    "X_test, y_test = read_data(get_dataset('valid'), sample_n=2000)\n",
    "# X_train, y_train = read_data(get_dataset('train'), sample_n=100)\n",
    "# X_test, y_test = read_data(get_dataset('valid'), sample_n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del fm['tfidf_sv']\n",
    "# del fm['tfidf_sv_dense']\n",
    "# del fm['lsa_200_sv']\n",
    "# del fm['lsa_500_sv']\n",
    "# del fm['count_tiny']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache feature models and trained fetures, we make this cache object\n",
    "# so different steps can reuse previously transformed features\n",
    "fm = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-04 13:04:09,026 [INFO] 'pattern' package not found; tag filters are not available for English\n",
      "2018-12-04 13:04:09,042 [INFO] Building features for count...\n",
      "2018-12-04 13:04:09,043 [INFO] Fit & Transform CountVectorizer...\n",
      "2018-12-04 13:04:49,903 [INFO] Vocab Size: 3573\n",
      "2018-12-04 13:04:52,038 [INFO] Building features for count_sv...\n",
      "2018-12-04 13:04:52,039 [INFO] Fit & Transform CountVectorizer...\n",
      "2018-12-04 13:05:34,404 [INFO] Vocab Size: 1704\n",
      "2018-12-04 13:05:36,732 [INFO] Building features for count_tiny...\n",
      "2018-12-04 13:05:36,741 [INFO] Fit & Transform CountVectorizer...\n",
      "2018-12-04 13:06:20,862 [INFO] Vocab Size: 1694\n"
     ]
    }
   ],
   "source": [
    "from fgclassifier.features import FeaturePipeline, logger\n",
    "\n",
    "def build_features(fm_names, fm):\n",
    "    for name in fm_names:\n",
    "        logger.info(f'Building features for {name}...')\n",
    "        model = FeaturePipeline.from_spec(name, cache=fm)\n",
    "        model.fit_transform(X_train)\n",
    "        model.transform(X_test)\n",
    "    \n",
    "build_features(['count', 'count_sv', 'count_tiny'], fm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exam the quality of the top terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (8000,) (2000,)\n",
      "\n",
      "min_df: 0.010, max_df: 0.800, ngram_range: (1, 5)\n",
      "\n",
      "vocab size: 3573\n",
      "\n",
      "吃 \t 18487\n",
      "！ \t 14847\n",
      "都 \t 13361\n",
      "有 \t 12560\n",
      "就 \t 11860\n",
      "\n",
      "min_df: 0.020, max_df: 0.800, ngram_range: (1, 5)\n",
      "\n",
      "vocab size: 1704\n",
      "\n",
      "吃 \t 18487\n",
      "！ \t 14847\n",
      "都 \t 13361\n",
      "有 \t 12560\n",
      "就 \t 11860\n",
      "\n",
      "min_df: 0.020, max_df: 0.600, ngram_range: (1, 5)\n",
      "\n",
      "vocab size: 1694\n",
      "\n",
      "！ \t 14847\n",
      "我 \t 11366\n",
      "和 \t 8712\n",
      "感觉 \t 6914\n",
      "可以 \t 6770\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print('Data Shape:', X_train.shape, X_test.shape)\n",
    "\n",
    "for mn in ['count', 'count_sv', 'count_tiny']:\n",
    "    model = fm[mn]['model'].named_steps[mn]\n",
    "    key = next(filter(lambda x: 'fit_transform' in x, fm[mn].keys()))\n",
    "    x_train = fm[mn][key]\n",
    "    counts = np.sum(x_train, axis=0).flat\n",
    "    counts = {k: counts[v] for k, v in model.vocabulary_.items()}\n",
    "    print('\\nmin_df: %.3f, max_df: %.3f, ngram_range: %s' % (\n",
    "        model.min_df, model.max_df, model.ngram_range\n",
    "    ))\n",
    "    print('\\nvocab size: %s\\n' % len(model.vocabulary_))\n",
    "    print('\\n'.join([\n",
    "        '%s \\t %s' % (k, v)\n",
    "        for k, v in Counter(counts).most_common()[:5]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the word count features, as it is pretty slow to run for the whole dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "def partial_get(d, keyword):\n",
    "    key = next(filter(lambda x: x.startswith(keyword), d.keys()))\n",
    "    return d[key]\n",
    "\n",
    "def save_transform_cache(mn, path=None):\n",
    "    path = path or f'data/fm_cache-{mn}'\n",
    "    Xtrain = partial_get(fm[mn], 'fit_transform')\n",
    "    Xtest = partial_get(fm[mn], 'transform')\n",
    "    joblib.dump(Xtrain, path + '-train.pkl')\n",
    "    joblib.dump(Xtest, path + '-test.pkl')\n",
    "    print(f'Saved {path}')\n",
    "    \n",
    "# save_transform_cache('count')\n",
    "# save_transform_cache('count_sv')\n",
    "# save_transform_cache('count_tiny')\n",
    "# joblib.load('data/fm_cache-count-test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-04 13:06:23,682 [INFO] Building features for tfidf...\n",
      "2018-12-04 13:06:23,685 [INFO]   count: fit_transform use cache.\n",
      "2018-12-04 13:06:23,688 [INFO] Fit & Transform TF-IDF...\n",
      "2018-12-04 13:06:23,837 [INFO]   count: transform use cache.\n",
      "2018-12-04 13:06:23,852 [INFO] Building features for lsa_500...\n",
      "2018-12-04 13:06:23,855 [INFO]   tfidf: fit_transform use cache.\n",
      "2018-12-04 13:06:23,856 [INFO] Fit & Transform TruncatedSVD...\n",
      "2018-12-04 13:06:31,186 [INFO]   tfidf: transform use cache.\n",
      "2018-12-04 13:06:31,293 [INFO] Building features for lsa_1k...\n",
      "2018-12-04 13:06:31,295 [INFO]   tfidf: fit_transform use cache.\n",
      "2018-12-04 13:06:31,296 [INFO] Fit & Transform TruncatedSVD...\n",
      "2018-12-04 13:06:48,648 [INFO]   tfidf: transform use cache.\n",
      "2018-12-04 13:06:48,857 [INFO] Building features for tfidf_sv...\n",
      "2018-12-04 13:06:48,858 [INFO]   count_sv: fit_transform use cache.\n",
      "2018-12-04 13:06:48,860 [INFO] Fit & Transform TF-IDF...\n",
      "2018-12-04 13:06:48,950 [INFO]   count_sv: transform use cache.\n",
      "2018-12-04 13:06:48,958 [INFO] Building features for tfidf_sv_dense...\n",
      "2018-12-04 13:06:48,959 [INFO]   tfidf_sv: fit_transform use cache.\n",
      "2018-12-04 13:06:49,089 [INFO]   tfidf_sv: transform use cache.\n",
      "2018-12-04 13:06:49,115 [INFO] Building features for lsa_500_sv...\n",
      "2018-12-04 13:06:49,116 [INFO]   tfidf_sv: fit_transform use cache.\n",
      "2018-12-04 13:06:49,119 [INFO] Fit & Transform TruncatedSVD...\n",
      "2018-12-04 13:06:54,572 [INFO]   tfidf_sv: transform use cache.\n",
      "2018-12-04 13:06:54,658 [INFO] Building features for tfidf_tiny...\n",
      "2018-12-04 13:06:54,660 [INFO]   count_tiny: fit_transform use cache.\n",
      "2018-12-04 13:06:54,663 [INFO] Fit & Transform TF-IDF...\n",
      "2018-12-04 13:06:54,750 [INFO]   count_tiny: transform use cache.\n",
      "2018-12-04 13:06:54,760 [INFO] Building features for tfidf_tiny_dense...\n",
      "2018-12-04 13:06:54,762 [INFO]   tfidf_tiny: fit_transform use cache.\n",
      "2018-12-04 13:06:54,883 [INFO]   tfidf_tiny: transform use cache.\n",
      "2018-12-04 13:06:54,897 [INFO] Building features for lsa_500_tiny...\n",
      "2018-12-04 13:06:54,900 [INFO]   tfidf_tiny: fit_transform use cache.\n",
      "2018-12-04 13:06:54,902 [INFO] Fit & Transform TruncatedSVD...\n",
      "2018-12-04 13:07:00,295 [INFO]   tfidf_tiny: transform use cache.\n",
      "2018-12-04 13:07:00,356 [INFO] Building features for word2vec...\n",
      "2018-12-04 13:07:01,002 [INFO] collecting all words and their counts\n",
      "2018-12-04 13:07:01,003 [INFO] PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-12-04 13:07:01,285 [INFO] pruned out 0 tokens with count <=1 (before 50009, after 50009)\n",
      "2018-12-04 13:07:01,315 [INFO] pruned out 25293 tokens with count <=2 (before 50016, after 24723)\n",
      "2018-12-04 13:07:01,450 [INFO] collected 36238 word types from a corpus of 1516568 raw words and 8000 sentences\n",
      "2018-12-04 13:07:01,452 [INFO] Loading a fresh vocabulary\n",
      "2018-12-04 13:07:01,543 [INFO] effective_min_count=5 retains 14272 unique words (39% of original 36238, drops 21966)\n",
      "2018-12-04 13:07:01,544 [INFO] effective_min_count=5 leaves 1448781 word corpus (97% of original 1491275, drops 42494)\n",
      "2018-12-04 13:07:01,630 [INFO] deleting the raw counts dictionary of 36238 items\n",
      "2018-12-04 13:07:01,633 [INFO] sample=0.5 downsamples 0 most-common words\n",
      "2018-12-04 13:07:01,635 [INFO] downsampling leaves estimated 1448781 word corpus (100.0% of prior 1448781)\n",
      "2018-12-04 13:07:01,705 [INFO] estimated required memory for 14272 words and 300 dimensions: 41388800 bytes\n",
      "2018-12-04 13:07:01,707 [INFO] resetting layer weights\n",
      "2018-12-04 13:07:02,001 [INFO] training model with 3 workers on 14272 vocabulary and 300 features, using sg=0 hs=0 sample=0.5 negative=5 window=10\n",
      "2018-12-04 13:07:03,034 [INFO] EPOCH 1 - PROGRESS: at 37.99% examples, 532469 words/s, in_qsize 6, out_qsize 0\n",
      "2018-12-04 13:07:04,039 [INFO] EPOCH 1 - PROGRESS: at 66.89% examples, 477695 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-04 13:07:05,119 [INFO] EPOCH 1 - PROGRESS: at 93.04% examples, 433197 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-04 13:07:05,459 [INFO] worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-04 13:07:05,474 [INFO] worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-04 13:07:05,495 [INFO] worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-04 13:07:05,496 [INFO] EPOCH - 1 : training on 1516568 raw words (1448799 effective words) took 3.5s, 415046 effective words/s\n",
      "2018-12-04 13:07:06,538 [INFO] EPOCH 2 - PROGRESS: at 24.14% examples, 338545 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-04 13:07:07,545 [INFO] EPOCH 2 - PROGRESS: at 48.33% examples, 342731 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-04 13:07:08,558 [INFO] EPOCH 2 - PROGRESS: at 77.99% examples, 370822 words/s, in_qsize 4, out_qsize 1\n",
      "2018-12-04 13:07:09,428 [INFO] worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-04 13:07:09,434 [INFO] worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-04 13:07:09,439 [INFO] worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-04 13:07:09,440 [INFO] EPOCH - 2 : training on 1516568 raw words (1448799 effective words) took 3.9s, 368265 effective words/s\n",
      "2018-12-04 13:07:10,500 [INFO] EPOCH 3 - PROGRESS: at 33.41% examples, 456644 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-04 13:07:11,533 [INFO] EPOCH 3 - PROGRESS: at 63.04% examples, 438029 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-04 13:07:12,419 [INFO] worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-04 13:07:12,423 [INFO] worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-04 13:07:12,427 [INFO] worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-04 13:07:12,428 [INFO] EPOCH - 3 : training on 1516568 raw words (1448799 effective words) took 3.0s, 485630 effective words/s\n",
      "2018-12-04 13:07:13,443 [INFO] EPOCH 4 - PROGRESS: at 39.34% examples, 560250 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-04 13:07:14,484 [INFO] EPOCH 4 - PROGRESS: at 70.85% examples, 501019 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-04 13:07:15,157 [INFO] worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-04 13:07:15,164 [INFO] worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-04 13:07:15,166 [INFO] worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-04 13:07:15,167 [INFO] EPOCH - 4 : training on 1516568 raw words (1448799 effective words) took 2.7s, 529549 effective words/s\n",
      "2018-12-04 13:07:16,178 [INFO] EPOCH 5 - PROGRESS: at 34.67% examples, 496332 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-04 13:07:17,189 [INFO] EPOCH 5 - PROGRESS: at 60.54% examples, 434750 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-04 13:07:18,190 [INFO] EPOCH 5 - PROGRESS: at 95.66% examples, 459019 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-04 13:07:18,298 [INFO] worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-04 13:07:18,304 [INFO] worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-04 13:07:18,328 [INFO] worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-04 13:07:18,330 [INFO] EPOCH - 5 : training on 1516568 raw words (1448799 effective words) took 3.2s, 458499 effective words/s\n",
      "2018-12-04 13:07:19,358 [INFO] EPOCH 6 - PROGRESS: at 26.11% examples, 369153 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-04 13:07:20,371 [INFO] EPOCH 6 - PROGRESS: at 51.66% examples, 366333 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-04 13:07:21,378 [INFO] EPOCH 6 - PROGRESS: at 81.84% examples, 390299 words/s, in_qsize 4, out_qsize 1\n",
      "2018-12-04 13:07:22,011 [INFO] worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-04 13:07:22,029 [INFO] worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-04 13:07:22,035 [INFO] worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-04 13:07:22,036 [INFO] EPOCH - 6 : training on 1516568 raw words (1448799 effective words) took 3.7s, 391421 effective words/s\n",
      "2018-12-04 13:07:23,040 [INFO] EPOCH 7 - PROGRESS: at 36.69% examples, 528440 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-04 13:07:24,053 [INFO] EPOCH 7 - PROGRESS: at 61.77% examples, 444746 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-04 13:07:25,063 [INFO] EPOCH 7 - PROGRESS: at 87.84% examples, 420931 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-04 13:07:25,679 [INFO] worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-04 13:07:25,703 [INFO] worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-04 13:07:25,704 [INFO] worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-04 13:07:25,705 [INFO] EPOCH - 7 : training on 1516568 raw words (1448799 effective words) took 3.7s, 395093 effective words/s\n",
      "2018-12-04 13:07:26,727 [INFO] EPOCH 8 - PROGRESS: at 27.44% examples, 389647 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-04 13:07:27,742 [INFO] EPOCH 8 - PROGRESS: at 64.96% examples, 464037 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-04 13:07:28,755 [INFO] EPOCH 8 - PROGRESS: at 91.75% examples, 436649 words/s, in_qsize 6, out_qsize 0\n",
      "2018-12-04 13:07:29,187 [INFO] worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-04 13:07:29,204 [INFO] worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-04 13:07:29,240 [INFO] worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-04 13:07:29,242 [INFO] EPOCH - 8 : training on 1516568 raw words (1448799 effective words) took 3.5s, 410106 effective words/s\n",
      "2018-12-04 13:07:30,261 [INFO] EPOCH 9 - PROGRESS: at 24.84% examples, 353803 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-04 13:07:31,283 [INFO] EPOCH 9 - PROGRESS: at 56.30% examples, 399003 words/s, in_qsize 6, out_qsize 0\n",
      "2018-12-04 13:07:32,299 [INFO] EPOCH 9 - PROGRESS: at 89.80% examples, 426381 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-04 13:07:32,553 [INFO] worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-04 13:07:32,561 [INFO] worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-04 13:07:32,571 [INFO] worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-04 13:07:32,572 [INFO] EPOCH - 9 : training on 1516568 raw words (1448799 effective words) took 3.3s, 435652 effective words/s\n",
      "2018-12-04 13:07:33,592 [INFO] EPOCH 10 - PROGRESS: at 38.65% examples, 549280 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-04 13:07:34,633 [INFO] EPOCH 10 - PROGRESS: at 70.92% examples, 500158 words/s, in_qsize 5, out_qsize 0\n",
      "2018-12-04 13:07:35,446 [INFO] worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-04 13:07:35,456 [INFO] worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-04 13:07:35,459 [INFO] worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-04 13:07:35,460 [INFO] EPOCH - 10 : training on 1516568 raw words (1448799 effective words) took 2.9s, 502467 effective words/s\n",
      "2018-12-04 13:07:35,461 [INFO] training on a 15165680 raw words (14487990 effective words) took 33.5s, 433026 effective words/s\n"
     ]
    }
   ],
   "source": [
    "build_features(['tfidf', 'lsa_500', 'lsa_1k'], fm)\n",
    "build_features(['tfidf_sv', 'tfidf_sv_dense', 'lsa_500_sv'], fm)\n",
    "build_features(['tfidf_tiny', 'tfidf_tiny_dense', 'lsa_500_tiny'], fm)\n",
    "build_features(['word2vec'], fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data/fm_cache-tfidf\n",
      "Saved data/fm_cache-tfidf_sv\n",
      "Saved data/fm_cache-tfidf_tiny\n",
      "Saved data/fm_cache-lsa_1k\n",
      "Saved data/fm_cache-lsa_500_sv\n",
      "Saved data/fm_cache-lsa_500_tiny\n",
      "Saved data/fm_cache-word2vec\n"
     ]
    }
   ],
   "source": [
    "save_transform_cache('tfidf')\n",
    "save_transform_cache('tfidf_sv')\n",
    "save_transform_cache('tfidf_tiny')\n",
    "save_transform_cache('lsa_1k')\n",
    "save_transform_cache('lsa_500_sv')\n",
    "save_transform_cache('lsa_500_tiny')\n",
    "save_transform_cache('word2vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Very Basic TF-IDF + LDA classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impact all feature models at once, so to avoid\n",
    "# classes being reloaded and causing save_model to fail\n",
    "from fgclassifier.baseline import Baseline, Dummy\n",
    "from fgclassifier.train import fm_cross_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check a basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-04 13:08:03,409 [INFO]   lsa_500: fit_transform use cache.\n",
      "2018-12-04 13:08:10,271 [INFO]   lsa_500: transform use cache.\n",
      "2018-12-04 13:08:10,348 [INFO] [Validate]: F1 Scores\n",
      "2018-12-04 13:08:10,351 [INFO]   location_traffic_convenience            \t0.4093\n",
      "2018-12-04 13:08:10,354 [INFO]   location_distance_from_business_district\t0.3387\n",
      "2018-12-04 13:08:10,357 [INFO]   location_easy_to_find                   \t0.4807\n",
      "2018-12-04 13:08:10,360 [INFO]   service_wait_time                       \t0.4154\n",
      "2018-12-04 13:08:10,364 [INFO]   service_waiters_attitude                \t0.5764\n",
      "2018-12-04 13:08:10,369 [INFO]   service_parking_convenience             \t0.3834\n",
      "2018-12-04 13:08:10,372 [INFO]   service_serving_speed                   \t0.4730\n",
      "2018-12-04 13:08:10,376 [INFO]   price_level                             \t0.4654\n",
      "2018-12-04 13:08:10,379 [INFO]   price_cost_effective                    \t0.3828\n",
      "2018-12-04 13:08:10,382 [INFO]   price_discount                          \t0.4636\n",
      "2018-12-04 13:08:10,385 [INFO]   environment_decoration                  \t0.4020\n",
      "2018-12-04 13:08:10,388 [INFO]   environment_noise                       \t0.4585\n",
      "2018-12-04 13:08:10,391 [INFO]   environment_space                       \t0.4549\n",
      "2018-12-04 13:08:10,394 [INFO]   environment_cleaness                    \t0.4771\n",
      "2018-12-04 13:08:10,397 [INFO]   dish_portion                            \t0.4165\n",
      "2018-12-04 13:08:10,401 [INFO]   dish_taste                              \t0.4756\n",
      "2018-12-04 13:08:10,404 [INFO]   dish_look                               \t0.3894\n",
      "2018-12-04 13:08:10,408 [INFO]   dish_recommendation                     \t0.4130\n",
      "2018-12-04 13:08:10,412 [INFO]   others_overall_experience               \t0.4670\n",
      "2018-12-04 13:08:10,416 [INFO]   others_willing_to_consume_again         \t0.4328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lsa_500_SGD_Logistic final score: 0.4387713107408892\n"
     ]
    }
   ],
   "source": [
    "model = Baseline('SGD_Logistic', fm=fm['lsa_500']['model'])\n",
    "# Always pass in the original features\n",
    "# the pipeline will take care of the cache\n",
    "model.fit(X_train, y_train)\n",
    "print(f'{model.name} final score:', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-04 13:08:10,492 [INFO]   lsa_500: fit_transform use cache.\n",
      "2018-12-04 13:09:49,741 [INFO]   lsa_500: transform use cache.\n",
      "2018-12-04 13:09:49,791 [INFO] [Validate]: F1 Scores\n",
      "2018-12-04 13:09:49,795 [INFO]   location_traffic_convenience            \t0.4223\n",
      "2018-12-04 13:09:49,797 [INFO]   location_distance_from_business_district\t0.3345\n",
      "2018-12-04 13:09:49,800 [INFO]   location_easy_to_find                   \t0.4456\n",
      "2018-12-04 13:09:49,803 [INFO]   service_wait_time                       \t0.3843\n",
      "2018-12-04 13:09:49,806 [INFO]   service_waiters_attitude                \t0.5888\n",
      "2018-12-04 13:09:49,808 [INFO]   service_parking_convenience             \t0.3557\n",
      "2018-12-04 13:09:49,811 [INFO]   service_serving_speed                   \t0.4359\n",
      "2018-12-04 13:09:49,813 [INFO]   price_level                             \t0.4953\n",
      "2018-12-04 13:09:49,816 [INFO]   price_cost_effective                    \t0.4008\n",
      "2018-12-04 13:09:49,819 [INFO]   price_discount                          \t0.5162\n",
      "2018-12-04 13:09:49,821 [INFO]   environment_decoration                  \t0.4341\n",
      "2018-12-04 13:09:49,824 [INFO]   environment_noise                       \t0.4253\n",
      "2018-12-04 13:09:49,826 [INFO]   environment_space                       \t0.4430\n",
      "2018-12-04 13:09:49,829 [INFO]   environment_cleaness                    \t0.4396\n",
      "2018-12-04 13:09:49,830 [INFO]   dish_portion                            \t0.4398\n",
      "2018-12-04 13:09:49,832 [INFO]   dish_taste                              \t0.5170\n",
      "2018-12-04 13:09:49,835 [INFO]   dish_look                               \t0.3474\n",
      "2018-12-04 13:09:49,838 [INFO]   dish_recommendation                     \t0.3875\n",
      "2018-12-04 13:09:49,840 [INFO]   others_overall_experience               \t0.4546\n",
      "2018-12-04 13:09:49,842 [INFO]   others_willing_to_consume_again         \t0.4645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lsa_500_Logistic final score: 0.4366171348301675\n"
     ]
    }
   ],
   "source": [
    "model = Baseline('Logistic', fm=fm['lsa_500']['model'])\n",
    "model.fit(X_train, y_train)\n",
    "print(f'{model.name} final score:', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic is much slower but performs not much better than Stochastic logistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-04 13:09:49,896 [INFO]   lsa_500: fit_transform use cache.\n",
      "2018-12-04 13:09:54,320 [INFO]   lsa_500: transform use cache.\n",
      "2018-12-04 13:09:54,375 [INFO] [Validate]: F1 Scores\n",
      "2018-12-04 13:09:54,380 [INFO]   location_traffic_convenience            \t0.4197\n",
      "2018-12-04 13:09:54,383 [INFO]   location_distance_from_business_district\t0.0406\n",
      "2018-12-04 13:09:54,385 [INFO]   location_easy_to_find                   \t0.4541\n",
      "2018-12-04 13:09:54,387 [INFO]   service_wait_time                       \t0.3974\n",
      "2018-12-04 13:09:54,390 [INFO]   service_waiters_attitude                \t0.5363\n",
      "2018-12-04 13:09:54,392 [INFO]   service_parking_convenience             \t0.3806\n",
      "2018-12-04 13:09:54,394 [INFO]   service_serving_speed                   \t0.4479\n",
      "2018-12-04 13:09:54,396 [INFO]   price_level                             \t0.4109\n",
      "2018-12-04 13:09:54,399 [INFO]   price_cost_effective                    \t0.4015\n",
      "2018-12-04 13:09:54,401 [INFO]   price_discount                          \t0.5152\n",
      "2018-12-04 13:09:54,403 [INFO]   environment_decoration                  \t0.3151\n",
      "2018-12-04 13:09:54,406 [INFO]   environment_noise                       \t0.4100\n",
      "2018-12-04 13:09:54,409 [INFO]   environment_space                       \t0.4078\n",
      "2018-12-04 13:09:54,411 [INFO]   environment_cleaness                    \t0.4412\n",
      "2018-12-04 13:09:54,413 [INFO]   dish_portion                            \t0.4177\n",
      "2018-12-04 13:09:54,416 [INFO]   dish_taste                              \t0.3826\n",
      "2018-12-04 13:09:54,419 [INFO]   dish_look                               \t0.2999\n",
      "2018-12-04 13:09:54,421 [INFO]   dish_recommendation                     \t0.3948\n",
      "2018-12-04 13:09:54,423 [INFO]   others_overall_experience               \t0.2480\n",
      "2018-12-04 13:09:54,426 [INFO]   others_willing_to_consume_again         \t0.4834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lsa_500_SGD_Huber final score: 0.39024959160520634\n"
     ]
    }
   ],
   "source": [
    "model = Baseline('SGD_Huber', fm=fm['lsa_500']['model'])\n",
    "model.fit(X_train, y_train)\n",
    "print(f'{model.name} final score:', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-04 13:09:54,485 [INFO]   lsa_500: fit_transform use cache.\n",
      "2018-12-04 13:09:59,788 [INFO]   lsa_500: transform use cache.\n",
      "2018-12-04 13:09:59,861 [INFO] [Validate]: F1 Scores\n",
      "2018-12-04 13:09:59,864 [INFO]   location_traffic_convenience            \t0.4185\n",
      "2018-12-04 13:09:59,868 [INFO]   location_distance_from_business_district\t0.3358\n",
      "2018-12-04 13:09:59,872 [INFO]   location_easy_to_find                   \t0.3111\n",
      "2018-12-04 13:09:59,877 [INFO]   service_wait_time                       \t0.3782\n",
      "2018-12-04 13:09:59,882 [INFO]   service_waiters_attitude                \t0.5664\n",
      "2018-12-04 13:09:59,885 [INFO]   service_parking_convenience             \t0.3897\n",
      "2018-12-04 13:09:59,889 [INFO]   service_serving_speed                   \t0.4691\n",
      "2018-12-04 13:09:59,892 [INFO]   price_level                             \t0.4418\n",
      "2018-12-04 13:09:59,895 [INFO]   price_cost_effective                    \t0.4166\n",
      "2018-12-04 13:09:59,897 [INFO]   price_discount                          \t0.5203\n",
      "2018-12-04 13:09:59,901 [INFO]   environment_decoration                  \t0.4427\n",
      "2018-12-04 13:09:59,904 [INFO]   environment_noise                       \t0.4564\n",
      "2018-12-04 13:09:59,911 [INFO]   environment_space                       \t0.4374\n",
      "2018-12-04 13:09:59,915 [INFO]   environment_cleaness                    \t0.4453\n",
      "2018-12-04 13:09:59,921 [INFO]   dish_portion                            \t0.4366\n",
      "2018-12-04 13:09:59,924 [INFO]   dish_taste                              \t0.5339\n",
      "2018-12-04 13:09:59,929 [INFO]   dish_look                               \t0.3540\n",
      "2018-12-04 13:09:59,933 [INFO]   dish_recommendation                     \t0.4233\n",
      "2018-12-04 13:09:59,937 [INFO]   others_overall_experience               \t0.3622\n",
      "2018-12-04 13:09:59,943 [INFO]   others_willing_to_consume_again         \t0.4782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lsa_500_SGD_SVC final score: 0.4308898988950892\n"
     ]
    }
   ],
   "source": [
    "model = Baseline('SGD_SVC', fm=fm['lsa_500']['model'])\n",
    "model.fit(X_train, y_train)\n",
    "print(f'{model.name} final score:', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-04 13:10:00,018 [INFO]   lsa_500: fit_transform use cache.\n",
      "2018-12-04 13:10:19,161 [INFO]   lsa_500: transform use cache.\n",
      "2018-12-04 13:10:19,215 [INFO] [Validate]: F1 Scores\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "2018-12-04 13:10:19,223 [INFO]   location_traffic_convenience            \t0.4039\n",
      "2018-12-04 13:10:19,227 [INFO]   location_distance_from_business_district\t0.3024\n",
      "2018-12-04 13:10:19,230 [INFO]   location_easy_to_find                   \t0.3817\n",
      "2018-12-04 13:10:19,234 [INFO]   service_wait_time                       \t0.3027\n",
      "2018-12-04 13:10:19,237 [INFO]   service_waiters_attitude                \t0.5177\n",
      "2018-12-04 13:10:19,242 [INFO]   service_parking_convenience             \t0.2484\n",
      "2018-12-04 13:10:19,245 [INFO]   service_serving_speed                   \t0.3578\n",
      "2018-12-04 13:10:19,248 [INFO]   price_level                             \t0.4344\n",
      "2018-12-04 13:10:19,252 [INFO]   price_cost_effective                    \t0.3359\n",
      "2018-12-04 13:10:19,255 [INFO]   price_discount                          \t0.4539\n",
      "2018-12-04 13:10:19,258 [INFO]   environment_decoration                  \t0.3717\n",
      "2018-12-04 13:10:19,263 [INFO]   environment_noise                       \t0.3456\n",
      "2018-12-04 13:10:19,269 [INFO]   environment_space                       \t0.3712\n",
      "2018-12-04 13:10:19,273 [INFO]   environment_cleaness                    \t0.3614\n",
      "2018-12-04 13:10:19,279 [INFO]   dish_portion                            \t0.3860\n",
      "2018-12-04 13:10:19,282 [INFO]   dish_taste                              \t0.3513\n",
      "2018-12-04 13:10:19,285 [INFO]   dish_look                               \t0.2608\n",
      "2018-12-04 13:10:19,289 [INFO]   dish_recommendation                     \t0.3012\n",
      "2018-12-04 13:10:19,294 [INFO]   others_overall_experience               \t0.4437\n",
      "2018-12-04 13:10:19,300 [INFO]   others_willing_to_consume_again         \t0.4185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lsa_500_Ridge final score: 0.36750217749456415\n"
     ]
    }
   ],
   "source": [
    "model = Baseline('Ridge', fm=fm['lsa_500']['model'])\n",
    "model.fit(X_train, y_train)\n",
    "print(f'{model.name} final score:', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for the Best Feature + Classifier Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for all classifiers and feature builders\n",
    "train_avg_scores, train_scores = defaultdict(dict), defaultdict(dict)\n",
    "test_avg_scores, test_scores = defaultdict(dict), defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dummy(classifier=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fgclassifier import classifiers\n",
    "from fgclassifier.baseline import Dummy\n",
    "\n",
    "Dummy(classifiers.DummyStratified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {\n",
    "    'fm_cache': fm,\n",
    "    'X_train': X_train,\n",
    "    'X_test': X_test,\n",
    "    'y_train': y_train,\n",
    "    'y_test': y_test,\n",
    "    'results': {\n",
    "        'models': {},\n",
    "        'test': test_scores,\n",
    "        'test_avg': test_avg_scores,\n",
    "        'train': train_scores,\n",
    "        'train_avg': train_avg_scores\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-04 13:17:35,429 [INFO] \n",
      "2018-12-04 13:17:35,430 [INFO] ============ Feature Model: tfidf ============\n",
      "2018-12-04 13:17:35,431 [INFO] \n",
      "2018-12-04 13:17:35,432 [INFO] Train for tfidf -> ComplementNB...\n",
      "2018-12-04 13:17:35,434 [INFO]   tfidf: fit_transform use cache.\n",
      "2018-12-04 13:17:35,642 [INFO]   tfidf: transform use cache.\n",
      "2018-12-04 13:17:35,773 [INFO] [Validate]: F1 Scores\n",
      "2018-12-04 13:17:35,777 [INFO]   location_traffic_convenience            \t0.4291\n",
      "2018-12-04 13:17:35,781 [INFO]   location_distance_from_business_district\t0.4602\n",
      "2018-12-04 13:17:35,784 [INFO]   location_easy_to_find                   \t0.5222\n",
      "2018-12-04 13:17:35,787 [INFO]   service_wait_time                       \t0.6386\n",
      "2018-12-04 13:17:35,790 [INFO]   service_waiters_attitude                \t0.5866\n",
      "2018-12-04 13:17:35,794 [INFO]   service_parking_convenience             \t0.4489\n",
      "2018-12-04 13:17:35,797 [INFO]   service_serving_speed                   \t0.5859\n",
      "2018-12-04 13:17:35,803 [INFO]   price_level                             \t0.6428\n",
      "2018-12-04 13:17:35,808 [INFO]   price_cost_effective                    \t0.5676\n",
      "2018-12-04 13:17:35,812 [INFO]   price_discount                          \t0.5583\n",
      "2018-12-04 13:17:35,818 [INFO]   environment_decoration                  \t0.5007\n",
      "2018-12-04 13:17:35,822 [INFO]   environment_noise                       \t0.6068\n",
      "2018-12-04 13:17:35,827 [INFO]   environment_space                       \t0.5898\n",
      "2018-12-04 13:17:35,832 [INFO]   environment_cleaness                    \t0.5802\n",
      "2018-12-04 13:17:35,839 [INFO]   dish_portion                            \t0.5598\n",
      "2018-12-04 13:17:35,847 [INFO]   dish_taste                              \t0.5973\n",
      "2018-12-04 13:17:35,851 [INFO]   dish_look                               \t0.5082\n",
      "2018-12-04 13:17:35,856 [INFO]   dish_recommendation                     \t0.4795\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "2018-12-04 13:17:35,862 [INFO]   others_overall_experience               \t0.5025\n",
      "2018-12-04 13:17:35,869 [INFO]   others_willing_to_consume_again         \t0.5472\n",
      "2018-12-04 13:17:35,871 [INFO]   tfidf: transform use cache.\n",
      "2018-12-04 13:17:35,938 [INFO] [Validate]: F1 Scores\n",
      "2018-12-04 13:17:35,940 [INFO]   location_traffic_convenience            \t0.3713\n",
      "2018-12-04 13:17:35,943 [INFO]   location_distance_from_business_district\t0.3192\n",
      "2018-12-04 13:17:35,945 [INFO]   location_easy_to_find                   \t0.4046\n",
      "2018-12-04 13:17:35,947 [INFO]   service_wait_time                       \t0.3797\n",
      "2018-12-04 13:17:35,950 [INFO]   service_waiters_attitude                \t0.5103\n",
      "2018-12-04 13:17:35,955 [INFO]   service_parking_convenience             \t0.3043\n",
      "2018-12-04 13:17:35,958 [INFO]   service_serving_speed                   \t0.4327\n",
      "2018-12-04 13:17:35,961 [INFO]   price_level                             \t0.5102\n",
      "2018-12-04 13:17:35,964 [INFO]   price_cost_effective                    \t0.3839\n",
      "2018-12-04 13:17:35,968 [INFO]   price_discount                          \t0.4472\n",
      "2018-12-04 13:17:35,970 [INFO]   environment_decoration                  \t0.4047\n",
      "2018-12-04 13:17:35,975 [INFO]   environment_noise                       \t0.4695\n",
      "2018-12-04 13:17:35,979 [INFO]   environment_space                       \t0.4616\n",
      "2018-12-04 13:17:35,989 [INFO]   environment_cleaness                    \t0.4529\n",
      "2018-12-04 13:17:35,993 [INFO]   dish_portion                            \t0.3954\n",
      "2018-12-04 13:17:36,000 [INFO]   dish_taste                              \t0.4809\n",
      "2018-12-04 13:17:36,009 [INFO]   dish_look                               \t0.3562\n",
      "2018-12-04 13:17:36,012 [INFO]   dish_recommendation                     \t0.3752\n",
      "2018-12-04 13:17:36,017 [INFO]   others_overall_experience               \t0.4578\n",
      "2018-12-04 13:17:36,020 [INFO]   others_willing_to_consume_again         \t0.4699\n",
      "2018-12-04 13:17:36,024 [INFO] -------------------------------------------------------\n",
      "2018-12-04 13:17:36,025 [INFO] 【tfidf -> ComplementNB】 Train: 0.5456, Test: 0.4194\n",
      "2018-12-04 13:17:36,026 [INFO] -------------------------------------------------------\n",
      "2018-12-04 13:17:36,027 [INFO] \n",
      "2018-12-04 13:17:36,028 [INFO] ============ Feature Model: tfidf_sv ============\n",
      "2018-12-04 13:17:36,029 [INFO] \n",
      "2018-12-04 13:17:36,030 [INFO] Train for tfidf_sv -> ComplementNB...\n",
      "2018-12-04 13:17:36,032 [INFO]   tfidf_sv: fit_transform use cache.\n",
      "2018-12-04 13:17:45,755 [INFO] [Validate]: F1 Scores\n",
      "2018-12-04 13:17:45,758 [INFO]   location_traffic_convenience            \t0.4270\n",
      "2018-12-04 13:17:45,760 [INFO]   location_distance_from_business_district\t0.4178\n",
      "2018-12-04 13:17:45,763 [INFO]   location_easy_to_find                   \t0.4770\n",
      "2018-12-04 13:17:45,766 [INFO]   service_wait_time                       \t0.5448\n",
      "2018-12-04 13:17:45,769 [INFO]   service_waiters_attitude                \t0.5474\n",
      "2018-12-04 13:17:45,772 [INFO]   service_parking_convenience             \t0.3727\n",
      "2018-12-04 13:17:45,775 [INFO]   service_serving_speed                   \t0.5070\n",
      "2018-12-04 13:17:45,778 [INFO]   price_level                             \t0.5615\n",
      "2018-12-04 13:17:45,781 [INFO]   price_cost_effective                    \t0.4845\n",
      "2018-12-04 13:17:45,784 [INFO]   price_discount                          \t0.5264\n",
      "2018-12-04 13:17:45,787 [INFO]   environment_decoration                  \t0.4385\n",
      "2018-12-04 13:17:45,790 [INFO]   environment_noise                       \t0.4773\n",
      "2018-12-04 13:17:45,794 [INFO]   environment_space                       \t0.5161\n",
      "2018-12-04 13:17:45,799 [INFO]   environment_cleaness                    \t0.5133\n",
      "2018-12-04 13:17:45,805 [INFO]   dish_portion                            \t0.5010\n",
      "2018-12-04 13:17:45,811 [INFO]   dish_taste                              \t0.5507\n",
      "2018-12-04 13:17:45,816 [INFO]   dish_look                               \t0.4611\n",
      "2018-12-04 13:17:45,820 [INFO]   dish_recommendation                     \t0.4613\n",
      "2018-12-04 13:17:45,825 [INFO]   others_overall_experience               \t0.4808\n",
      "2018-12-04 13:17:45,829 [INFO]   others_willing_to_consume_again         \t0.4927\n",
      "2018-12-04 13:17:45,831 [INFO]   tfidf_sv: transform use cache.\n",
      "2018-12-04 13:17:45,872 [INFO] [Validate]: F1 Scores\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "2018-12-04 13:17:45,875 [INFO]   location_traffic_convenience            \t0.3704\n",
      "2018-12-04 13:17:45,878 [INFO]   location_distance_from_business_district\t0.3184\n",
      "2018-12-04 13:17:45,881 [INFO]   location_easy_to_find                   \t0.3854\n",
      "2018-12-04 13:17:45,885 [INFO]   service_wait_time                       \t0.4003\n",
      "2018-12-04 13:17:45,889 [INFO]   service_waiters_attitude                \t0.4870\n",
      "2018-12-04 13:17:45,892 [INFO]   service_parking_convenience             \t0.2706\n",
      "2018-12-04 13:17:45,894 [INFO]   service_serving_speed                   \t0.4188\n",
      "2018-12-04 13:17:45,897 [INFO]   price_level                             \t0.4553\n",
      "2018-12-04 13:17:45,900 [INFO]   price_cost_effective                    \t0.3594\n",
      "2018-12-04 13:17:45,902 [INFO]   price_discount                          \t0.4675\n",
      "2018-12-04 13:17:45,905 [INFO]   environment_decoration                  \t0.3889\n",
      "2018-12-04 13:17:45,908 [INFO]   environment_noise                       \t0.3715\n",
      "2018-12-04 13:17:45,911 [INFO]   environment_space                       \t0.4333\n",
      "2018-12-04 13:17:45,916 [INFO]   environment_cleaness                    \t0.4096\n",
      "2018-12-04 13:17:45,918 [INFO]   dish_portion                            \t0.4110\n",
      "2018-12-04 13:17:45,920 [INFO]   dish_taste                              \t0.4894\n",
      "2018-12-04 13:17:45,922 [INFO]   dish_look                               \t0.3596\n",
      "2018-12-04 13:17:45,924 [INFO]   dish_recommendation                     \t0.4002\n",
      "2018-12-04 13:17:45,927 [INFO]   others_overall_experience               \t0.4421\n",
      "2018-12-04 13:17:45,930 [INFO]   others_willing_to_consume_again         \t0.4473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-04 13:17:45,932 [INFO] -------------------------------------------------------\n",
      "2018-12-04 13:17:45,934 [INFO] 【tfidf_sv -> ComplementNB】 Train: 0.4879, Test: 0.4043\n",
      "2018-12-04 13:17:45,937 [INFO] -------------------------------------------------------\n",
      "2018-12-04 13:17:45,939 [INFO] \n",
      "2018-12-04 13:17:45,941 [INFO] ============ Feature Model: tfidf_tiny ============\n",
      "2018-12-04 13:17:45,942 [INFO] \n",
      "2018-12-04 13:17:45,944 [INFO] Train for tfidf_tiny -> ComplementNB...\n",
      "2018-12-04 13:17:45,946 [INFO]   tfidf_tiny: fit_transform use cache.\n",
      "2018-12-04 13:17:53,541 [INFO] [Validate]: F1 Scores\n",
      "2018-12-04 13:17:53,543 [INFO]   location_traffic_convenience            \t0.4218\n",
      "2018-12-04 13:17:53,546 [INFO]   location_distance_from_business_district\t0.4233\n",
      "2018-12-04 13:17:53,549 [INFO]   location_easy_to_find                   \t0.4778\n",
      "2018-12-04 13:17:53,552 [INFO]   service_wait_time                       \t0.5419\n",
      "2018-12-04 13:17:53,555 [INFO]   service_waiters_attitude                \t0.5479\n",
      "2018-12-04 13:17:53,558 [INFO]   service_parking_convenience             \t0.3706\n",
      "2018-12-04 13:17:53,561 [INFO]   service_serving_speed                   \t0.5020\n",
      "2018-12-04 13:17:53,564 [INFO]   price_level                             \t0.5632\n",
      "2018-12-04 13:17:53,567 [INFO]   price_cost_effective                    \t0.4816\n",
      "2018-12-04 13:17:53,571 [INFO]   price_discount                          \t0.5253\n",
      "2018-12-04 13:17:53,576 [INFO]   environment_decoration                  \t0.4372\n",
      "2018-12-04 13:17:53,581 [INFO]   environment_noise                       \t0.4837\n",
      "2018-12-04 13:17:53,589 [INFO]   environment_space                       \t0.5196\n",
      "2018-12-04 13:17:53,596 [INFO]   environment_cleaness                    \t0.5116\n",
      "2018-12-04 13:17:53,601 [INFO]   dish_portion                            \t0.5030\n",
      "2018-12-04 13:17:53,607 [INFO]   dish_taste                              \t0.5566\n",
      "2018-12-04 13:17:53,612 [INFO]   dish_look                               \t0.4628\n",
      "2018-12-04 13:17:53,622 [INFO]   dish_recommendation                     \t0.4680\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "2018-12-04 13:17:53,629 [INFO]   others_overall_experience               \t0.4812\n",
      "2018-12-04 13:17:53,633 [INFO]   others_willing_to_consume_again         \t0.4921\n",
      "2018-12-04 13:17:53,636 [INFO]   tfidf_tiny: transform use cache.\n",
      "2018-12-04 13:17:53,670 [INFO] [Validate]: F1 Scores\n",
      "2018-12-04 13:17:53,672 [INFO]   location_traffic_convenience            \t0.3689\n",
      "2018-12-04 13:17:53,675 [INFO]   location_distance_from_business_district\t0.3162\n",
      "2018-12-04 13:17:53,677 [INFO]   location_easy_to_find                   \t0.3945\n",
      "2018-12-04 13:17:53,680 [INFO]   service_wait_time                       \t0.4038\n",
      "2018-12-04 13:17:53,694 [INFO]   service_waiters_attitude                \t0.4855\n",
      "2018-12-04 13:17:53,702 [INFO]   service_parking_convenience             \t0.2692\n",
      "2018-12-04 13:17:53,715 [INFO]   service_serving_speed                   \t0.4165\n",
      "2018-12-04 13:17:53,723 [INFO]   price_level                             \t0.4544\n",
      "2018-12-04 13:17:53,727 [INFO]   price_cost_effective                    \t0.3556\n",
      "2018-12-04 13:17:53,731 [INFO]   price_discount                          \t0.4675\n",
      "2018-12-04 13:17:53,734 [INFO]   environment_decoration                  \t0.3834\n",
      "2018-12-04 13:17:53,738 [INFO]   environment_noise                       \t0.3705\n",
      "2018-12-04 13:17:53,741 [INFO]   environment_space                       \t0.4329\n",
      "2018-12-04 13:17:53,744 [INFO]   environment_cleaness                    \t0.4159\n",
      "2018-12-04 13:17:53,747 [INFO]   dish_portion                            \t0.4142\n",
      "2018-12-04 13:17:53,751 [INFO]   dish_taste                              \t0.4868\n",
      "2018-12-04 13:17:53,754 [INFO]   dish_look                               \t0.3608\n",
      "2018-12-04 13:17:53,757 [INFO]   dish_recommendation                     \t0.3964\n",
      "2018-12-04 13:17:53,760 [INFO]   others_overall_experience               \t0.4411\n",
      "2018-12-04 13:17:53,765 [INFO]   others_willing_to_consume_again         \t0.4442\n",
      "2018-12-04 13:17:53,768 [INFO] -------------------------------------------------------\n",
      "2018-12-04 13:17:53,770 [INFO] 【tfidf_tiny -> ComplementNB】 Train: 0.4886, Test: 0.4039\n",
      "2018-12-04 13:17:53,773 [INFO] -------------------------------------------------------\n",
      "2018-12-04 13:17:53,774 [INFO] \n",
      "2018-12-04 13:17:53,776 [INFO] ============ Feature Model: lsa_500 ============\n",
      "2018-12-04 13:17:53,777 [INFO] \n",
      "2018-12-04 13:17:53,780 [INFO] Train for lsa_500 -> LDA...\n",
      "2018-12-04 13:17:53,784 [INFO]   lsa_500: fit_transform use cache.\n",
      "2018-12-04 13:18:14,866 [INFO]   tfidf: transform use cache.\n",
      "2018-12-04 13:18:15,390 [INFO] [Validate]: F1 Scores\n",
      "2018-12-04 13:18:15,394 [INFO]   location_traffic_convenience            \t0.6974\n",
      "2018-12-04 13:18:15,399 [INFO]   location_distance_from_business_district\t0.7190\n",
      "2018-12-04 13:18:15,402 [INFO]   location_easy_to_find                   \t0.6091\n",
      "2018-12-04 13:18:15,406 [INFO]   service_wait_time                       \t0.6037\n",
      "2018-12-04 13:18:15,410 [INFO]   service_waiters_attitude                \t0.6614\n",
      "2018-12-04 13:18:15,413 [INFO]   service_parking_convenience             \t0.7340\n",
      "2018-12-04 13:18:15,417 [INFO]   service_serving_speed                   \t0.6429\n",
      "2018-12-04 13:18:15,422 [INFO]   price_level                             \t0.5758\n",
      "2018-12-04 13:18:15,427 [INFO]   price_cost_effective                    \t0.6272\n",
      "2018-12-04 13:18:15,431 [INFO]   price_discount                          \t0.6333\n",
      "2018-12-04 13:18:15,434 [INFO]   environment_decoration                  \t0.6083\n",
      "2018-12-04 13:18:15,439 [INFO]   environment_noise                       \t0.6099\n",
      "2018-12-04 13:18:15,446 [INFO]   environment_space                       \t0.5718\n",
      "2018-12-04 13:18:15,453 [INFO]   environment_cleaness                    \t0.6101\n",
      "2018-12-04 13:18:15,460 [INFO]   dish_portion                            \t0.5483\n",
      "2018-12-04 13:18:15,465 [INFO]   dish_taste                              \t0.6499\n",
      "2018-12-04 13:18:15,472 [INFO]   dish_look                               \t0.4963\n",
      "2018-12-04 13:18:15,477 [INFO]   dish_recommendation                     \t0.6361\n",
      "2018-12-04 13:18:15,484 [INFO]   others_overall_experience               \t0.6121\n",
      "2018-12-04 13:18:15,489 [INFO]   others_willing_to_consume_again         \t0.6168\n",
      "2018-12-04 13:18:15,490 [INFO]   lsa_500: transform use cache.\n",
      "2018-12-04 13:18:15,574 [INFO] [Validate]: F1 Scores\n",
      "2018-12-04 13:18:15,578 [INFO]   location_traffic_convenience            \t0.4326\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "2018-12-04 13:18:15,583 [INFO]   location_distance_from_business_district\t0.3318\n",
      "2018-12-04 13:18:15,586 [INFO]   location_easy_to_find                   \t0.4970\n",
      "2018-12-04 13:18:15,589 [INFO]   service_wait_time                       \t0.4450\n",
      "2018-12-04 13:18:15,593 [INFO]   service_waiters_attitude                \t0.5899\n",
      "2018-12-04 13:18:15,598 [INFO]   service_parking_convenience             \t0.3818\n",
      "2018-12-04 13:18:15,602 [INFO]   service_serving_speed                   \t0.4576\n",
      "2018-12-04 13:18:15,607 [INFO]   price_level                             \t0.4876\n",
      "2018-12-04 13:18:15,610 [INFO]   price_cost_effective                    \t0.4208\n",
      "2018-12-04 13:18:15,614 [INFO]   price_discount                          \t0.5221\n",
      "2018-12-04 13:18:15,619 [INFO]   environment_decoration                  \t0.4629\n",
      "2018-12-04 13:18:15,623 [INFO]   environment_noise                       \t0.4573\n",
      "2018-12-04 13:18:15,627 [INFO]   environment_space                       \t0.4501\n",
      "2018-12-04 13:18:15,630 [INFO]   environment_cleaness                    \t0.4701\n",
      "2018-12-04 13:18:15,635 [INFO]   dish_portion                            \t0.4416\n",
      "2018-12-04 13:18:15,639 [INFO]   dish_taste                              \t0.5142\n",
      "2018-12-04 13:18:15,643 [INFO]   dish_look                               \t0.3737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-04 13:18:15,646 [INFO]   dish_recommendation                     \t0.4163\n",
      "2018-12-04 13:18:15,653 [INFO]   others_overall_experience               \t0.4904\n",
      "2018-12-04 13:18:15,656 [INFO]   others_willing_to_consume_again         \t0.4937\n",
      "2018-12-04 13:18:15,658 [INFO] -------------------------------------------------------\n",
      "2018-12-04 13:18:15,659 [INFO] 【lsa_500 -> LDA】 Train: 0.6232, Test: 0.4568\n",
      "2018-12-04 13:18:15,661 [INFO] -------------------------------------------------------\n",
      "2018-12-04 13:18:15,662 [INFO] Train for lsa_500 -> QDA...\n",
      "2018-12-04 13:18:15,664 [INFO]   lsa_500: fit_transform use cache.\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "2018-12-04 13:18:30,908 [INFO]   lsa_500: transform use cache.\n",
      "2018-12-04 13:18:38,423 [INFO] [Validate]: F1 Scores\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "2018-12-04 13:18:38,428 [INFO]   location_traffic_convenience            \t0.4781\n",
      "2018-12-04 13:18:38,432 [INFO]   location_distance_from_business_district\t0.4822\n",
      "2018-12-04 13:18:38,436 [INFO]   location_easy_to_find                   \t0.4716\n",
      "2018-12-04 13:18:38,439 [INFO]   service_wait_time                       \t0.2337\n",
      "2018-12-04 13:18:38,444 [INFO]   service_waiters_attitude                \t0.9734\n",
      "2018-12-04 13:18:38,448 [INFO]   service_parking_convenience             \t0.2424\n",
      "2018-12-04 13:18:38,453 [INFO]   service_serving_speed                   \t0.4769\n",
      "2018-12-04 13:18:38,457 [INFO]   price_level                             \t0.9737\n",
      "2018-12-04 13:18:38,462 [INFO]   price_cost_effective                    \t0.4748\n",
      "2018-12-04 13:18:38,467 [INFO]   price_discount                          \t0.7254\n",
      "2018-12-04 13:18:38,471 [INFO]   environment_decoration                  \t0.7117\n",
      "2018-12-04 13:18:38,479 [INFO]   environment_noise                       \t0.4667\n",
      "2018-12-04 13:18:38,487 [INFO]   environment_space                       \t0.7086\n",
      "2018-12-04 13:18:38,494 [INFO]   environment_cleaness                    \t0.4674\n",
      "2018-12-04 13:18:38,503 [INFO]   dish_portion                            \t0.9750\n",
      "2018-12-04 13:18:38,514 [INFO]   dish_taste                              \t0.4595\n",
      "2018-12-04 13:18:38,523 [INFO]   dish_look                               \t0.4599\n",
      "2018-12-04 13:18:38,528 [INFO]   dish_recommendation                     \t0.4730\n",
      "2018-12-04 13:18:38,532 [INFO]   others_overall_experience               \t0.7225\n",
      "2018-12-04 13:18:38,535 [INFO]   others_willing_to_consume_again         \t0.4698\n",
      "2018-12-04 13:18:38,537 [INFO]   lsa_500: transform use cache.\n",
      "2018-12-04 13:18:40,340 [INFO] [Validate]: F1 Scores\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "2018-12-04 13:18:40,343 [INFO]   location_traffic_convenience            \t0.3717\n",
      "2018-12-04 13:18:40,345 [INFO]   location_distance_from_business_district\t0.2971\n",
      "2018-12-04 13:18:40,348 [INFO]   location_easy_to_find                   \t0.3260\n",
      "2018-12-04 13:18:40,350 [INFO]   service_wait_time                       \t0.2336\n",
      "2018-12-04 13:18:40,352 [INFO]   service_waiters_attitude                \t0.4327\n",
      "2018-12-04 13:18:40,355 [INFO]   service_parking_convenience             \t0.2415\n",
      "2018-12-04 13:18:40,358 [INFO]   service_serving_speed                   \t0.2592\n",
      "2018-12-04 13:18:40,360 [INFO]   price_level                             \t0.3523\n",
      "2018-12-04 13:18:40,362 [INFO]   price_cost_effective                    \t0.2898\n",
      "2018-12-04 13:18:40,365 [INFO]   price_discount                          \t0.3858\n",
      "2018-12-04 13:18:40,368 [INFO]   environment_decoration                  \t0.3350\n",
      "2018-12-04 13:18:40,371 [INFO]   environment_noise                       \t0.3006\n",
      "2018-12-04 13:18:40,374 [INFO]   environment_space                       \t0.2903\n",
      "2018-12-04 13:18:40,377 [INFO]   environment_cleaness                    \t0.3064\n",
      "2018-12-04 13:18:40,380 [INFO]   dish_portion                            \t0.3183\n",
      "2018-12-04 13:18:40,383 [INFO]   dish_taste                              \t0.3219\n",
      "2018-12-04 13:18:40,385 [INFO]   dish_look                               \t0.2860\n",
      "2018-12-04 13:18:40,388 [INFO]   dish_recommendation                     \t0.2662\n",
      "2018-12-04 13:18:40,457 [INFO]   others_overall_experience               \t0.4183\n",
      "2018-12-04 13:18:40,463 [INFO]   others_willing_to_consume_again         \t0.3343\n",
      "2018-12-04 13:18:40,464 [INFO] -------------------------------------------------------\n",
      "2018-12-04 13:18:40,467 [INFO] 【lsa_500 -> QDA】 Train: 0.5723, Test: 0.3184\n",
      "2018-12-04 13:18:40,468 [INFO] -------------------------------------------------------\n",
      "2018-12-04 13:18:40,469 [INFO] Train for lsa_500 -> LinearSVC...\n",
      "2018-12-04 13:18:40,471 [INFO]   lsa_500: fit_transform use cache.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# We'd only need to run the dummy models on one feature model,\n",
    "# as they do not care about the features\n",
    "# fm_cross_check(\n",
    "#     ['tfidf_sv'],\n",
    "#     ['DummyStratified', 'DummyMostFrequent'],\n",
    "#     model_cls=Dummy, **conf)\n",
    "\n",
    "# Naive Bayes models cannot handle negative values, so we pass\n",
    "# in only tfidf features\n",
    "fm_cross_check(\n",
    "    ['tfidf', 'tfidf_sv', 'tfidf_tiny'],\n",
    "    ['ComplementNB'], **conf)\n",
    "\n",
    "# All other models can run on many classifiers\n",
    "results = fm_cross_check(\n",
    "    ['lsa_500',\n",
    "     'lsa_500_sv',\n",
    "     'lsa_500_tiny',\n",
    "     'lsa_1k',\n",
    "     'word2vec',\n",
    "     'tfidf_sv_dense',\n",
    "     'tfidf_tiny_dense',\n",
    "    ],\n",
    "    ['LDA', 'QDA', 'LinearSVC',\n",
    "     'SGD_Logistic', 'SGD_SVC',\n",
    "     'Ridge'], **conf)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = {}\n",
    "for fm_name in all_scores:\n",
    "    for clf_name in all_scores[fm_name]:\n",
    "        key = f'{fm_name}.{clf_name}'\n",
    "        rows[key] = [all_avg_scores[fm_name][clf_name],\n",
    "                     *all_scores[fm_name][clf_name]]\n",
    "df = pd.DataFrame(rows)\n",
    "df.index = ['average', *y_train.columns]\n",
    "df = df.T.sort_values('average', ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df.T.drop(['average']).boxplot(\n",
    "    figsize=(18, 6), rot=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the models for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from fgclassifier.utils import save_model\n",
    "\n",
    "def clear_cache(model):\n",
    "    if hasattr(model, 'steps'):\n",
    "        for (name, step) in model.steps:\n",
    "            clear_cache(step)\n",
    "    if hasattr(model, 'cache'):\n",
    "        model.cache = None\n",
    "    return model\n",
    "\n",
    "for name, model in results['models'].items():\n",
    "    clear_cache(model)\n",
    "    save_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- `ComplementNB` performs much better than a simple MultinomialNB, because our class labels are mostly unbalanced.\n",
    "- `LatentDirichletAllocation` topics as features are not suitable for our classification problem, as features are often collinear. They often fare no better than the dummy classifier where we simply return the most frequent labels.\n",
    "- LSA (Latent Semantic Analysis, Tfidf + SVD) shows a much more promising outlook, especially when combined with Linear Discriminant Analysis or SVC.\n",
    "- Find the right vocabulary (min_df and ngram range) is crucial. Throw away noises early often outperforms running dimension reduction later.\n",
    "- Basically SVD makes each feature (component) more indendent with each other, making LDA and SVC easier to come up with good fittings.\n",
    "- Tree based models are not particularly useful. But the results may be different had we tuned the tree structure more.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Required:\n",
    "\n",
    "- Tune hyperparamters for `ComplementNB`, `TruncatedSVD`, `LinearDiscriminantAnalysis` and `SVC`/`LinearSVC`. Try different kernel functions.\n",
    "- Try over-/under-sampling since most of our classes are imbalanced. [Possible solution](https://imbalanced-learn.org/)\n",
    "- Test some boosting methods, especially [xgboost](https://xgboost.readthedocs.io/en/latest/).\n",
    "- Test word embedding as features.\n",
    "\n",
    "Optional:\n",
    "\n",
    "- Possibly use different classifier for different labels.\n",
    "- Test two step predictions: first run binary prediction for \"mentioned\" vs \"not mentioned\", i.e., -2 vs (-1, 0, 1), then predict (-1, 0, 1).\n",
    "    - This could happen as either [ClassifierChain](https://scikit-learn.org/stable/modules/multiclass.html#classifierchain) or separate steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = results['models']['lsa_500_en_LDA']\n",
    "print(X_test[0:1].shape)\n",
    "probas = model.predict_proba(X_test[0:1])\n",
    "probas[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
