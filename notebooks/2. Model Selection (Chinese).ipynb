{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.getLogger('jieba').setLevel(logging.WARN)\n",
    "logging.getLogger('fgclassifier').setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "## Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to use our baseline model.\n",
    "It also demonstrates how to test different feature models (i.e.,\n",
    "different ways of building the features) at the same time.\n",
    "\n",
    "We will use mostly the Google Translated English dataset for this\n",
    "demonstration purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-04 01:37:00,870 [INFO] Reading /opt/storage/train/sentiment_analysis_trainingset.csv.tokenized.csv..\n",
      "2018-12-04 01:37:02,781 [INFO] Reading /opt/storage/train/sentiment_analysis_trainingset.csv..\n",
      "2018-12-04 01:37:04,806 [INFO] Reading /opt/storage/valid/sentiment_analysis_validationset.csv.tokenized.csv..\n",
      "2018-12-04 01:37:05,064 [INFO] Reading /opt/storage/valid/sentiment_analysis_validationset.csv..\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from fgclassifier.utils import read_data, get_dataset\n",
    "\n",
    "X_train, y_train = read_data(get_dataset('train'))\n",
    "X_test, y_test = read_data(get_dataset('valid'))\n",
    "# X_train, y_train = read_data(get_dataset('train'), sample_n=100)\n",
    "# X_test, y_test = read_data(get_dataset('valid'), sample_n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del fm['tfidf_sv']\n",
    "# del fm['tfidf_sv_dense']\n",
    "# del fm['lsa_200_sv']\n",
    "# del fm['lsa_500_sv']\n",
    "# del fm['count_tiny']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache feature models and trained fetures, we make this cache object\n",
    "# so different steps can reuse previously transformed features\n",
    "fm = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-04 01:37:05,741 [INFO] 'pattern' package not found; tag filters are not available for English\n",
      "2018-12-04 01:37:05,749 [INFO] Building features for count...\n",
      "2018-12-04 01:37:05,750 [INFO] Fit & Transform CountVectorizer...\n"
     ]
    }
   ],
   "source": [
    "from fgclassifier.features import FeaturePipeline, logger\n",
    "\n",
    "def build_features(fm_names, fm):\n",
    "    for name in fm_names:\n",
    "        logger.info(f'Building features for {name}...')\n",
    "        model = FeaturePipeline.from_spec(name, cache=fm)\n",
    "        model.fit_transform(X_train)\n",
    "        model.transform(X_test)\n",
    "    \n",
    "build_features(['count', 'count_sv', 'count_tiny'], fm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exam the quality of the top terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print('Data Shape:', X_train.shape, X_test.shape)\n",
    "\n",
    "for mn in ['count', 'count_sv', 'count_tiny']:\n",
    "    model = fm[mn]['model'].named_steps[mn]\n",
    "    key = next(filter(lambda x: 'fit_transform' in x, fm[mn].keys()))\n",
    "    x_train = fm[mn][key]\n",
    "    counts = np.sum(x_train, axis=0).flat\n",
    "    counts = {k: counts[v] for k, v in model.vocabulary_.items()}\n",
    "    print('\\nmin_df: %.3f, max_df: %.3f, ngram_range: %s' % (\n",
    "        model.min_df, model.max_df, model.ngram_range\n",
    "    ))\n",
    "    print('\\nvocab size: %s\\n' % len(model.vocabulary_))\n",
    "    print('\\n'.join([\n",
    "        '%s \\t %s' % (k, v)\n",
    "        for k, v in Counter(counts).most_common()[:5]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the word count features, as it is pretty slow to run for the whole dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "def partial_get(d, keyword):\n",
    "    key = next(filter(lambda x: x.startswith(keyword), d.keys()))\n",
    "    return d[key]\n",
    "\n",
    "def save_count_cache(mn, path=None):\n",
    "    path = path or f'data/fm_cache-{mn}'\n",
    "    Xtrain = partial_get(fm[mn], 'fit_transform')\n",
    "    Xtest = partial_get(fm[mn], 'transform')\n",
    "    joblib.dump(Xtrain, path + '-train.pkl')\n",
    "    joblib.dump(Xtest, path + '-test.pkl')\n",
    "    \n",
    "save_count_cache('count')\n",
    "save_count_cache('count_sv')\n",
    "save_count_cache('count_tiny')\n",
    "joblib.load('data/fm_cache-count-test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_features(['tfidf', 'lsa_500', 'lsa_1k'], fm)\n",
    "build_features(['tfidf_sv', 'tfidf_sv_dense', 'lsa_500_sv'], fm)\n",
    "build_features(['tfidf_tiny', 'tfidf_tiny_dense', 'lsa_500_tiny'], fm)\n",
    "build_features(['word2vec', 'word2vec_minmax'], fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm['tfidf']['model'].named_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Very Basic TF-IDF + LDA classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impact all feature models at once, so to avoid\n",
    "# classes being reloaded and causing save_model to fail\n",
    "from fgclassifier.baseline import Baseline, Dummy\n",
    "from fgclassifier.classifiers import LDA\n",
    "from fgclassifier.train import fm_cross_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Discriminant Analysis, specify the FeaturePipeline\n",
    "# as steps\n",
    "model = Baseline(('LDA', LDA), fm=fm['lsa_500']['model'])\n",
    "\n",
    "# Always pass in the original features\n",
    "# the pipeline will take care of the cache\n",
    "model.fit(X_train, y_train)\n",
    "print(model.name)\n",
    "print('Final score:', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.scores(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for the Best Feature + Classifier Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for all classifiers and feature builders\n",
    "all_avg_scores, all_scores = defaultdict(dict), defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fgclassifier import classifiers\n",
    "from fgclassifier.baseline import Dummy\n",
    "\n",
    "Dummy(classifiers.DummyStratified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {\n",
    "    'fm_cache': fm,\n",
    "    'X_train': X_train,\n",
    "    'X_test': X_test,\n",
    "    'y_train': y_train,\n",
    "    'y_test': y_test,\n",
    "    'results': {\n",
    "        'models': {},\n",
    "        'avg': all_avg_scores,\n",
    "        'all': all_scores\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# We'd only need to run the dummy models on one feature model,\n",
    "# as they do not care about the features\n",
    "fm_cross_check(\n",
    "    ['tfidf_sv'],\n",
    "    ['DummyStratified', 'DummyMostFrequent'],\n",
    "    model_cls=Dummy, **conf)\n",
    "\n",
    "# Naive Bayes models cannot handle negative values, so we pass\n",
    "# in only tfidf features\n",
    "fm_cross_check(\n",
    "    ['tfidf', 'tfidf_sv', 'tfidf_tiny', 'word2vec_minmax'],\n",
    "    ['MultinomialNB', 'ComplementNB'], **conf)\n",
    "\n",
    "# All other models can run on many classifiers\n",
    "results = fm_cross_check(\n",
    "    ['lsa_500',\n",
    "     'lsa_1k',\n",
    "     'tfidf_sv_dense',\n",
    "     'tfidf_tiny_dense',\n",
    "     'lsa_500_sv',\n",
    "     'lsa_500_tiny',\n",
    "     'word2vec'\n",
    "    ],\n",
    "    ['LDA', 'QDA', 'LinearSVC', 'Logistic', 'Ridge'], **conf)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = {}\n",
    "for fm_name in all_scores:\n",
    "    for clf_name in all_scores[fm_name]:\n",
    "        key = f'{fm_name}.{clf_name}'\n",
    "        rows[key] = [all_avg_scores[fm_name][clf_name],\n",
    "                     *all_scores[fm_name][clf_name]]\n",
    "df = pd.DataFrame(rows)\n",
    "df.index = ['average', *y_train.columns]\n",
    "df = df.T.sort_values('average', ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df.T.drop(['average']).boxplot(\n",
    "    figsize=(18, 6), rot=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the models for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from fgclassifier.utils import save_model\n",
    "\n",
    "def clear_cache(model):\n",
    "    if hasattr(model, 'steps'):\n",
    "        for (name, step) in model.steps:\n",
    "            clear_cache(step)\n",
    "    if hasattr(model, 'cache'):\n",
    "        model.cache = None\n",
    "    return model\n",
    "\n",
    "for name, model in results['models'].items():\n",
    "    clear_cache(model)\n",
    "    save_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- `ComplementNB` performs much better than a simple MultinomialNB, because our class labels are mostly unbalanced.\n",
    "- `LatentDirichletAllocation` topics as features are not suitable for our classification problem, as features are often collinear. They often fare no better than the dummy classifier where we simply return the most frequent labels.\n",
    "- LSA (Latent Semantic Analysis, Tfidf + SVD) shows a much more promising outlook, especially when combined with Linear Discriminant Analysis or SVC.\n",
    "- Find the right vocabulary (min_df and ngram range) is crucial. Throw away noises early often outperforms running dimension reduction later.\n",
    "- Basically SVD makes each feature (component) more indendent with each other, making LDA and SVC easier to come up with good fittings.\n",
    "- Tree based models are not particularly useful. But the results may be different had we tuned the tree structure more.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Required:\n",
    "\n",
    "- Tune hyperparamters for `ComplementNB`, `TruncatedSVD`, `LinearDiscriminantAnalysis` and `SVC`/`LinearSVC`. Try different kernel functions.\n",
    "- Try over-/under-sampling since most of our classes are imbalanced. [Possible solution](https://imbalanced-learn.org/)\n",
    "- Test some boosting methods, especially [xgboost](https://xgboost.readthedocs.io/en/latest/).\n",
    "- Test word embedding as features.\n",
    "\n",
    "Optional:\n",
    "\n",
    "- Possibly use different classifier for different labels.\n",
    "- Test two step predictions: first run binary prediction for \"mentioned\" vs \"not mentioned\", i.e., -2 vs (-1, 0, 1), then predict (-1, 0, 1).\n",
    "    - This could happen as either [ClassifierChain](https://scikit-learn.org/stable/modules/multiclass.html#classifierchain) or separate steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = results['models']['lsa_500_en_LDA']\n",
    "print(X_test[0:1].shape)\n",
    "probas = model.predict_proba(X_test[0:1])\n",
    "probas[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
