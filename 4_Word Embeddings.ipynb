{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook tries to investigate different ways of include word embeddings as features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELMO\n",
    "\n",
    "[ELMo](https://allennlp.org/elmo) is the state-of-the-art deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts. We use [ELMoForManyLangs](https://github.com/HIT-SCIR/ELMoForManyLangs) to train our own embedding representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-20 14:07:27,468 INFO: Read cache data/train/sentiment_analysis_trainingset.csv.segged_sample_None.tsv..\n"
     ]
    }
   ],
   "source": [
    "from elmoformanylangs import Embedder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from config import train_data_path\n",
    "from fgclassifier.utils import read_data\n",
    "\n",
    "\n",
    "X, y = read_data(train_data_path, seg_words=True, sample_n=None)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-20 10:05:12,659 INFO: char embedding size: 8844\n",
      "2018-11-20 10:05:13,141 INFO: word embedding size: 69598\n",
      "2018-11-20 10:05:18,929 INFO: Model(\n",
      "  (token_embedder): ConvTokenEmbedder(\n",
      "    (word_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(69598, 100, padding_idx=3)\n",
      "    )\n",
      "    (char_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(8844, 50, padding_idx=8841)\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
      "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
      "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
      "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
      "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
      "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
      "    )\n",
      "    (highways): Highway(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
      "  )\n",
      "  (encoder): ElmobiLm(\n",
      "    (forward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (forward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "embedder = Embedder('data/elmo-zhs-100k-mc4-lr0.001/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-20 11:20:28,216 INFO: 1 batches, avg len: 130.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 1024) 3\n"
     ]
    }
   ],
   "source": [
    "def article_to_sentences(articles):\n",
    "    sentences, aids = [], []\n",
    "    for aid, article in enumerate(articles):\n",
    "        for s in article.split('。'):\n",
    "            s = s.strip()\n",
    "            if not s:\n",
    "                continue\n",
    "            sentences.append(s.split())\n",
    "            aids.append(aid)\n",
    "    return sentences, aids\n",
    "\n",
    "\n",
    "sentences, aids = article_to_sentences(X_train[:2])\n",
    "X_train_elmo = embedder.sents2elmo(sentences)\n",
    "print(X_train_elmo[0].shape, len(X_train_elmo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "很少 吃 兔子 肉 ！ BBLANKK 在 那 附近 本来 想 去 吃 泰国菜 的 ， 最后 还是 选择 了 这家 ， 果然 没 让 失望 ， 进去 后 的 座位 上 都 有 只 流氓兔 的 抱 枕 ， 点 了 一个 爆辣 的 兔头 ， 姐妹 吃 的 一直 赞不绝口 ！ BBLANKK\n",
      "\n",
      "手 撕 烤 兔 ， 本 以为 是 自己 撕 的 ， 结果 是 服务员 到 你 面前 撕 ！ BBLANKK 然后 拌 ！ BBLANKK 那 味道 吃 的 真的 太 过瘾 了 ！ BBLANKK 姐妹 一直 在 赞 ！ BBLANKK 这 主要 还是 针对 能 吃 辣 ， 口味重 的 人 ！ BBLANKK 自我 觉得 也 超级 够味 BBLANKK ！ 还点 了 串串 ， 上来 以后 吃 的 发现 不是 自己 点 的 ， 服务员 去 核对 后 ， 又 重新 上 了 ！ BBLANKK 还 不停 的 抱歉 ！ BBLANKK 这 服务 也 不错 ， 如果 每个 服务员 脸上 在 挂些 微笑 则 更好 ！ BBLANKK 总之 吃 的 很 过瘾 ！ BBLANKK 价格 也 真的 很 便宜 ！ BBLANKK 撑 到 爆 ， 大众 买单 ， 两 人才 98 ！ 划算\n",
      "\n",
      "最近 微博 比较 火 的 一家 店 ， 突然 心血来潮 就 去 了 ！ 路上 堵车 ， 一个多 小时 才 到 ， 而且 到 地方 已经 快 7 点 了 吧 ， 还 剩 最后 一个 紫米 的 ， 赶紧 买买 买 ！ 还 买 了 绿野仙踪 ， 一个 香蕉 的 忘记 名字 了 ， 还 买 了 一盒 奶冻 一样 的 东西 ， 比较 粗线条 ， 名字 不 记得 了 也 没 拍 ！ 奶冻 还行 ， 不过 味道 没有 85 的 浓 ！ 面包 都 比较 健康 的 口感 ， 都 不怎么 甜 ， 紫米 的 刚 开始 接受 不了 ， 感觉 不怎么样 ， 里面 有 超多 紫米 ， 核桃 ， 葡萄干 ， 桂圆 ， 后来 越 吃 越 好吃 ， 香蕉 的 那个 香蕉 烤熟 了 ， 吃 起来 不 好吃 ， 绿野仙踪 挺好吃 的 ， 绿豆 抹 茶 跟 乳酪 ！ 略 咸 的 口味 ， 去 的 较晚 ， 没买 到 托斯卡 尼 不 开心 ， 下次 接着 去 ， 还要 尝试 巧克力 什么 的 那款 ！ 总的来说 不错 ， 价格 略贵 但是 用料 真的 太足 了 ！ 不过 喜欢 腻 喜欢 甜 的 朋友 就 不 推荐 你们 去 了\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\n'.join(' '.join(x) for x in sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we check the shape of the embedding vectors, each review is represented\n",
    "by multiple sentences. Each word (token) in a sentence is represented\n",
    "by a vector of length 1024. Would 1024 dimensions be able to represent all\n",
    "the latent meanings in the world? Maybe not, but a combination of them\n",
    "could capture important information in this specific corpus decently well.\n",
    "\n",
    "We need to find a way to use these embedings in our downstream classification\n",
    "task. There are many ways to do it. [This article](https://arxiv.org/abs/1806.06259)\n",
    "experimented many of them. Basically it says simper averages work good enough\n",
    "for most tasks.\n",
    "\n",
    "Another thing we noticed is that since we are splitting sentences only by 「。」，\n",
    "we missed separating sentences that ends with \"！\" or \"？\". As \"！\" and \"？\"\n",
    "do bear more semantics than period, it might not be a bad thing.  \n",
    "\n",
    "Anyway, let's improve our sentence splitting function a little bit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-20 14:32:04,661 INFO: 1 batches, avg len: 18.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "很少 吃 兔子 肉 ！\n",
      "BBLANKK 在 那 附近 本来 想 去 吃 泰国菜 的 ， 最后 还是 选择 了 这家 ， 果然 没 让 失望 ， 进去 后 的 座位 上 都 有 只 流氓兔 的 抱 枕 ， 点 了 一个 爆辣 的 兔头 ， 姐妹 吃 的 一直 赞不绝口 ！\n",
      "BBLANKK\n",
      "手 撕 烤 兔 ， 本 以为 是 自己 撕 的 ， 结果 是 服务员 到 你 面前 撕 ！\n",
      "BBLANKK 然后 拌 ！\n",
      "BBLANKK 那 味道 吃 的 真的 太 过瘾 了 ！\n",
      "BBLANKK 姐妹 一直 在 赞 ！\n",
      "BBLANKK 这 主要 还是 针对 能 吃 辣 ， 口味重 的 人 ！\n",
      "BBLANKK 自我 觉得 也 超级 够味 BBLANKK ！\n",
      "还点 了 串串 ， 上来 以后 吃 的 发现 不是 自己 点 的 ， 服务员 去 核对 后 ， 又 重新 上 了 ！\n",
      "BBLANKK 还 不停 的 抱歉 ！\n",
      "BBLANKK 这 服务 也 不错 ， 如果 每个 服务员 脸上 在 挂些 微笑 则 更好 ！\n",
      "BBLANKK 总之 吃 的 很 过瘾 ！\n",
      "BBLANKK 价格 也 真的 很 便宜 ！\n",
      "BBLANKK 撑 到 爆 ， 大众 买单 ， 两 人才 98 ！\n",
      "划算\n",
      "最近 微博 比较 火 的 一家 店 ， 突然 心血来潮 就 去 了 ！\n",
      "路上 堵车 ， 一个多 小时 才 到 ， 而且 到 地方 已经 快 7 点 了 吧 ， 还 剩 最后 一个 紫米 的 ， 赶紧 买买 买 ！\n",
      "还 买 了 绿野仙踪 ， 一个 香蕉 的 忘记 名字 了 ， 还 买 了 一盒 奶冻 一样 的 东西 ， 比较 粗线条 ， 名字 不 记得 了 也 没 拍 ！\n",
      "奶冻 还行 ， 不过 味道 没有 85 的 浓 ！\n",
      "面包 都 比较 健康 的 口感 ， 都 不怎么 甜 ， 紫米 的 刚 开始 接受 不了 ， 感觉 不怎么样 ， 里面 有 超多 紫米 ， 核桃 ， 葡萄干 ， 桂圆 ， 后来 越 吃 越 好吃 ， 香蕉 的 那个 香蕉 烤熟 了 ， 吃 起来 不 好吃 ， 绿野仙踪 挺好吃 的 ， 绿豆 抹 茶 跟 乳酪 ！\n",
      "略 咸 的 口味 ， 去 的 较晚 ， 没买 到 托斯卡 尼 不 开心 ， 下次 接着 去 ， 还要 尝试 巧克力 什么 的 那款 ！\n",
      "总的来说 不错 ， 价格 略贵 但是 用料 真的 太足 了 ！\n",
      "不过 喜欢 腻 喜欢 甜 的 朋友 就 不 推荐 你们 去 了\n",
      "\n",
      "(5, 1024) 24 24\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "RE_EXCL = re.compile('！+')\n",
    "RE_QUES = re.compile('？+')\n",
    "\n",
    "def split_by(s, regexp, char):\n",
    "    if char in s.strip(char):\n",
    "        tmp = regexp.split(s)\n",
    "        last = tmp.pop()\n",
    "        ret = [x + char for x in tmp]\n",
    "        ret.append(last)  # add last sentence back\n",
    "        return ret\n",
    "\n",
    "def article_to_sentences(articles):\n",
    "    sentences, aids, slens = [], [], []\n",
    "    for aid, article in enumerate(articles):\n",
    "        ss = article.split('。')\n",
    "        while ss:\n",
    "            s = ss.pop(0).strip()\n",
    "            if not s:\n",
    "                continue\n",
    "            tmp = split_by(s, RE_EXCL, '！')\n",
    "            if tmp:\n",
    "                ss = tmp + ss\n",
    "                continue\n",
    "                \n",
    "            tmp = split_by(s, RE_QUES, '？')\n",
    "            if tmp:\n",
    "                ss = tmp + ss\n",
    "                continue\n",
    "                \n",
    "            tokens = s.split()\n",
    "            sentences.append(tokens)\n",
    "            # keep a record of article ids and sentence length\n",
    "            # so that we know which sentence/word belongs to\n",
    "            # which article\n",
    "            aids.append(aid)\n",
    "            slens.append(len(tokens))\n",
    "    return sentences, aids, slens\n",
    "\n",
    "\n",
    "sentences, aids, slens = article_to_sentences(X_train[:2])\n",
    "print('\\n'.join(' '.join(x) for x in sentences))\n",
    "\n",
    "print()\n",
    "X_train_elmo = embedder.sents2elmo(sentences)\n",
    "print(X_train_elmo[0].shape, len(X_train_elmo), len(slens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to build the averages. We can do it word-by-word,\n",
    "or calculate averages in sentences first, then take sentence\n",
    "average for an article (review), which might've\n",
    "given shorter sentences higher weights than they deserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-20 14:33:28,180 INFO: 6 batches, avg len: 14.7\n"
     ]
    }
   ],
   "source": [
    "sentences, aids, slens = article_to_sentences(X_test[:10])\n",
    "embs = embedder.sents2elmo(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>1024</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.068202</td>\n",
       "      <td>0.293435</td>\n",
       "      <td>-0.946647</td>\n",
       "      <td>0.373405</td>\n",
       "      <td>0.019808</td>\n",
       "      <td>-0.310937</td>\n",
       "      <td>-0.316767</td>\n",
       "      <td>-0.079124</td>\n",
       "      <td>-0.098896</td>\n",
       "      <td>-0.287463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508182</td>\n",
       "      <td>-0.198488</td>\n",
       "      <td>0.178393</td>\n",
       "      <td>-0.403227</td>\n",
       "      <td>-0.501390</td>\n",
       "      <td>0.386936</td>\n",
       "      <td>0.076814</td>\n",
       "      <td>-0.177638</td>\n",
       "      <td>0.216966</td>\n",
       "      <td>-0.211923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.028542</td>\n",
       "      <td>0.093681</td>\n",
       "      <td>-0.924516</td>\n",
       "      <td>0.674874</td>\n",
       "      <td>-0.074027</td>\n",
       "      <td>-0.198827</td>\n",
       "      <td>-0.504699</td>\n",
       "      <td>0.062472</td>\n",
       "      <td>0.138705</td>\n",
       "      <td>-0.276513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588356</td>\n",
       "      <td>-0.263873</td>\n",
       "      <td>0.328776</td>\n",
       "      <td>-0.450251</td>\n",
       "      <td>-0.257557</td>\n",
       "      <td>0.023268</td>\n",
       "      <td>-0.341576</td>\n",
       "      <td>-0.014883</td>\n",
       "      <td>0.103347</td>\n",
       "      <td>-0.061155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.248675</td>\n",
       "      <td>0.021631</td>\n",
       "      <td>-1.012321</td>\n",
       "      <td>0.531638</td>\n",
       "      <td>0.065087</td>\n",
       "      <td>-0.145901</td>\n",
       "      <td>-0.556056</td>\n",
       "      <td>-0.039598</td>\n",
       "      <td>0.485349</td>\n",
       "      <td>0.047028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317467</td>\n",
       "      <td>-0.099202</td>\n",
       "      <td>0.078911</td>\n",
       "      <td>-0.304988</td>\n",
       "      <td>0.038534</td>\n",
       "      <td>0.122042</td>\n",
       "      <td>-0.422591</td>\n",
       "      <td>-0.234440</td>\n",
       "      <td>0.100334</td>\n",
       "      <td>-0.086534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.121712</td>\n",
       "      <td>0.191930</td>\n",
       "      <td>-1.231352</td>\n",
       "      <td>0.404950</td>\n",
       "      <td>0.143160</td>\n",
       "      <td>-0.060729</td>\n",
       "      <td>0.188212</td>\n",
       "      <td>-0.085650</td>\n",
       "      <td>0.169458</td>\n",
       "      <td>-0.272459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143824</td>\n",
       "      <td>0.124883</td>\n",
       "      <td>0.505670</td>\n",
       "      <td>-0.558850</td>\n",
       "      <td>-0.620959</td>\n",
       "      <td>0.625774</td>\n",
       "      <td>0.275083</td>\n",
       "      <td>-0.248307</td>\n",
       "      <td>0.324095</td>\n",
       "      <td>-0.462545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.251268</td>\n",
       "      <td>0.366207</td>\n",
       "      <td>-1.047636</td>\n",
       "      <td>0.246586</td>\n",
       "      <td>-0.294999</td>\n",
       "      <td>0.240501</td>\n",
       "      <td>-0.355867</td>\n",
       "      <td>0.071590</td>\n",
       "      <td>0.111405</td>\n",
       "      <td>-0.226960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328104</td>\n",
       "      <td>-0.072210</td>\n",
       "      <td>0.584550</td>\n",
       "      <td>-0.452596</td>\n",
       "      <td>-0.193370</td>\n",
       "      <td>0.233115</td>\n",
       "      <td>0.113667</td>\n",
       "      <td>-0.072564</td>\n",
       "      <td>0.154790</td>\n",
       "      <td>-0.488066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.120469</td>\n",
       "      <td>0.011523</td>\n",
       "      <td>-1.135528</td>\n",
       "      <td>0.837119</td>\n",
       "      <td>0.166698</td>\n",
       "      <td>-0.525736</td>\n",
       "      <td>-0.585312</td>\n",
       "      <td>0.046266</td>\n",
       "      <td>0.663572</td>\n",
       "      <td>0.158238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305730</td>\n",
       "      <td>-0.132625</td>\n",
       "      <td>-0.224237</td>\n",
       "      <td>-0.227819</td>\n",
       "      <td>0.195378</td>\n",
       "      <td>-0.319985</td>\n",
       "      <td>-0.537222</td>\n",
       "      <td>-0.356351</td>\n",
       "      <td>-0.121881</td>\n",
       "      <td>-0.036729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.158894</td>\n",
       "      <td>0.032087</td>\n",
       "      <td>-1.188803</td>\n",
       "      <td>0.605884</td>\n",
       "      <td>-0.230254</td>\n",
       "      <td>0.110983</td>\n",
       "      <td>-0.513036</td>\n",
       "      <td>0.277207</td>\n",
       "      <td>0.419474</td>\n",
       "      <td>-0.207109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077929</td>\n",
       "      <td>0.107817</td>\n",
       "      <td>0.205626</td>\n",
       "      <td>-0.079184</td>\n",
       "      <td>-0.238272</td>\n",
       "      <td>0.354426</td>\n",
       "      <td>-0.160015</td>\n",
       "      <td>-0.219914</td>\n",
       "      <td>-0.018861</td>\n",
       "      <td>-0.255687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001826</td>\n",
       "      <td>0.304018</td>\n",
       "      <td>-0.801234</td>\n",
       "      <td>0.362024</td>\n",
       "      <td>-0.059323</td>\n",
       "      <td>-0.169137</td>\n",
       "      <td>-0.137594</td>\n",
       "      <td>0.014599</td>\n",
       "      <td>0.292199</td>\n",
       "      <td>-0.334517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750622</td>\n",
       "      <td>-0.212787</td>\n",
       "      <td>0.395819</td>\n",
       "      <td>-0.112058</td>\n",
       "      <td>-0.742296</td>\n",
       "      <td>0.169252</td>\n",
       "      <td>-0.220114</td>\n",
       "      <td>-0.057841</td>\n",
       "      <td>0.079855</td>\n",
       "      <td>-0.347297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.119300</td>\n",
       "      <td>0.060534</td>\n",
       "      <td>-0.907626</td>\n",
       "      <td>0.326221</td>\n",
       "      <td>-0.129374</td>\n",
       "      <td>0.134551</td>\n",
       "      <td>-0.322363</td>\n",
       "      <td>0.180659</td>\n",
       "      <td>0.279821</td>\n",
       "      <td>-0.278353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574352</td>\n",
       "      <td>-0.240929</td>\n",
       "      <td>0.182954</td>\n",
       "      <td>-0.081244</td>\n",
       "      <td>-0.273950</td>\n",
       "      <td>0.306851</td>\n",
       "      <td>-0.160054</td>\n",
       "      <td>0.057242</td>\n",
       "      <td>0.103492</td>\n",
       "      <td>-0.242089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.045324</td>\n",
       "      <td>0.399205</td>\n",
       "      <td>-1.057199</td>\n",
       "      <td>0.490464</td>\n",
       "      <td>0.064823</td>\n",
       "      <td>-0.298407</td>\n",
       "      <td>-0.111564</td>\n",
       "      <td>-0.027645</td>\n",
       "      <td>0.063582</td>\n",
       "      <td>-0.403712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404983</td>\n",
       "      <td>-0.216591</td>\n",
       "      <td>0.170507</td>\n",
       "      <td>-0.260297</td>\n",
       "      <td>-0.485226</td>\n",
       "      <td>0.482495</td>\n",
       "      <td>-0.006189</td>\n",
       "      <td>-0.139399</td>\n",
       "      <td>0.120037</td>\n",
       "      <td>-0.254346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1         2         3         4         5         6         7     \\\n",
       "0                                                                         \n",
       "0  0.068202  0.293435 -0.946647  0.373405  0.019808 -0.310937 -0.316767   \n",
       "1 -0.028542  0.093681 -0.924516  0.674874 -0.074027 -0.198827 -0.504699   \n",
       "2  0.248675  0.021631 -1.012321  0.531638  0.065087 -0.145901 -0.556056   \n",
       "3  0.121712  0.191930 -1.231352  0.404950  0.143160 -0.060729  0.188212   \n",
       "4  0.251268  0.366207 -1.047636  0.246586 -0.294999  0.240501 -0.355867   \n",
       "5 -0.120469  0.011523 -1.135528  0.837119  0.166698 -0.525736 -0.585312   \n",
       "6  0.158894  0.032087 -1.188803  0.605884 -0.230254  0.110983 -0.513036   \n",
       "7  0.001826  0.304018 -0.801234  0.362024 -0.059323 -0.169137 -0.137594   \n",
       "8  0.119300  0.060534 -0.907626  0.326221 -0.129374  0.134551 -0.322363   \n",
       "9  0.045324  0.399205 -1.057199  0.490464  0.064823 -0.298407 -0.111564   \n",
       "\n",
       "       8         9         10      ...         1015      1016      1017  \\\n",
       "0                                  ...                                    \n",
       "0 -0.079124 -0.098896 -0.287463    ...     0.508182 -0.198488  0.178393   \n",
       "1  0.062472  0.138705 -0.276513    ...     0.588356 -0.263873  0.328776   \n",
       "2 -0.039598  0.485349  0.047028    ...     0.317467 -0.099202  0.078911   \n",
       "3 -0.085650  0.169458 -0.272459    ...     0.143824  0.124883  0.505670   \n",
       "4  0.071590  0.111405 -0.226960    ...     0.328104 -0.072210  0.584550   \n",
       "5  0.046266  0.663572  0.158238    ...     0.305730 -0.132625 -0.224237   \n",
       "6  0.277207  0.419474 -0.207109    ...     0.077929  0.107817  0.205626   \n",
       "7  0.014599  0.292199 -0.334517    ...     0.750622 -0.212787  0.395819   \n",
       "8  0.180659  0.279821 -0.278353    ...     0.574352 -0.240929  0.182954   \n",
       "9 -0.027645  0.063582 -0.403712    ...     0.404983 -0.216591  0.170507   \n",
       "\n",
       "       1018      1019      1020      1021      1022      1023      1024  \n",
       "0                                                                        \n",
       "0 -0.403227 -0.501390  0.386936  0.076814 -0.177638  0.216966 -0.211923  \n",
       "1 -0.450251 -0.257557  0.023268 -0.341576 -0.014883  0.103347 -0.061155  \n",
       "2 -0.304988  0.038534  0.122042 -0.422591 -0.234440  0.100334 -0.086534  \n",
       "3 -0.558850 -0.620959  0.625774  0.275083 -0.248307  0.324095 -0.462545  \n",
       "4 -0.452596 -0.193370  0.233115  0.113667 -0.072564  0.154790 -0.488066  \n",
       "5 -0.227819  0.195378 -0.319985 -0.537222 -0.356351 -0.121881 -0.036729  \n",
       "6 -0.079184 -0.238272  0.354426 -0.160015 -0.219914 -0.018861 -0.255687  \n",
       "7 -0.112058 -0.742296  0.169252 -0.220114 -0.057841  0.079855 -0.347297  \n",
       "8 -0.081244 -0.273950  0.306851 -0.160054  0.057242  0.103492 -0.242089  \n",
       "9 -0.260297 -0.485226  0.482495 -0.006189 -0.139399  0.120037 -0.254346  \n",
       "\n",
       "[10 rows x 1024 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take sentence average on words\n",
    "sents_avg = np.vstack(np.mean(x, axis=0) for x in embs)\n",
    "df = pd.DataFrame(np.hstack([np.array([aids]).T, sents_avg]))\n",
    "# Then take article avearges based on sentences\n",
    "# the first column are the article ids\n",
    "df[0] = df[0].astype('int')\n",
    "df.groupby(0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how to take averages word by word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>1024</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.101779</td>\n",
       "      <td>0.283301</td>\n",
       "      <td>-0.900231</td>\n",
       "      <td>0.345071</td>\n",
       "      <td>0.022835</td>\n",
       "      <td>-0.299208</td>\n",
       "      <td>-0.232614</td>\n",
       "      <td>-0.100858</td>\n",
       "      <td>-0.100119</td>\n",
       "      <td>-0.260453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555478</td>\n",
       "      <td>-0.215898</td>\n",
       "      <td>0.132628</td>\n",
       "      <td>-0.422329</td>\n",
       "      <td>-0.462794</td>\n",
       "      <td>0.295195</td>\n",
       "      <td>0.064091</td>\n",
       "      <td>-0.166212</td>\n",
       "      <td>0.169991</td>\n",
       "      <td>-0.169296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.070025</td>\n",
       "      <td>0.063162</td>\n",
       "      <td>-0.878004</td>\n",
       "      <td>0.743448</td>\n",
       "      <td>-0.069338</td>\n",
       "      <td>-0.124913</td>\n",
       "      <td>-0.556164</td>\n",
       "      <td>-0.026335</td>\n",
       "      <td>0.243542</td>\n",
       "      <td>-0.211147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687062</td>\n",
       "      <td>-0.255119</td>\n",
       "      <td>0.312055</td>\n",
       "      <td>-0.457865</td>\n",
       "      <td>-0.279171</td>\n",
       "      <td>0.006943</td>\n",
       "      <td>-0.281550</td>\n",
       "      <td>0.003033</td>\n",
       "      <td>0.132788</td>\n",
       "      <td>-0.011245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.194546</td>\n",
       "      <td>-0.069376</td>\n",
       "      <td>-0.943380</td>\n",
       "      <td>0.561626</td>\n",
       "      <td>0.017150</td>\n",
       "      <td>0.002253</td>\n",
       "      <td>-0.408099</td>\n",
       "      <td>-0.051316</td>\n",
       "      <td>0.345255</td>\n",
       "      <td>-0.165207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.461930</td>\n",
       "      <td>-0.164422</td>\n",
       "      <td>0.247815</td>\n",
       "      <td>-0.450748</td>\n",
       "      <td>-0.010738</td>\n",
       "      <td>0.114379</td>\n",
       "      <td>-0.215294</td>\n",
       "      <td>-0.125112</td>\n",
       "      <td>0.170125</td>\n",
       "      <td>-0.207496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.281636</td>\n",
       "      <td>0.127619</td>\n",
       "      <td>-0.966139</td>\n",
       "      <td>0.287935</td>\n",
       "      <td>0.171048</td>\n",
       "      <td>-0.079147</td>\n",
       "      <td>-0.015877</td>\n",
       "      <td>0.095158</td>\n",
       "      <td>0.081275</td>\n",
       "      <td>-0.302310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443954</td>\n",
       "      <td>-0.042620</td>\n",
       "      <td>0.261498</td>\n",
       "      <td>-0.449750</td>\n",
       "      <td>-0.626974</td>\n",
       "      <td>0.356350</td>\n",
       "      <td>0.132579</td>\n",
       "      <td>-0.321036</td>\n",
       "      <td>0.315697</td>\n",
       "      <td>-0.345978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.144019</td>\n",
       "      <td>0.258029</td>\n",
       "      <td>-1.091062</td>\n",
       "      <td>0.266817</td>\n",
       "      <td>-0.081337</td>\n",
       "      <td>0.245391</td>\n",
       "      <td>-0.244364</td>\n",
       "      <td>0.084588</td>\n",
       "      <td>0.071181</td>\n",
       "      <td>-0.242540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344382</td>\n",
       "      <td>-0.072969</td>\n",
       "      <td>0.427867</td>\n",
       "      <td>-0.324701</td>\n",
       "      <td>-0.040438</td>\n",
       "      <td>0.153624</td>\n",
       "      <td>-0.159518</td>\n",
       "      <td>0.031568</td>\n",
       "      <td>0.105475</td>\n",
       "      <td>-0.480427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.047805</td>\n",
       "      <td>0.099159</td>\n",
       "      <td>-0.922499</td>\n",
       "      <td>0.560363</td>\n",
       "      <td>0.175776</td>\n",
       "      <td>-0.301265</td>\n",
       "      <td>-0.403926</td>\n",
       "      <td>-0.062262</td>\n",
       "      <td>0.414132</td>\n",
       "      <td>-0.095919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588578</td>\n",
       "      <td>-0.120086</td>\n",
       "      <td>0.178956</td>\n",
       "      <td>-0.372808</td>\n",
       "      <td>0.113399</td>\n",
       "      <td>-0.096326</td>\n",
       "      <td>-0.386146</td>\n",
       "      <td>-0.082621</td>\n",
       "      <td>-0.064487</td>\n",
       "      <td>-0.211222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.150593</td>\n",
       "      <td>0.045343</td>\n",
       "      <td>-1.105080</td>\n",
       "      <td>0.514560</td>\n",
       "      <td>-0.154937</td>\n",
       "      <td>0.297473</td>\n",
       "      <td>-0.400714</td>\n",
       "      <td>0.175799</td>\n",
       "      <td>0.418541</td>\n",
       "      <td>-0.212346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262562</td>\n",
       "      <td>0.139245</td>\n",
       "      <td>0.398199</td>\n",
       "      <td>-0.147461</td>\n",
       "      <td>-0.227501</td>\n",
       "      <td>0.350058</td>\n",
       "      <td>-0.038029</td>\n",
       "      <td>-0.111012</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>-0.209893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.054791</td>\n",
       "      <td>0.211176</td>\n",
       "      <td>-0.810110</td>\n",
       "      <td>0.251320</td>\n",
       "      <td>-0.028393</td>\n",
       "      <td>-0.247055</td>\n",
       "      <td>-0.200220</td>\n",
       "      <td>-0.002998</td>\n",
       "      <td>0.196519</td>\n",
       "      <td>-0.311758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.742207</td>\n",
       "      <td>-0.215268</td>\n",
       "      <td>0.291482</td>\n",
       "      <td>-0.181914</td>\n",
       "      <td>-0.634936</td>\n",
       "      <td>0.153558</td>\n",
       "      <td>-0.252822</td>\n",
       "      <td>-0.046519</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>-0.187608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.133544</td>\n",
       "      <td>0.082850</td>\n",
       "      <td>-0.978896</td>\n",
       "      <td>0.402337</td>\n",
       "      <td>-0.032145</td>\n",
       "      <td>0.132255</td>\n",
       "      <td>-0.392965</td>\n",
       "      <td>0.290704</td>\n",
       "      <td>0.302420</td>\n",
       "      <td>-0.203162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533943</td>\n",
       "      <td>-0.190472</td>\n",
       "      <td>0.145426</td>\n",
       "      <td>-0.108401</td>\n",
       "      <td>-0.172996</td>\n",
       "      <td>0.393919</td>\n",
       "      <td>-0.295246</td>\n",
       "      <td>0.145372</td>\n",
       "      <td>0.017513</td>\n",
       "      <td>-0.150516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.046585</td>\n",
       "      <td>0.279045</td>\n",
       "      <td>-0.998540</td>\n",
       "      <td>0.436874</td>\n",
       "      <td>0.025244</td>\n",
       "      <td>-0.248909</td>\n",
       "      <td>0.048599</td>\n",
       "      <td>0.054734</td>\n",
       "      <td>0.124040</td>\n",
       "      <td>-0.409424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.442144</td>\n",
       "      <td>-0.300073</td>\n",
       "      <td>0.139323</td>\n",
       "      <td>-0.363365</td>\n",
       "      <td>-0.491794</td>\n",
       "      <td>0.431296</td>\n",
       "      <td>-0.010705</td>\n",
       "      <td>-0.172927</td>\n",
       "      <td>0.135138</td>\n",
       "      <td>-0.279213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1         2         3         4         5         6         7     \\\n",
       "0                                                                         \n",
       "0  0.101779  0.283301 -0.900231  0.345071  0.022835 -0.299208 -0.232614   \n",
       "1  0.070025  0.063162 -0.878004  0.743448 -0.069338 -0.124913 -0.556164   \n",
       "2  0.194546 -0.069376 -0.943380  0.561626  0.017150  0.002253 -0.408099   \n",
       "3  0.281636  0.127619 -0.966139  0.287935  0.171048 -0.079147 -0.015877   \n",
       "4  0.144019  0.258029 -1.091062  0.266817 -0.081337  0.245391 -0.244364   \n",
       "5  0.047805  0.099159 -0.922499  0.560363  0.175776 -0.301265 -0.403926   \n",
       "6  0.150593  0.045343 -1.105080  0.514560 -0.154937  0.297473 -0.400714   \n",
       "7 -0.054791  0.211176 -0.810110  0.251320 -0.028393 -0.247055 -0.200220   \n",
       "8  0.133544  0.082850 -0.978896  0.402337 -0.032145  0.132255 -0.392965   \n",
       "9 -0.046585  0.279045 -0.998540  0.436874  0.025244 -0.248909  0.048599   \n",
       "\n",
       "       8         9         10      ...         1015      1016      1017  \\\n",
       "0                                  ...                                    \n",
       "0 -0.100858 -0.100119 -0.260453    ...     0.555478 -0.215898  0.132628   \n",
       "1 -0.026335  0.243542 -0.211147    ...     0.687062 -0.255119  0.312055   \n",
       "2 -0.051316  0.345255 -0.165207    ...     0.461930 -0.164422  0.247815   \n",
       "3  0.095158  0.081275 -0.302310    ...     0.443954 -0.042620  0.261498   \n",
       "4  0.084588  0.071181 -0.242540    ...     0.344382 -0.072969  0.427867   \n",
       "5 -0.062262  0.414132 -0.095919    ...     0.588578 -0.120086  0.178956   \n",
       "6  0.175799  0.418541 -0.212346    ...     0.262562  0.139245  0.398199   \n",
       "7 -0.002998  0.196519 -0.311758    ...     0.742207 -0.215268  0.291482   \n",
       "8  0.290704  0.302420 -0.203162    ...     0.533943 -0.190472  0.145426   \n",
       "9  0.054734  0.124040 -0.409424    ...     0.442144 -0.300073  0.139323   \n",
       "\n",
       "       1018      1019      1020      1021      1022      1023      1024  \n",
       "0                                                                        \n",
       "0 -0.422329 -0.462794  0.295195  0.064091 -0.166212  0.169991 -0.169296  \n",
       "1 -0.457865 -0.279171  0.006943 -0.281550  0.003033  0.132788 -0.011245  \n",
       "2 -0.450748 -0.010738  0.114379 -0.215294 -0.125112  0.170125 -0.207496  \n",
       "3 -0.449750 -0.626974  0.356350  0.132579 -0.321036  0.315697 -0.345978  \n",
       "4 -0.324701 -0.040438  0.153624 -0.159518  0.031568  0.105475 -0.480427  \n",
       "5 -0.372808  0.113399 -0.096326 -0.386146 -0.082621 -0.064487 -0.211222  \n",
       "6 -0.147461 -0.227501  0.350058 -0.038029 -0.111012  0.050968 -0.209893  \n",
       "7 -0.181914 -0.634936  0.153558 -0.252822 -0.046519  0.042969 -0.187608  \n",
       "8 -0.108401 -0.172996  0.393919 -0.295246  0.145372  0.017513 -0.150516  \n",
       "9 -0.363365 -0.491794  0.431296 -0.010705 -0.172927  0.135138 -0.279213  \n",
       "\n",
       "[10 rows x 1024 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_aids = np.repeat(aids, slens) # word article ids\n",
    "words = np.vstack(embs)\n",
    "df = pd.DataFrame(np.hstack([np.array([word_aids]).T, words]))\n",
    "# Then take article avearges based on sentences\n",
    "# the first column are the article ids\n",
    "df[0] = df[0].astype('int')\n",
    "df.groupby(0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-20 15:47:17,811 INFO: char embedding size: 8844\n",
      "2018-11-20 15:47:18,191 INFO: word embedding size: 69598\n",
      "2018-11-20 15:47:23,175 INFO: Model(\n",
      "  (token_embedder): ConvTokenEmbedder(\n",
      "    (word_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(69598, 100, padding_idx=3)\n",
      "    )\n",
      "    (char_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(8844, 50, padding_idx=8841)\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
      "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
      "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
      "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
      "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
      "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
      "    )\n",
      "    (highways): Highway(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
      "  )\n",
      "  (encoder): ElmobiLm(\n",
      "    (forward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (forward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from elmoformanylangs import Embedder as ElmoEmbedder\n",
    "\n",
    "embedder = ElmoEmbedder('data/elmo-zhs-100k-mc4-lr0.001/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-20 15:47:10,826 INFO: char embedding size: 6169\n",
      "2018-11-20 15:47:11,218 INFO: word embedding size: 71222\n",
      "2018-11-20 15:47:16,098 INFO: Model(\n",
      "  (token_embedder): ConvTokenEmbedder(\n",
      "    (word_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(71222, 100, padding_idx=3)\n",
      "    )\n",
      "    (char_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(6169, 50, padding_idx=6166)\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
      "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
      "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
      "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
      "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
      "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
      "    )\n",
      "    (highways): Highway(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
      "  )\n",
      "  (encoder): ElmobiLm(\n",
      "    (forward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (forward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "embedder2 = ElmoEmbedder('../data/zhs.model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "from elmoformanylangs import Embedder as ElmoEmbedder\n",
    "from fgclassifier.features import FeaturePipeline, logger, article_to_sentences\n",
    "\n",
    "\n",
    "class ElmoRawVectorizer(BaseEstimator):\n",
    "    \"\"\"\n",
    "    Elmo Word Embedding with pre-trained models\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "        embedder:  where you save ElMoForManyLangs model\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, embedder, batch_size=64, split_sentence=True):\n",
    "        if isinstance(embedder, str):\n",
    "            embedder = ElmoEmbedder(embedder, batch_size=batch_size)\n",
    "        else:\n",
    "            embedder.batch_size = batch_size\n",
    "        self.embedder = embedder\n",
    "        # Whether to split reviews into sentences before passing to embedder\n",
    "        # otherwise a review will be considered as one sentence.\n",
    "        self.split_sentence = split_sentence\n",
    "        \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X, y).transform(X)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # No fitting needed, because we are using pre-trained\n",
    "        # models, which is already loaded while initializing\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        sentences, aids, slens = article_to_sentences(X, self.split_sentence)\n",
    "        embs = embedder.sents2elmo(sentences)\n",
    "        return (aids, slens, embs)\n",
    "    \n",
    "\n",
    "class ElmoTransformer(ElmoVectorizer):\n",
    "    \"\"\"Transform ELMo embeddings to 1D features\n",
    "    by averaging word vectors for all sentences\n",
    "    \n",
    "    Parameters\n",
    "    ----------------------------------\n",
    "        strategy:  How to calcualte the vector. Choose from\n",
    "                   - word:      word by word average\n",
    "                   - sentence:  take in-sentence average by words first,\n",
    "                                then take sentence averages for articles\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, strategy='word'):\n",
    "        self.strategy = strategy\n",
    "        \n",
    "    def transform(self, X):\n",
    "        aids, slens, embs = X  # X must be a tuple\n",
    "        if self.strategy == 'word':\n",
    "            word_aids = np.repeat(aids, slens) # word article ids\n",
    "            words = np.vstack(embs)\n",
    "            df = pd.DataFrame(np.hstack([np.array([word_aids]).T, words]))\n",
    "        else:\n",
    "            sents_avg = np.vstack(np.mean(x, axis=0) for x in embs)\n",
    "            df = pd.DataFrame(np.hstack([np.array([aids]).T, sents_avg]))\n",
    "        df[0] = df[0].astype('int')\n",
    "        df = df.groupby(0).mean()\n",
    "        return df.values\n",
    "    \n",
    "fm_spec = {\n",
    "    'elmo_raw': ElmoRawVectorizer(embedder, batch_size=32),\n",
    "    # embedder2 uses the official pre-tained model downloaded from\n",
    "    #   https://github.com/HIT-SCIR/ELMoForManyLangs\n",
    "    'elmo_raw2': ElmoRawVectorizer(embedder2, batch_size=32),\n",
    "    'elmo_raw3': ElmoRawVectorizer(embedder, batch_size=32, split_sentence=False),\n",
    "    'elmo_raw4': ElmoRawVectorizer(embedder2, batch_size=32, split_sentence=False),\n",
    "    'elmo': ['elmo_raw', ElmoTransformer()],\n",
    "    'elmo2': ['elmo_raw2', ElmoTransformer()],\n",
    "    'elmo3': ['elmo_raw3', ElmoTransformer()],\n",
    "    'elmo4': ['elmo_raw4', ElmoTransformer()],\n",
    "    'elmo_sent_avg': ['elmo_raw', ElmoTransformer(strategy='sentence')],\n",
    "    'elmo_sent_avg2': ['elmo_raw2', ElmoTransformer(strategy='sentence')],\n",
    "    'elmo_svd_500': ['elmo', TruncatedSVD(n_components=500)],\n",
    "    'elmo_sent_avg_svd_500': ['elmo_sent_avg', TruncatedSVD(n_components=500)],\n",
    "    'count': CountVectorizer(ngram_range=(1, 4), min_df=0.005, max_df=0.95),\n",
    "    'tfidf': ['count', TfidfTransformer],\n",
    "    'lsa_100': ['tfidf', TruncatedSVD(n_components=100)],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['elmo_raw', 'count', 'tfidf', 'elmo', 'elmo_sent_avg', 'elmo_svd_500', 'elmo_sent_avg_svd_500', 'lsa_100', 'elmo_sent_avg_svg_500', 'elmo_raw2', 'elmo2', 'elmo_sent_avg2'])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-20 16:35:00,773 INFO: Building features for elmo_raw...\n",
      "2018-11-20 16:35:00,775 INFO:   elmo_raw: fit_transform use cache.\n",
      "2018-11-20 16:35:00,777 INFO:   elmo_raw: transform use cache.\n",
      "2018-11-20 16:35:00,778 INFO: Building features for elmo_raw2...\n",
      "2018-11-20 16:35:00,781 INFO:   elmo_raw2: fit_transform use cache.\n",
      "2018-11-20 16:35:00,782 INFO:   elmo_raw2: transform use cache.\n",
      "2018-11-20 16:35:00,784 INFO: Building features for elmo_raw3...\n",
      "2018-11-20 16:35:02,189 INFO: 4 batches, avg len: 247.1\n"
     ]
    }
   ],
   "source": [
    "for name in fm_spec.keys():\n",
    "    logger.info(f'Building features for {name}...')\n",
    "    model = FeaturePipeline(name, spec=fm_spec, cache=fm)\n",
    "    model.fit_transform(X_train[:100])\n",
    "    model.transform(X_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_avg_scores, all_scores = defaultdict(dict), defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-20 16:22:44,840 INFO: ======== Feature Model: elmo =========\n",
      "2018-11-20 16:22:44,841 INFO: Train for elmo -> LinearSVC...\n",
      "2018-11-20 16:22:49,183 INFO: [Validate]: F1 Scores\n",
      "2018-11-20 16:22:49,185 INFO:   location_traffic_convenience            \t0.6875\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "2018-11-20 16:22:49,187 INFO:   location_distance_from_business_district\t0.4737\n",
      "2018-11-20 16:22:49,189 INFO:   location_easy_to_find                   \t0.5139\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "2018-11-20 16:22:49,191 INFO:   service_wait_time                       \t0.2963\n",
      "2018-11-20 16:22:49,194 INFO:   service_waiters_attitude                \t0.1667\n",
      "2018-11-20 16:22:49,196 INFO:   service_parking_convenience             \t1.0000\n",
      "2018-11-20 16:22:49,197 INFO:   service_serving_speed                   \t0.5139\n",
      "2018-11-20 16:22:49,201 INFO:   price_level                             \t0.1818\n",
      "2018-11-20 16:22:49,203 INFO:   price_cost_effective                    \t0.4778\n",
      "2018-11-20 16:22:49,206 INFO:   price_discount                          \t0.4329\n",
      "2018-11-20 16:22:49,208 INFO:   environment_decoration                  \t0.4924\n",
      "2018-11-20 16:22:49,210 INFO:   environment_noise                       \t0.8667\n",
      "2018-11-20 16:22:49,213 INFO:   environment_space                       \t0.0455\n",
      "2018-11-20 16:22:49,220 INFO:   environment_cleaness                    \t0.2815\n",
      "2018-11-20 16:22:49,225 INFO:   dish_portion                            \t0.1875\n",
      "2018-11-20 16:22:49,232 INFO:   dish_taste                              \t0.2652\n",
      "2018-11-20 16:22:49,235 INFO:   dish_look                               \t0.2188\n",
      "2018-11-20 16:22:49,238 INFO:   dish_recommendation                     \t0.1905\n",
      "2018-11-20 16:22:49,241 INFO:   others_overall_experience               \t0.5231\n",
      "2018-11-20 16:22:49,247 INFO:   others_willing_to_consume_again         \t0.5833\n",
      "2018-11-20 16:22:49,248 INFO: ---------------------------------------------------\n",
      "2018-11-20 16:22:49,250 INFO: 【elmo -> LinearSVC】: 0.4199\n",
      "2018-11-20 16:22:49,252 INFO: ---------------------------------------------------\n",
      "2018-11-20 16:22:49,255 INFO: Train for elmo -> Ridge...\n",
      "2018-11-20 16:22:49,420 INFO: [Validate]: F1 Scores\n",
      "2018-11-20 16:22:49,422 INFO:   location_traffic_convenience            \t0.8039\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "2018-11-20 16:22:49,426 INFO:   location_distance_from_business_district\t0.4737\n",
      "2018-11-20 16:22:49,429 INFO:   location_easy_to_find                   \t0.2963\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "2018-11-20 16:22:49,431 INFO:   service_wait_time                       \t0.4737\n",
      "2018-11-20 16:22:49,433 INFO:   service_waiters_attitude                \t0.1667\n",
      "2018-11-20 16:22:49,436 INFO:   service_parking_convenience             \t0.4737\n",
      "2018-11-20 16:22:49,439 INFO:   service_serving_speed                   \t0.4737\n",
      "2018-11-20 16:22:49,441 INFO:   price_level                             \t0.3485\n",
      "2018-11-20 16:22:49,443 INFO:   price_cost_effective                    \t0.4118\n",
      "2018-11-20 16:22:49,445 INFO:   price_discount                          \t0.5524\n",
      "2018-11-20 16:22:49,447 INFO:   environment_decoration                  \t0.7619\n",
      "2018-11-20 16:22:49,450 INFO:   environment_noise                       \t0.8039\n",
      "2018-11-20 16:22:49,452 INFO:   environment_space                       \t0.2222\n",
      "2018-11-20 16:22:49,454 INFO:   environment_cleaness                    \t0.3750\n",
      "2018-11-20 16:22:49,456 INFO:   dish_portion                            \t0.2792\n",
      "2018-11-20 16:22:49,458 INFO:   dish_taste                              \t0.2667\n",
      "2018-11-20 16:22:49,460 INFO:   dish_look                               \t0.2059\n",
      "2018-11-20 16:22:49,463 INFO:   dish_recommendation                     \t0.2963\n",
      "2018-11-20 16:22:49,465 INFO:   others_overall_experience               \t0.6190\n",
      "2018-11-20 16:22:49,467 INFO:   others_willing_to_consume_again         \t0.6703\n",
      "2018-11-20 16:22:49,468 INFO: ---------------------------------------------------\n",
      "2018-11-20 16:22:49,470 INFO: 【elmo -> Ridge】: 0.4487\n",
      "2018-11-20 16:22:49,471 INFO: ---------------------------------------------------\n",
      "2018-11-20 16:22:49,472 INFO: ======== Feature Model: elmo2 =========\n",
      "2018-11-20 16:22:49,473 INFO: Train for elmo2 -> LinearSVC...\n",
      "2018-11-20 16:22:54,308 INFO: [Validate]: F1 Scores\n",
      "2018-11-20 16:22:54,310 INFO:   location_traffic_convenience            \t0.6875\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "2018-11-20 16:22:54,312 INFO:   location_distance_from_business_district\t0.4737\n",
      "2018-11-20 16:22:54,314 INFO:   location_easy_to_find                   \t0.2745\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "2018-11-20 16:22:54,316 INFO:   service_wait_time                       \t0.2963\n",
      "2018-11-20 16:22:54,318 INFO:   service_waiters_attitude                \t0.1667\n",
      "2018-11-20 16:22:54,320 INFO:   service_parking_convenience             \t1.0000\n",
      "2018-11-20 16:22:54,323 INFO:   service_serving_speed                   \t0.5139\n",
      "2018-11-20 16:22:54,325 INFO:   price_level                             \t0.1500\n",
      "2018-11-20 16:22:54,328 INFO:   price_cost_effective                    \t0.8667\n",
      "2018-11-20 16:22:54,330 INFO:   price_discount                          \t0.4444\n",
      "2018-11-20 16:22:54,332 INFO:   environment_decoration                  \t0.6703\n",
      "2018-11-20 16:22:54,335 INFO:   environment_noise                       \t1.0000\n",
      "2018-11-20 16:22:54,337 INFO:   environment_space                       \t0.0455\n",
      "2018-11-20 16:22:54,339 INFO:   environment_cleaness                    \t0.2045\n",
      "2018-11-20 16:22:54,342 INFO:   dish_portion                            \t0.1875\n",
      "2018-11-20 16:22:54,344 INFO:   dish_taste                              \t0.3083\n",
      "2018-11-20 16:22:54,347 INFO:   dish_look                               \t0.2188\n",
      "2018-11-20 16:22:54,349 INFO:   dish_recommendation                     \t0.2222\n",
      "2018-11-20 16:22:54,352 INFO:   others_overall_experience               \t0.5231\n",
      "2018-11-20 16:22:54,354 INFO:   others_willing_to_consume_again         \t0.5833\n",
      "2018-11-20 16:22:54,357 INFO: ---------------------------------------------------\n",
      "2018-11-20 16:22:54,358 INFO: 【elmo2 -> LinearSVC】: 0.4419\n",
      "2018-11-20 16:22:54,360 INFO: ---------------------------------------------------\n",
      "2018-11-20 16:22:54,361 INFO: Train for elmo2 -> Ridge...\n",
      "2018-11-20 16:22:54,528 INFO: [Validate]: F1 Scores\n",
      "2018-11-20 16:22:54,530 INFO:   location_traffic_convenience            \t0.8039\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "2018-11-20 16:22:54,534 INFO:   location_distance_from_business_district\t0.4737\n",
      "2018-11-20 16:22:54,536 INFO:   location_easy_to_find                   \t0.2963\n",
      "2018-11-20 16:22:54,539 INFO:   service_wait_time                       \t1.0000\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-20 16:22:54,541 INFO:   service_waiters_attitude                \t0.1667\n",
      "2018-11-20 16:22:54,545 INFO:   service_parking_convenience             \t0.4737\n",
      "2018-11-20 16:22:54,549 INFO:   service_serving_speed                   \t0.4444\n",
      "2018-11-20 16:22:54,552 INFO:   price_level                             \t0.3485\n",
      "2018-11-20 16:22:54,554 INFO:   price_cost_effective                    \t0.4118\n",
      "2018-11-20 16:22:54,557 INFO:   price_discount                          \t0.5524\n",
      "2018-11-20 16:22:54,559 INFO:   environment_decoration                  \t0.7619\n",
      "2018-11-20 16:22:54,562 INFO:   environment_noise                       \t0.8039\n",
      "2018-11-20 16:22:54,564 INFO:   environment_space                       \t0.1667\n",
      "2018-11-20 16:22:54,566 INFO:   environment_cleaness                    \t0.2929\n",
      "2018-11-20 16:22:54,569 INFO:   dish_portion                            \t0.2792\n",
      "2018-11-20 16:22:54,571 INFO:   dish_taste                              \t0.3173\n",
      "2018-11-20 16:22:54,573 INFO:   dish_look                               \t0.2059\n",
      "2018-11-20 16:22:54,576 INFO:   dish_recommendation                     \t0.2963\n",
      "2018-11-20 16:22:54,578 INFO:   others_overall_experience               \t0.6190\n",
      "2018-11-20 16:22:54,580 INFO:   others_willing_to_consume_again         \t0.6703\n",
      "2018-11-20 16:22:54,581 INFO: ---------------------------------------------------\n",
      "2018-11-20 16:22:54,583 INFO: 【elmo2 -> Ridge】: 0.4692\n",
      "2018-11-20 16:22:54,583 INFO: ---------------------------------------------------\n",
      "2018-11-20 16:22:54,584 INFO: ======== Feature Model: elmo_sent_avg =========\n",
      "2018-11-20 16:22:54,586 INFO: Train for elmo_sent_avg -> LinearSVC...\n",
      "2018-11-20 16:22:58,759 INFO: [Validate]: F1 Scores\n",
      "2018-11-20 16:22:58,761 INFO:   location_traffic_convenience            \t0.6000\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "2018-11-20 16:22:58,763 INFO:   location_distance_from_business_district\t0.4737\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "2018-11-20 16:22:58,765 INFO:   location_easy_to_find                   \t0.1875\n",
      "2018-11-20 16:22:58,768 INFO:   service_wait_time                       \t0.4737\n",
      "2018-11-20 16:22:58,770 INFO:   service_waiters_attitude                \t0.2333\n",
      "2018-11-20 16:22:58,772 INFO:   service_parking_convenience             \t0.4737\n",
      "2018-11-20 16:22:58,774 INFO:   service_serving_speed                   \t0.2059\n",
      "2018-11-20 16:22:58,777 INFO:   price_level                             \t0.4417\n",
      "2018-11-20 16:22:58,779 INFO:   price_cost_effective                    \t0.4778\n",
      "2018-11-20 16:22:58,782 INFO:   price_discount                          \t0.2778\n",
      "2018-11-20 16:22:58,784 INFO:   environment_decoration                  \t0.4222\n",
      "2018-11-20 16:22:58,786 INFO:   environment_noise                       \t0.6703\n",
      "2018-11-20 16:22:58,789 INFO:   environment_space                       \t0.1500\n",
      "2018-11-20 16:22:58,791 INFO:   environment_cleaness                    \t0.4949\n",
      "2018-11-20 16:22:58,794 INFO:   dish_portion                            \t0.2679\n",
      "2018-11-20 16:22:58,796 INFO:   dish_taste                              \t0.5333\n",
      "2018-11-20 16:22:58,798 INFO:   dish_look                               \t0.2188\n",
      "2018-11-20 16:22:58,801 INFO:   dish_recommendation                     \t0.2963\n",
      "2018-11-20 16:22:58,803 INFO:   others_overall_experience               \t0.6190\n",
      "2018-11-20 16:22:58,805 INFO:   others_willing_to_consume_again         \t0.7917\n",
      "2018-11-20 16:22:58,807 INFO: ---------------------------------------------------\n",
      "2018-11-20 16:22:58,810 INFO: 【elmo_sent_avg -> LinearSVC】: 0.4155\n",
      "2018-11-20 16:22:58,819 INFO: ---------------------------------------------------\n",
      "2018-11-20 16:22:58,821 INFO: Train for elmo_sent_avg -> Ridge...\n",
      "2018-11-20 16:22:58,966 INFO: [Validate]: F1 Scores\n",
      "2018-11-20 16:22:58,967 INFO:   location_traffic_convenience            \t0.6875\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "2018-11-20 16:22:58,969 INFO:   location_distance_from_business_district\t0.4737\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "2018-11-20 16:22:58,972 INFO:   location_easy_to_find                   \t0.2059\n",
      "2018-11-20 16:22:58,974 INFO:   service_wait_time                       \t1.0000\n",
      "2018-11-20 16:22:58,977 INFO:   service_waiters_attitude                \t0.2652\n",
      "2018-11-20 16:22:58,979 INFO:   service_parking_convenience             \t0.4737\n",
      "2018-11-20 16:22:58,981 INFO:   service_serving_speed                   \t0.4737\n",
      "2018-11-20 16:22:58,983 INFO:   price_level                             \t0.3590\n",
      "2018-11-20 16:22:58,986 INFO:   price_cost_effective                    \t0.6875\n",
      "2018-11-20 16:22:58,988 INFO:   price_discount                          \t0.3385\n",
      "2018-11-20 16:22:58,990 INFO:   environment_decoration                  \t0.5238\n",
      "2018-11-20 16:22:58,993 INFO:   environment_noise                       \t0.6875\n",
      "2018-11-20 16:22:58,996 INFO:   environment_space                       \t0.2222\n",
      "2018-11-20 16:22:58,999 INFO:   environment_cleaness                    \t0.4505\n",
      "2018-11-20 16:22:59,001 INFO:   dish_portion                            \t0.2917\n",
      "2018-11-20 16:22:59,003 INFO:   dish_taste                              \t0.2292\n",
      "2018-11-20 16:22:59,005 INFO:   dish_look                               \t0.2188\n",
      "2018-11-20 16:22:59,007 INFO:   dish_recommendation                     \t0.2963\n",
      "2018-11-20 16:22:59,009 INFO:   others_overall_experience               \t0.6190\n",
      "2018-11-20 16:22:59,011 INFO:   others_willing_to_consume_again         \t0.5238\n",
      "2018-11-20 16:22:59,012 INFO: ---------------------------------------------------\n",
      "2018-11-20 16:22:59,013 INFO: 【elmo_sent_avg -> Ridge】: 0.4514\n",
      "2018-11-20 16:22:59,014 INFO: ---------------------------------------------------\n",
      "2018-11-20 16:22:59,015 INFO: ======== Feature Model: elmo_sent_avg2 =========\n",
      "2018-11-20 16:22:59,016 INFO: Train for elmo_sent_avg2 -> LinearSVC...\n",
      "2018-11-20 16:23:02,612 INFO: [Validate]: F1 Scores\n",
      "2018-11-20 16:23:02,613 INFO:   location_traffic_convenience            \t0.6000\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "2018-11-20 16:23:02,616 INFO:   location_distance_from_business_district\t0.4737\n",
      "2018-11-20 16:23:02,618 INFO:   location_easy_to_find                   \t0.2500\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "2018-11-20 16:23:02,620 INFO:   service_wait_time                       \t0.4737\n",
      "2018-11-20 16:23:02,622 INFO:   service_waiters_attitude                \t0.2333\n",
      "2018-11-20 16:23:02,624 INFO:   service_parking_convenience             \t0.4737\n",
      "2018-11-20 16:23:02,627 INFO:   service_serving_speed                   \t0.2059\n",
      "2018-11-20 16:23:02,629 INFO:   price_level                             \t0.3167\n",
      "2018-11-20 16:23:02,631 INFO:   price_cost_effective                    \t0.8667\n",
      "2018-11-20 16:23:02,633 INFO:   price_discount                          \t0.3162\n",
      "2018-11-20 16:23:02,636 INFO:   environment_decoration                  \t0.3485\n",
      "2018-11-20 16:23:02,638 INFO:   environment_noise                       \t0.6703\n",
      "2018-11-20 16:23:02,640 INFO:   environment_space                       \t0.1500\n",
      "2018-11-20 16:23:02,642 INFO:   environment_cleaness                    \t0.4949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-20 16:23:02,644 INFO:   dish_portion                            \t0.2679\n",
      "2018-11-20 16:23:02,647 INFO:   dish_taste                              \t0.5333\n",
      "2018-11-20 16:23:02,649 INFO:   dish_look                               \t0.2000\n",
      "2018-11-20 16:23:02,652 INFO:   dish_recommendation                     \t0.2963\n",
      "2018-11-20 16:23:02,654 INFO:   others_overall_experience               \t0.5744\n",
      "2018-11-20 16:23:02,656 INFO:   others_willing_to_consume_again         \t0.7917\n",
      "2018-11-20 16:23:02,657 INFO: ---------------------------------------------------\n",
      "2018-11-20 16:23:02,658 INFO: 【elmo_sent_avg2 -> LinearSVC】: 0.4269\n",
      "2018-11-20 16:23:02,660 INFO: ---------------------------------------------------\n",
      "2018-11-20 16:23:02,661 INFO: Train for elmo_sent_avg2 -> Ridge...\n",
      "2018-11-20 16:23:02,803 INFO: [Validate]: F1 Scores\n",
      "2018-11-20 16:23:02,805 INFO:   location_traffic_convenience            \t0.6875\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "2018-11-20 16:23:02,807 INFO:   location_distance_from_business_district\t0.4737\n",
      "2018-11-20 16:23:02,810 INFO:   location_easy_to_find                   \t0.2745\n",
      "2018-11-20 16:23:02,812 INFO:   service_wait_time                       \t1.0000\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "2018-11-20 16:23:02,815 INFO:   service_waiters_attitude                \t0.2652\n",
      "2018-11-20 16:23:02,818 INFO:   service_parking_convenience             \t0.4737\n",
      "2018-11-20 16:23:02,821 INFO:   service_serving_speed                   \t0.4737\n",
      "2018-11-20 16:23:02,823 INFO:   price_level                             \t0.3333\n",
      "2018-11-20 16:23:02,826 INFO:   price_cost_effective                    \t0.8667\n",
      "2018-11-20 16:23:02,829 INFO:   price_discount                          \t0.3385\n",
      "2018-11-20 16:23:02,831 INFO:   environment_decoration                  \t0.5238\n",
      "2018-11-20 16:23:02,834 INFO:   environment_noise                       \t0.6000\n",
      "2018-11-20 16:23:02,837 INFO:   environment_space                       \t0.2222\n",
      "2018-11-20 16:23:02,840 INFO:   environment_cleaness                    \t0.4505\n",
      "2018-11-20 16:23:02,842 INFO:   dish_portion                            \t0.2750\n",
      "2018-11-20 16:23:02,848 INFO:   dish_taste                              \t0.2714\n",
      "2018-11-20 16:23:02,854 INFO:   dish_look                               \t0.2188\n",
      "2018-11-20 16:23:02,857 INFO:   dish_recommendation                     \t0.2963\n",
      "2018-11-20 16:23:02,861 INFO:   others_overall_experience               \t0.6190\n",
      "2018-11-20 16:23:02,864 INFO:   others_willing_to_consume_again         \t0.5238\n",
      "2018-11-20 16:23:02,865 INFO: ---------------------------------------------------\n",
      "2018-11-20 16:23:02,866 INFO: 【elmo_sent_avg2 -> Ridge】: 0.4594\n",
      "2018-11-20 16:23:02,868 INFO: ---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from fgclassifier.train import fm_cross_check\n",
    "\n",
    "conf = {\n",
    "    'fm_cache': fm,\n",
    "    'y_train': y_train[:100],\n",
    "    'y_test': y_test[:10],\n",
    "    'results': {\n",
    "        'avg': all_avg_scores,\n",
    "        'all': all_scores\n",
    "    }\n",
    "}\n",
    "\n",
    "# fm_cross_check(\n",
    "#     ['tfidf'],\n",
    "#     ['ComplementNB', 'DummyStratified'], **conf)\n",
    "\n",
    "# We'd only need to run the dummy models on one feature model,\n",
    "# as they do not care about the features\n",
    "results = fm_cross_check(\n",
    "    ['elmo',\n",
    "     'elmo2',\n",
    "     'elmo_sent_avg',\n",
    "     'elmo_sent_avg2'],\n",
    "    ['LinearSVC', 'Ridge'], **conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here each row is a sentence, with all words in the sentence averaged.\n",
    "We can see that Review 0 has 12 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
