{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook tries out the state-of-the-art word embeding model [ELMo](https://allennlp.org/elmo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-14 22:30:31,568 [INFO] Read cache data/train/sentiment_analysis_trainingset.csv.segged_sample_None.tsv..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "吼吼 吼 ， 萌死 人 的 棒棒糖 ， 中 了 大众 点评 的 霸王餐 ， 太 可爱 了\n",
      "一直 就 好奇 这个 棒棒糖 是 怎么 个 东西 ， 大众 点评 给 了 我 这个 土老冒 一个 见识 的 机会\n",
      "看 介绍 棒棒糖 是 用 德国 糖 做 的 ， 不会 很甜 ， 中间 的 照片 是 糯米 的 ， 能 食用 ， 真是太 高端 大气 上档次 了 ， 还 可以 买 蝴蝶结 扎口 ， 送人 可以 买 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-14 22:30:36,007 [INFO] Read cache data/train/sentiment_analysis_trainingset.csv.segged_sample_None.tsv..\n",
      "2018-11-14 22:30:39,507 [INFO] Read cache data/validate/sentiment_analysis_validationset.csv.segged_sample_None.tsv..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "说起 这次 霸王餐 ， 真 有点 不知 如何 评价 ， 相当 的 一波三折\n",
      "日期 从 十多号 改成 20 号 ， 然后 晚上 六点半 的 活动 ， 下午 两点 半 通知 改期 ， 再次 改到 23\n",
      "到 了 23 号 终于 没 变动 了 ， 报名 时 的 全场 自助 默默 变成 了 套餐 ！ 除去 一些 不爱 吃 的 东西 ， 吃 到 的 东西 少得 可怜 ， 一个 人 三只 虾 也 是 醉 了 ！\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-14 22:30:40,084 [INFO] Read cache data/test-a/sentiment_analysis_testa.csv.segged_sample_None.tsv..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "哎 ， 想当年 来 佘山 的 时候 ， 啥 都 没有 ， 三品 香算 镇上 最大 看起来 最 像样 的 饭店 了\n",
      "菜品 多 ， 有点 太 多 ， 感觉 啥 都 有 ， 杂都 不足以 形容\n",
      "随便 点些 ， 居然 口味 什么 的 都 好 还 可以 ， 价钱 自然 是 便宜 当 震惊\n",
      "元宝 虾 和 椒盐 九肚鱼 都 不错 吃\n",
      "不过 近来 几次 么 ， 味道 明显 没 以前 好 了\n",
      "冷餐 里面 一个 凉拌\n",
      "\n",
      "我 想 说 他们 家 的 优惠活动 好 持久 啊 ， 我 预售 的 时候 买 的 券 ， 前两天 心血来潮 去 吃 的 活动 还 在 继续\n",
      "首先 说 下 服务 ， 因为 和 男票 开车 去 的 ， 有点 不 认路 ， 老板 很 耐心 的 在 电话 里 帮 我们 指路 ， 到 了 门店 之后 也 帮 我们 推荐 了 他们 家 做 的 比较 地道 的 伤心 凉粉 ， 说 是 厨师 是 四川 那边 来 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from config import validate_data_path, train_data_path, testa_data_path\n",
    "from fgclassifier import read_csv\n",
    "\n",
    "def content_to_corpus(data_path, txt_path, sample_n=None):\n",
    "    \"\"\"Convert Review content to text corpus for word embedding training\"\"\"\n",
    "    df = read_csv(data_path, seg_words=True, sample_n=None)\n",
    "    if sample_n:\n",
    "        df = df.sample(sample_n, random_state=1)\n",
    "    all_content = '\\n'.join(\n",
    "        y.strip() for x in df['content']\n",
    "        for y in x.strip('\"').split('。') if y.strip()\n",
    "    )\n",
    "    print(all_content[:200])\n",
    "    print()\n",
    "    with open(txt_path, 'w') as f:\n",
    "        f.write(all_content + '\\n')\n",
    "    \n",
    "content_to_corpus(train_data_path, 'data/text_train.txt')\n",
    "content_to_corpus(train_data_path, 'data/text_train_10k.txt', sample_n=10000)\n",
    "content_to_corpus(validate_data_path, 'data/text_valid.txt')\n",
    "content_to_corpus(testa_data_path, 'data/text_testa.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1114130 30757624 166330158\r\n"
     ]
    }
   ],
   "source": [
    "!cat data/text_train.txt data/text_valid.txt data/text_testa.txt | wc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All dataset combined has 30 million words, which is too much. According to [ELMoForManyLangs](https://github.com/HIT-SCIR/ELMoForManyLangs), it would take 3 days to train 20m words on an NVIDIA P100 GPU.\n",
    "\n",
    "We must sample the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   82727 2255688 12200210 data/text_train_10k.txt\r\n"
     ]
    }
   ],
   "source": [
    "!wc data/text_train_10k.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "店里 冰淇淋 有 12 个 口味 的 ~\r\n",
      "除了 冰淇淋 ~ 甜品 饮料 也 有 ~ 看 电影 前 可以 来 这里 等 ~ 也 可以 买 进去 吃 哈 ~\r\n",
      "# 枫树 胡桃 # BBLANKK\r\n",
      "店员 妹子 挖 完 冰淇淋 还 帮 我 称 了 一下 ~ 说 他们 家 的 单球 是 60g ~\r\n",
      "味道 很 好 啊 ~ 奶味算重 的 了 ~ 也 不会 很甜 ~ 里面 有 核桃仁 ~ 核桃仁 也 好吃 ~\r\n",
      "一个 球挺 多 的 ~ 吃 着 绝对 够 了 ~\r\n",
      "不过 原价 有点 小贵 ~ M 团有 团购 能 便宜 一点 ~\r\n",
      "总体 很 满意 的 ~ 以后 想 吃 冰淇淋 可以 来 这家 ~ 再 吃 吃 别的 味 ~\r\n",
      "极食 urban BBLANKK harvest 是 一个 走 自然 环保 高端 线路 的 餐厅 ， 位于 杭州 大厦 D座 5 楼 ～ 光看 地标 也 是 够 逼格 了 一进 门口 装饰 有 微型 田园 BBLANKK 看上去 食材 都 新鲜 的 不要 不要 的 ～ 给 创意 一个 赞 BBLANKK 只要 菜单 上 有 “ 即 摘 ” 字眼 的 ， 都 由 服务员 现场 采摘 取用 ， 菜色 摆盘 精致 而且 色彩 丰富 ， 让 人 食欲 大开 ， 口味 都 还 不错 ～ 不过 本人 本 就 不是 一个 太 挑食 的 人 啦 饭后 上 了 甜品 ， 好吃 到 飞 起来 ， 吃 得 愉快 心情 就 好好 ， 尤其 是 这样 一个 周末\r\n",
      "因为 价格 偏贵 的 缘故 ， 如此 黄金地段 、 高峰 时间 用餐 人 倒 不 多 ， 这 也 保证 了 用餐 环境 的 舒适度 ， 还有 一个 好消息 就是 ： 开业 初期 有 七折 优惠 哦 ！ 大家 赶紧 去 拔草 吧\r\n"
     ]
    }
   ],
   "source": [
    "!tail data/text_train_10k.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random sample of 10,000 reviews gives about 83k sentences, and 2.2m words. We expect the training\n",
    "time for 10,000 reviews to be about 8 hours.\n",
    "\n",
    "Let's try a very small subset just to make sure the software works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1000   29554  159470 data/text_train_1k.txt\r\n"
     ]
    }
   ],
   "source": [
    "# !shuf -n 10000 data/all_text.txt > data/little_text.txt\n",
    "# Use `gshuf` on Mac\n",
    "!gshuf -n 1000 data/text_train.txt > data/text_train_1k.txt\n",
    "!gshuf -n 100 data/text_train.txt > data/text_train_100.txt\n",
    "!wc data/text_train_1k.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, clip_grad=5.0, config_path='/Users/jesse/workspace/ML/fine-grain-sentiment-analysis/misc/elmo/cnn_50_100_512_4096_sample.json', eval_steps=10000, gpu=0, lr=0.001, lr_decay=0.8, max_epoch=10, max_sent_len=20, max_vocab_size=150000, min_count=5, model='data/elmo-zhs-1k', optimizer='adam', save_classify_layer=False, seed=1, test_path=None, train_path='data/text_train_1k.txt', valid_path='data/text_train_100.txt', valid_size=0, word_embedding=None)\n",
      "{'encoder': {'name': 'elmo', 'projection_dim': 512, 'cell_clip': 3, 'proj_clip': 3, 'dim': 4096, 'n_layers': 2}, 'token_embedder': {'name': 'cnn', 'activation': 'relu', 'filters': [[1, 32], [2, 32], [3, 64], [4, 128], [5, 256], [6, 512], [7, 1024]], 'n_highway': 2, 'word_dim': 100, 'char_dim': 50, 'max_characters_per_token': 50}, 'classifier': {'name': 'sampled_softmax', 'n_samples': 8192}, 'dropout': 0.1}\n",
      "2018-11-14 22:36:57,640 INFO: training instance: 1505, training tokens: 28596.\n",
      "2018-11-14 22:36:57,645 INFO: valid instance: 143, valid tokens: 2705.\n",
      "2018-11-14 22:36:57,675 INFO: Truncated word count: 7085.\n",
      "2018-11-14 22:36:57,676 INFO: Original vocabulary size: 5629.\n",
      "2018-11-14 22:36:57,683 INFO: Word embedding size: 786\n",
      "2018-11-14 22:36:57,704 INFO: Char embedding size: 2140\n",
      "2018-11-14 22:36:59,727 INFO: 48 batches, avg len: 20.0\n",
      "2018-11-14 22:36:59,728 INFO: Evaluate every 10000 batches.\n",
      "2018-11-14 22:37:00,040 INFO: 5 batches, avg len: 19.9\n",
      "2018-11-14 22:37:00,040 INFO: vocab size: 786\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "2018-11-14 22:37:08,984 INFO: Model(\n",
      "  (token_embedder): ConvTokenEmbedder(\n",
      "    (word_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(786, 100, padding_idx=3)\n",
      "    )\n",
      "    (char_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(2140, 50, padding_idx=2137)\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
      "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
      "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
      "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
      "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
      "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
      "    )\n",
      "    (highways): Highway(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
      "  )\n",
      "  (encoder): ElmobiLm(\n",
      "    (forward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (forward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      "  (classify_layer): SampledSoftmaxLayer(\n",
      "    (criterion): CrossEntropyLoss()\n",
      "    (column_emb): Embedding(786, 512)\n",
      "    (column_bias): Embedding(786, 1)\n",
      "  )\n",
      ")\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/elmoformanylangs-0.0.2-py3.6.egg/elmoformanylangs/biLM.py:343: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/elmoformanylangs-0.0.2-py3.6.egg/elmoformanylangs/biLM.py:348: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "2018-11-14 22:37:40,645 INFO: Epoch=0 iter=32 lr=0.001000 train_ppl=72388.250000 time=28.90s\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/elmoformanylangs-0.0.2-py3.6.egg/elmoformanylangs/biLM.py:297: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2018-11-14 22:37:56,929 INFO: Epoch=0 iter=48 lr=0.001000 valid_ppl=58.615864\n",
      "2018-11-14 22:37:57,981 INFO: New record achieved!\n",
      "2018-11-14 22:38:24,576 INFO: Epoch=1 iter=32 lr=0.000800 train_ppl=63.343208 time=26.59s\n",
      "2018-11-14 22:38:42,185 INFO: Epoch=1 iter=48 lr=0.000800 valid_ppl=44.460205\n",
      "2018-11-14 22:38:42,798 INFO: New record achieved!\n",
      "2018-11-14 22:39:09,410 INFO: Epoch=2 iter=32 lr=0.000640 train_ppl=52.716682 time=26.61s\n",
      "2018-11-14 22:39:24,734 INFO: Epoch=2 iter=48 lr=0.000640 valid_ppl=41.916843\n",
      "2018-11-14 22:39:25,305 INFO: New record achieved!\n",
      "2018-11-14 22:39:55,008 INFO: Epoch=3 iter=32 lr=0.000512 train_ppl=47.527332 time=29.70s\n",
      "2018-11-14 22:40:11,341 INFO: Epoch=3 iter=48 lr=0.000512 valid_ppl=39.813450\n",
      "2018-11-14 22:40:12,012 INFO: New record achieved!\n",
      "2018-11-14 22:40:38,603 INFO: Epoch=4 iter=32 lr=0.000410 train_ppl=43.219276 time=26.58s\n",
      "2018-11-14 22:40:54,555 INFO: Epoch=4 iter=48 lr=0.000410 valid_ppl=38.112942\n",
      "2018-11-14 22:40:55,184 INFO: New record achieved!\n",
      "2018-11-14 22:41:27,812 INFO: Epoch=5 iter=32 lr=0.000328 train_ppl=40.482231 time=32.62s\n",
      "2018-11-14 22:41:44,222 INFO: Epoch=5 iter=48 lr=0.000328 valid_ppl=37.239307\n",
      "2018-11-14 22:41:44,942 INFO: New record achieved!\n",
      "2018-11-14 22:42:12,696 INFO: Epoch=6 iter=32 lr=0.000262 train_ppl=36.799458 time=27.75s\n",
      "2018-11-14 22:42:29,051 INFO: Epoch=6 iter=48 lr=0.000262 valid_ppl=36.741238\n",
      "2018-11-14 22:42:29,662 INFO: New record achieved!\n",
      "2018-11-14 22:42:58,419 INFO: Epoch=7 iter=32 lr=0.000210 train_ppl=35.172501 time=28.75s\n",
      "2018-11-14 22:43:17,635 INFO: Epoch=7 iter=48 lr=0.000210 valid_ppl=36.912933\n",
      "2018-11-14 22:43:48,403 INFO: Epoch=8 iter=32 lr=0.000168 train_ppl=32.478752 time=30.75s\n",
      "2018-11-14 22:44:03,723 INFO: Epoch=8 iter=48 lr=0.000168 valid_ppl=36.847874\n",
      "2018-11-14 22:44:29,567 INFO: Epoch=9 iter=32 lr=0.000134 train_ppl=31.984341 time=25.84s\n",
      "2018-11-14 22:44:51,497 INFO: Epoch=9 iter=48 lr=0.000134 valid_ppl=37.348961\n",
      "2018-11-14 22:44:51,503 INFO: best train ppl: 100000000.000000, best valid ppl: 36.741238.\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "# add `pwd` to `config_path` because trained model depends on that file\n",
    "# absolute path makes it easier to find\n",
    "!python -m elmoformanylangs.biLM train \\\n",
    "    --train_path data/text_train_1k.txt \\\n",
    "    --valid_path data/text_train_100.txt \\\n",
    "    --model data/elmo-zhs-1k \\\n",
    "    --config_path `pwd`/misc/elmo/cnn_50_100_512_4096_sample.json \\\n",
    "    --seed 1 \\\n",
    "    --gpu 0 \\\n",
    "    --optimizer adam \\\n",
    "    --lr 0.001 \\\n",
    "    --lr_decay 0.8 \\\n",
    "    --batch_size 32 \\\n",
    "    --clip_grad 5 \\\n",
    "    --max_epoch 10 \\\n",
    "    --max_sent_len 20 \\\n",
    "    --max_vocab_size 150000 \\\n",
    "    --eval_steps 10000 \\\n",
    "    --min_count 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-14 23:19:31,908 [INFO] Read cache data/train/sentiment_analysis_trainingset.csv.segged_sample_None.tsv..\n"
     ]
    }
   ],
   "source": [
    "df_train = read_csv(train_data_path, seg_words=True, sample_n=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-14 23:21:26,090 [INFO] char embedding size: 8582\n",
      "2018-11-14 23:21:26,861 [INFO] word embedding size: 69827\n",
      "2018-11-14 23:21:34,862 [INFO] Model(\n",
      "  (token_embedder): ConvTokenEmbedder(\n",
      "    (word_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(69827, 100, padding_idx=3)\n",
      "    )\n",
      "    (char_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(8582, 50, padding_idx=8579)\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
      "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
      "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
      "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
      "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
      "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
      "    )\n",
      "    (highways): Highway(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
      "  )\n",
      "  (encoder): ElmobiLm(\n",
      "    (forward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (forward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "2018-11-14 23:21:35,856 [INFO] 1 batches, avg len: 371.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.16197295,  0.05117923, -0.13360588, ...,  0.24924016,\n",
       "         -0.27383432, -0.05000202],\n",
       "        [ 0.06199374,  0.07696173, -0.23577517, ...,  0.26290917,\n",
       "         -0.27809614, -0.06464732],\n",
       "        [ 0.0008731 , -0.04712557, -0.08987609, ..., -0.00968068,\n",
       "         -0.13784361, -0.03070146],\n",
       "        ...,\n",
       "        [-0.27461815,  0.03719755, -0.13428287, ..., -0.06027537,\n",
       "         -0.07961495, -0.14139868],\n",
       "        [-0.06108154,  0.13908525, -0.2571093 , ...,  0.01645198,\n",
       "         -0.02265188, -0.02150639],\n",
       "        [-0.19907278,  0.02419554, -0.19596738, ...,  0.07171986,\n",
       "         -0.01507132,  0.02613006]], dtype=float32),\n",
       " array([[-0.17354196, -0.36698878, -0.04885902, ..., -0.02680009,\n",
       "          0.13608061,  0.12091058],\n",
       "        [-0.29550084, -0.12204532, -0.28084293, ..., -0.29321548,\n",
       "          0.13516046, -0.11846065],\n",
       "        [-0.05146622, -0.19961458,  0.01509347, ...,  0.05483557,\n",
       "         -0.06374971, -0.0203303 ],\n",
       "        ...,\n",
       "        [-0.1181826 ,  0.02767085, -0.35975978, ..., -0.01324531,\n",
       "          0.00909343, -0.03078758],\n",
       "        [-0.0251124 ,  0.20625134, -0.2706751 , ...,  0.09297368,\n",
       "          0.14488776, -0.00088627],\n",
       "        [-0.04889162, -0.19273376, -0.3477179 , ...,  0.0895622 ,\n",
       "          0.04090813,  0.11943939]], dtype=float32)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elmoformanylangs import Embedder\n",
    "\n",
    "elmoemb = Embedder('data/elmo-zhs-fsauor')\n",
    "# e = Embedder('data/elmo-zhs-1k')\n",
    "\n",
    "sents = df_train['content'][0:2]\n",
    "elmoemb.sents2elmo(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat data/text_train.txt data/text_testa.txt > data/text_train_valid.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train the full model\n",
    "!time python -m elmoformanylangs.biLM train \\\n",
    "    --train_path data/text_train_valid.txt \\\n",
    "    --valid_path data/text_testa.txt \\\n",
    "    --model data/elmo-zhs \\\n",
    "    --config_path `pwd`/misc/elmo/cnn_50_100_512_4096_sample.json \\\n",
    "    --seed 1 \\\n",
    "    --gpu 0 \\\n",
    "    --optimizer adam \\\n",
    "    --lr 0.001 \\\n",
    "    --lr_decay 0.8 \\\n",
    "    --batch_size 32 \\\n",
    "    --clip_grad 5 \\\n",
    "    --max_epoch 10 \\\n",
    "    --max_sent_len 20 \\\n",
    "    --max_vocab_size 150000 \\\n",
    "    --eval_steps 10000 \\\n",
    "    --min_count 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
